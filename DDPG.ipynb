{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a612d2d2-e16b-452d-aa42-a9177ed95653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import DDPG.DDPG as dg \n",
    "import Env.env as e\n",
    "import Utils.utils as utils\n",
    "import DDPG.buffer as bf\n",
    "import time \n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Set print options for NumPy arrays to format floating-point numbers with 5 decimal places;\n",
    "# By using this line, any floating-point numbers in a NumPy array will be printed with exactly 5 decimal places.\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "\n",
    "def plot_figure_state(figure_state, filename='./learning_curve/figure_state.png'):\n",
    "    figure_state = np.array(figure_state)\n",
    "    time = np.linspace(0, len(figure_state), len(figure_state))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time, figure_state[:, 0], label='State 1')\n",
    "    plt.plot(time, figure_state[:, 1], label='State 2')\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('State Value')\n",
    "    plt.title('State Values Over Time')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()  # 关闭图形以释放内存\n",
    "\n",
    "\n",
    "# setting the episode length. \n",
    "episode_length = 1000 \n",
    "\n",
    "replay_buffer_file = 'replay_buffer.pkl'\n",
    "\n",
    "def actor_training(env, policy, batch_size, replay_buffer, start_timesteps, total_ep_training ):\n",
    "\n",
    "    global episode_length \n",
    "\n",
    "    # list to store the episode rewards. \n",
    "    ep_reward_list = [] \n",
    "\n",
    "    # exploration  VS exploitation  Decay rate for the standard deviation of noise.\n",
    "    # This controls how much the noise (exploration) decreases over time.\n",
    "    # A higher decay_rate (e.g., 0.02) leads to faster decay, resulting in less exploration in later episodes,\n",
    "    # while a lower decay_rate (e.g., 0.01) maintains exploration for a longer period, potentially aiding in finding a global optimum.\n",
    "    decay_rate = 0.03 \n",
    "\n",
    "    data_listt = [] \n",
    "\n",
    "    start = time.time() \n",
    "    # Load replay buffer data if the file exists\n",
    "    '''if os.path.exists(replay_buffer_file):\n",
    "        with open(replay_buffer_file, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)'''\n",
    "    # else:\n",
    "    #     replay_buffer = ReplayBuffer()  # Initialize your replay buffer here\n",
    "\n",
    "    for ep in range(1, total_ep_training): #total_ep_training = 3000 \n",
    "        \n",
    "        print(\"\\n \\n \\n episode : \", ep ) \n",
    "        episode_reward = 0 \n",
    "        # call the reset function to get the initial state....\n",
    "        state, info_dic = env.reset() \n",
    "\n",
    "        # setpoint state and setpoint actions for the current episode \n",
    "        setpoint_state = info_dic['setpoint_state']   \n",
    "        setpoint_action = info_dic['setpoint_action'] \n",
    "\n",
    "        # decay of the statndard diviation with the episode \n",
    "        decay_std = 1 * 1/(1 + decay_rate * ep)   \n",
    "\n",
    "        std_dev = np.array([decay_std, decay_std*0.1], dtype=float)   # the larger std, the larger noise  \n",
    "        ep_len = 0  \n",
    "\n",
    "        actions__ = [] \n",
    "        obs__ = [] \n",
    "        us_obs__ = []\n",
    "        us_actions__ = [] \n",
    "\n",
    "\n",
    "        break_episode = False  \n",
    "        counter = 0\n",
    "\n",
    "        figure_state=[]\n",
    "        while not(break_episode): \n",
    "            counter += 1\n",
    "\n",
    "            ep_len += 1 \n",
    "\n",
    "            ### selecting the actions random actions for some staring some episodes...\n",
    "            if ep <= start_timesteps: #start_timesteps = 1000\n",
    "                action = env.action_space.sample()   \n",
    "            else:\n",
    "\n",
    "                aaa1=policy.select_action(state)\n",
    "                aaa2=utils.gaussian_noise(mean=np.array([0, 0]) , std=std_dev )\n",
    "                noisy_action = policy.select_action(state) + utils.gaussian_noise(mean=np.array([0, 0]) , std=std_dev )  \n",
    "                                           \n",
    "                action = utils.clip_negative_positive_one(noisy_action)  \n",
    "                \n",
    "            ### Perform action\n",
    "            # print(\"actions : \", action) \n",
    "\n",
    "            obs__.append(state)  \n",
    "            actions__.append(action)    \n",
    "\n",
    "            # # print(state)\n",
    "            t_s  = utils.reverse_normalize_minmax_states(state[:2]) \n",
    "            # # print(state[:2])\n",
    "            # t_e  = utils.reverse_normalize_minmax_error(state[2]) \n",
    "            # # print(state[2])\n",
    "            # t_ie = utils.reverse_normalize_minmax_ierror(state[3]) \n",
    "            # # print(state[3])\n",
    "\n",
    "            # obsss = np.concatenate([t_s, t_e, t_ie]) \n",
    "            # us_obs__.append(obsss) \n",
    "\n",
    "            t_a = utils.reverse_normalize_minmax_actions(action)   \n",
    "            # us_actions__.append(t_a)    \n",
    "            \n",
    "            #### calling the step function which is returning the next_state, reward, termination and trancate....\n",
    "            next_state, reward, terminated, trancate, _ = env.step(action) \n",
    "            \n",
    "            ### break episode if terminate or trancate is true. \n",
    "            # terminated = true: the state converges to steady state; trancate=true: length = episode length\n",
    "            break_episode = terminated or trancate  \n",
    "            done = terminated \n",
    "\n",
    "            if done:\n",
    "                d = 1\n",
    "            else:\n",
    "                d = 0\n",
    "\n",
    "            ### Store data in replay buffer \n",
    "            replay_buffer.add(state, action, next_state, reward, d)  \n",
    "\n",
    "            ### Train agent after collecting sufficient data\n",
    "            if ep >= start_timesteps:\n",
    "                policy.train(replay_buffer, batch_size )    \n",
    "\n",
    "\n",
    "            if break_episode: \n",
    "                obs__ = np.array(obs__) \n",
    "                actions__ = np.array(actions__)  \n",
    "\n",
    "\n",
    "                print(\" step   : \", np.round(setpoint_state, 2))  \n",
    "                print(\" state  : \", np.round(t_s, 2))   \n",
    "                print(\" step a : \", np.round(setpoint_action, 2)) \n",
    "                print(\" action : \", np.round(t_a, 2))    \n",
    "                print(\" done   : \", done)        \n",
    "\n",
    "                print(\"   _std : \", np.round(decay_std, 3))   \n",
    "                print(\"episode length : \", counter) \n",
    "\n",
    "\n",
    "                dict__n = {\n",
    "                    \"setpoint_state  \": setpoint_state, \n",
    "                    \"state           \":t_s,\n",
    "                    \"setpoint_action \": setpoint_action,\n",
    "                    \"action          \":t_a,\n",
    "                    \"ep_reward       \":episode_reward,\n",
    "                    \"reward          \":reward,\n",
    "                    \"done            \":done,\n",
    "                    \"std             \":decay_std, \n",
    "                    \"episode length  \":counter \n",
    "                }  \n",
    "\n",
    "                data_listt.append(dict__n) \n",
    "\n",
    "\n",
    "            if ep % episode_length == 0: \n",
    "                # dir_l = utils.global_dir + '/data'  \n",
    "                # policy.save(dir_l, ep)   \n",
    "\n",
    "                # file  = utils.global_dir + '/data/mat/reward_list'+ str(ep) +'.csv'\n",
    "                # np.savetxt(file, ep_reward_list, delimiter=',')     \n",
    "                pass \n",
    "\n",
    "\n",
    "            state = next_state \n",
    "            episode_reward += reward \n",
    "\n",
    "            \n",
    "            figure_state.append(t_s)\n",
    " \n",
    "        if ep>1:\n",
    "            plot_figure_state(figure_state, 'figure_state_episode_{}.png'.format(ep))\n",
    "\n",
    "\n",
    "        ep_reward_list.append(episode_reward)    \n",
    "        print(\"\\nEpisode reward : \", round(episode_reward, 2))  \n",
    "        \n",
    "        if ep == 1000: \n",
    "            # Save replay buffer data to file at the end of the run\n",
    "            with open(replay_buffer_file, 'wb') as f:\n",
    "                pickle.dump(replay_buffer, f)\n",
    "\n",
    "\n",
    "    end = time.time() \n",
    "\n",
    "    time_taken_in_seconds = round(end-start, 2)  \n",
    "    time_taken_in_minutes = round(time_taken_in_seconds / 60, 2) \n",
    "    time_taken_in_hours  = round(time_taken_in_minutes / 60, 2) \n",
    "\n",
    "\n",
    "    # saving the time taken to train the Actor agent. \n",
    "    with open('time.txt', 'w') as file:\n",
    "        file.write(str(start))  \n",
    "        file.write('\\n') \n",
    "        file.write(str(end))  \n",
    "        file.write(\"\\n\"+str(time_taken_in_seconds)+\" time taken during training in seconds\")      \n",
    "        file.write(\"\\n\"+str(time_taken_in_minutes)+\" time taken during training in minutes\")     \n",
    "        file.write(\"\\n\"+str(time_taken_in_hours)+\" time taken during training in hours\")     \n",
    "\n",
    "    print() \n",
    "\n",
    "    file  = utils.global_dir + '/data/mat/reward_list.csv'\n",
    "    np.savetxt(file, ep_reward_list, delimiter=',')  \n",
    "\n",
    "    dir_l = utils.global_dir + '/data'\n",
    "    policy.save(dir_l, 17) \n",
    "\n",
    "\n",
    "    with open('output_list.txt', 'w') as file:\n",
    "        for dictionary in data_listt:\n",
    "            for key, value in dictionary.items():\n",
    "                file.write('%s:%s\\n' % (key, value))\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed0212-ec4d-4772-b875-d93388d0d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating the environment. \n",
    "    cstr = e.cstr_env() \n",
    "\n",
    "    state_dim_ = cstr.observation_space.shape[0] \n",
    "    action_dim_ = cstr.action_space.shape[0]  \n",
    "\n",
    "    print(\"state dim : \", state_dim_) \n",
    "    print(\"action dim : \", action_dim_ )   \n",
    "    \n",
    "    # create the DDPG object. \n",
    "    ddpg = dg.DDPG( \n",
    "            state_dim=state_dim_, \n",
    "            action_dim=action_dim_, \n",
    "            discount=1, \n",
    "            tau=0.001\n",
    "        )    \n",
    "\n",
    "    ## buffer size \n",
    "    buffer_size = int(1e6)  \n",
    "\n",
    "    # creating the buffer which is used to save the tranistions [s, a, s', r, done]\n",
    "    buffer = bf.ReplayBuffer(state_dim_, action_dim_, buffer_size)  \n",
    "\n",
    "    actor_training( \n",
    "        env= cstr,\n",
    "        policy= ddpg,\n",
    "        # batch size used to update the actor-critic.\n",
    "        batch_size= 256,\n",
    "        replay_buffer= buffer,\n",
    "        # warm-up episodes till episode_length episodes there is no update in the actor-critic network. \n",
    "        start_timesteps=  1000, #episode_length,\n",
    "        # totoal number of episodes used to train the actor-critic network.\n",
    "        total_ep_training = 3000 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4b7c6d-58dc-400f-b02a-051ffc2353cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353977"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ddpg.actor_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b2708f-f5c8-45e4-bd64-cbc146edea4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fa0f5f7e60>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, 353977), ddpg.actor_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8dfa1ca-b160-4585-b6fd-e50af2d55aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fa12e74da0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, 353978), ddpg.critic_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3b9f997-39b9-425d-bf24-93b206592e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state dim :  4\n",
      "action dim :  2\n",
      "\n",
      " \n",
      " \n",
      " episode :  1\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.85000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.64000 -0.27000]\n",
      " done   :  False\n",
      "   _std :  0.971\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3971.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  2\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.26000 -0.74000]\n",
      " done   :  False\n",
      "   _std :  0.943\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4114.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  3\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.64000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.08000 -0.42000]\n",
      " done   :  False\n",
      "   _std :  0.917\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2886.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  4\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.32000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.93000 -0.53000]\n",
      " done   :  False\n",
      "   _std :  0.893\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3642.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  5\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.90000 -0.45000]\n",
      " done   :  False\n",
      "   _std :  0.87\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7311.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  6\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.70000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.37000 1.16000]\n",
      " done   :  False\n",
      "   _std :  0.847\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2524.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  7\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.22000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.77000 -0.85000]\n",
      " done   :  False\n",
      "   _std :  0.826\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9028.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  8\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.19000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.02000 0.09000]\n",
      " done   :  False\n",
      "   _std :  0.806\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2396.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  9\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.91000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.87000 0.54000]\n",
      " done   :  False\n",
      "   _std :  0.787\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4897.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  10\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.79000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.06000 -0.38000]\n",
      " done   :  False\n",
      "   _std :  0.769\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1914.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  11\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.28000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.78000 1.09000]\n",
      " done   :  False\n",
      "   _std :  0.752\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5306.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  12\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.47000 -0.13000]\n",
      " done   :  False\n",
      "   _std :  0.735\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9521.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  13\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.10000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.25000 0.71000]\n",
      " done   :  False\n",
      "   _std :  0.719\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2051.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  14\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.16000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.07000 1.00000]\n",
      " done   :  False\n",
      "   _std :  0.704\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3393.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  15\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.23000 -0.31000]\n",
      " done   :  False\n",
      "   _std :  0.69\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9339.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  16\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.19000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.24000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.676\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3253.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  17\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.67000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.29000 0.58000]\n",
      " done   :  False\n",
      "   _std :  0.662\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3723.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  18\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.08000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.38000 0.56000]\n",
      " done   :  False\n",
      "   _std :  0.649\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2556.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  19\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.59000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.02000 0.75000]\n",
      " done   :  False\n",
      "   _std :  0.637\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3108.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  20\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.25000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.91000 0.55000]\n",
      " done   :  False\n",
      "   _std :  0.625\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2642.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  21\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.69000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.66000 1.03000]\n",
      " done   :  False\n",
      "   _std :  0.613\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2133.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  22\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.24000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.69000 0.40000]\n",
      " done   :  False\n",
      "   _std :  0.602\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2577.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  23\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.52000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.95000 -0.89000]\n",
      " done   :  False\n",
      "   _std :  0.592\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2459.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  24\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.23000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.87000 0.36000]\n",
      " done   :  False\n",
      "   _std :  0.581\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3370.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  25\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.39000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.42000 0.20000]\n",
      " done   :  False\n",
      "   _std :  0.571\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2540.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  26\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.20000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.63000 -0.08000]\n",
      " done   :  False\n",
      "   _std :  0.562\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2959.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  27\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.39000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.97000 0.96000]\n",
      " done   :  False\n",
      "   _std :  0.552\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3444.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  28\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.63000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.49000 -1.12000]\n",
      " done   :  False\n",
      "   _std :  0.543\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4500.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  29\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.20000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.28000]\n",
      " done   :  False\n",
      "   _std :  0.535\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7811.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  30\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.17000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.19000 -1.17000]\n",
      " done   :  False\n",
      "   _std :  0.526\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3500.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  31\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.65000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.61000 0.48000]\n",
      " done   :  False\n",
      "   _std :  0.518\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2540.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  32\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.39000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.83000 0.74000]\n",
      " done   :  False\n",
      "   _std :  0.51\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3004.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  33\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.11000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.98000 0.21000]\n",
      " done   :  False\n",
      "   _std :  0.503\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4246.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  34\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.10000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.32000 0.97000]\n",
      " done   :  False\n",
      "   _std :  0.495\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3314.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  35\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.22000 0.76000]\n",
      " done   :  False\n",
      "   _std :  0.488\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3853.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  36\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.56000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.67000 0.66000]\n",
      " done   :  False\n",
      "   _std :  0.481\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2833.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  37\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.58000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.61000 0.48000]\n",
      " done   :  False\n",
      "   _std :  0.474\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7573.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  38\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.45000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.65000 0.21000]\n",
      " done   :  False\n",
      "   _std :  0.467\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3688.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  39\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.55000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.50000 -0.18000]\n",
      " done   :  False\n",
      "   _std :  0.461\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3325.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  40\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.75000 -0.16000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.09000 -0.52000]\n",
      " done   :  False\n",
      "   _std :  0.455\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7579.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  41\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.56000 0.93000]\n",
      " done   :  False\n",
      "   _std :  0.448\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2018.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  42\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.09000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.56000 0.14000]\n",
      " done   :  False\n",
      "   _std :  0.442\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3383.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  43\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.95000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.24000 -0.83000]\n",
      " done   :  False\n",
      "   _std :  0.437\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6028.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  44\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.51000 0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.26000 -0.16000]\n",
      " done   :  False\n",
      "   _std :  0.431\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9475.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  45\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.35000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.98000 -0.98000]\n",
      " done   :  False\n",
      "   _std :  0.426\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2995.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  46\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.69000 -1.08000]\n",
      " done   :  False\n",
      "   _std :  0.42\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1907.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  47\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.57000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.94000 0.99000]\n",
      " done   :  False\n",
      "   _std :  0.415\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3825.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  48\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.97000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.38000 -0.41000]\n",
      " done   :  False\n",
      "   _std :  0.41\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3440.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  49\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.19000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.15000 0.28000]\n",
      " done   :  False\n",
      "   _std :  0.405\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8303.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  50\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.33000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.30000]\n",
      " done   :  False\n",
      "   _std :  0.4\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5770.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  51\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.04000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.18000 0.57000]\n",
      " done   :  False\n",
      "   _std :  0.395\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6916.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  52\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.09000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.15000 1.10000]\n",
      " done   :  False\n",
      "   _std :  0.391\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3819.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  53\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.43000 -0.17000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.52000 -0.06000]\n",
      " done   :  False\n",
      "   _std :  0.386\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6851.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  54\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.86000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.13000 -0.85000]\n",
      " done   :  False\n",
      "   _std :  0.382\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10431.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  55\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.25000 0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.92000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.377\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9930.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  56\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.57000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.97000 1.11000]\n",
      " done   :  False\n",
      "   _std :  0.373\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3714.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  57\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.72000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.26000 -1.15000]\n",
      " done   :  False\n",
      "   _std :  0.369\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1649.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  58\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.10000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.365\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5115.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  59\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.59000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.99000 -0.92000]\n",
      " done   :  False\n",
      "   _std :  0.361\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5204.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  60\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.30000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.42000 -0.74000]\n",
      " done   :  False\n",
      "   _std :  0.357\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1704.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  61\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.63000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.63000 -0.51000]\n",
      " done   :  False\n",
      "   _std :  0.353\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6227.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  62\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.19000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.10000 -0.56000]\n",
      " done   :  False\n",
      "   _std :  0.35\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6801.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  63\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.85000 0.63000]\n",
      " done   :  False\n",
      "   _std :  0.346\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6814.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  64\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.26000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.59000 -0.24000]\n",
      " done   :  False\n",
      "   _std :  0.342\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3070.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  65\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.52000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.28000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.339\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2821.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  66\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.17000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.09000 0.06000]\n",
      " done   :  False\n",
      "   _std :  0.336\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3947.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  67\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.59000 -0.21000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.38000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.332\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -11335.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  68\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.71000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.62000 0.67000]\n",
      " done   :  False\n",
      "   _std :  0.329\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6502.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  69\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.40000 0.11000]\n",
      " done   :  False\n",
      "   _std :  0.326\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4584.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  70\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.70000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.90000 -0.11000]\n",
      " done   :  False\n",
      "   _std :  0.323\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2895.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  71\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.56000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.57000 1.02000]\n",
      " done   :  False\n",
      "   _std :  0.319\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2956.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  72\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.39000 0.47000]\n",
      " done   :  False\n",
      "   _std :  0.316\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3045.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  73\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.50000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.72000 0.83000]\n",
      " done   :  False\n",
      "   _std :  0.313\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3005.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  74\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.14000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.04000 0.13000]\n",
      " done   :  False\n",
      "   _std :  0.311\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2227.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  75\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.62000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.36000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.308\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1674.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  76\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.07000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.33000 0.61000]\n",
      " done   :  False\n",
      "   _std :  0.305\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3743.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  77\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.35000 0.85000]\n",
      " done   :  False\n",
      "   _std :  0.302\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3375.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  78\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.83000 1.07000]\n",
      " done   :  False\n",
      "   _std :  0.299\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4481.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  79\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.22000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 0.47000]\n",
      " done   :  False\n",
      "   _std :  0.297\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2171.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  80\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.00000 1.09000]\n",
      " done   :  False\n",
      "   _std :  0.294\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2800.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  81\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.30000 0.80000]\n",
      " done   :  False\n",
      "   _std :  0.292\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6698.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  82\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.91000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.21000 -0.57000]\n",
      " done   :  False\n",
      "   _std :  0.289\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4519.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  83\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.94000 -0.21000]\n",
      " done   :  False\n",
      "   _std :  0.287\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1994.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  84\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.86000 -0.96000]\n",
      " done   :  False\n",
      "   _std :  0.284\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5186.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  85\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.17000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.52000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.282\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1847.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  86\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.22000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.38000 -0.71000]\n",
      " done   :  False\n",
      "   _std :  0.279\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2094.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  87\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.54000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.75000 -0.33000]\n",
      " done   :  False\n",
      "   _std :  0.277\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2978.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  88\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.80000 0.14000]\n",
      " done   :  False\n",
      "   _std :  0.275\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5483.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  89\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.33000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.22000 0.86000]\n",
      " done   :  False\n",
      "   _std :  0.272\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2620.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  90\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.38000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.22000 1.12000]\n",
      " done   :  False\n",
      "   _std :  0.27\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2819.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  91\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.17000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.04000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.268\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1479.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  92\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.12000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.27000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.266\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2470.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  93\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.78000 -0.80000]\n",
      " done   :  False\n",
      "   _std :  0.264\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4231.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  94\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.20000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.04000 -0.75000]\n",
      " done   :  False\n",
      "   _std :  0.262\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2687.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  95\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.36000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.80000 -0.31000]\n",
      " done   :  False\n",
      "   _std :  0.26\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3264.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  96\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.54000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.97000 0.64000]\n",
      " done   :  False\n",
      "   _std :  0.258\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3653.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  97\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.32000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 0.77000]\n",
      " done   :  False\n",
      "   _std :  0.256\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4734.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  98\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.48000 0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.79000 1.10000]\n",
      " done   :  False\n",
      "   _std :  0.254\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5769.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  99\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.19000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.70000 -0.52000]\n",
      " done   :  False\n",
      "   _std :  0.252\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2983.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  100\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.10000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.78000 0.84000]\n",
      " done   :  False\n",
      "   _std :  0.25\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4525.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  101\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.27000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.39000 -0.48000]\n",
      " done   :  False\n",
      "   _std :  0.248\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5094.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  102\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.24000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.15000 0.86000]\n",
      " done   :  False\n",
      "   _std :  0.246\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5874.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  103\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.18000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.62000 -0.54000]\n",
      " done   :  False\n",
      "   _std :  0.244\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3734.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  104\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.94000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.09000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.243\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5021.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  105\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.01000 0.99000]\n",
      " done   :  False\n",
      "   _std :  0.241\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1611.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  106\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.43000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.39000 -0.41000]\n",
      " done   :  False\n",
      "   _std :  0.239\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3567.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  107\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.19000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.08000 -0.66000]\n",
      " done   :  False\n",
      "   _std :  0.238\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4025.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  108\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.94000 -0.75000]\n",
      " done   :  False\n",
      "   _std :  0.236\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2938.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  109\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.76000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.88000 -0.10000]\n",
      " done   :  False\n",
      "   _std :  0.234\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3596.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  110\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.51000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.11000 0.15000]\n",
      " done   :  False\n",
      "   _std :  0.233\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2252.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  111\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.56000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.71000 -0.97000]\n",
      " done   :  False\n",
      "   _std :  0.231\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2621.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  112\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.71000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.41000 1.15000]\n",
      " done   :  False\n",
      "   _std :  0.229\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2511.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  113\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.22000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.36000 0.77000]\n",
      " done   :  False\n",
      "   _std :  0.228\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2873.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  114\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.31000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.62000 0.57000]\n",
      " done   :  False\n",
      "   _std :  0.226\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2005.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  115\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.54000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.51000]\n",
      " done   :  False\n",
      "   _std :  0.225\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7307.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  116\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.38000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.50000 -0.06000]\n",
      " done   :  False\n",
      "   _std :  0.223\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3327.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  117\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.87000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.79000 0.32000]\n",
      " done   :  False\n",
      "   _std :  0.222\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2704.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  118\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.69000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.06000 -0.99000]\n",
      " done   :  False\n",
      "   _std :  0.22\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4219.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  119\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.48000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.46000 -0.97000]\n",
      " done   :  False\n",
      "   _std :  0.219\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5783.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  120\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.27000 -0.88000]\n",
      " done   :  False\n",
      "   _std :  0.217\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4731.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  121\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.20000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.88000 0.85000]\n",
      " done   :  False\n",
      "   _std :  0.216\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4303.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  122\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.39000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.65000 -0.06000]\n",
      " done   :  False\n",
      "   _std :  0.215\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5366.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  123\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.36000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.42000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.213\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1754.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  124\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.58000 -1.00000]\n",
      " done   :  True\n",
      "   _std :  0.212\n",
      "episode length :  812\n",
      "\n",
      "Episode reward :  -5071.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  125\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.35000 0.77000]\n",
      " done   :  False\n",
      "   _std :  0.211\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4549.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  126\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.78000 0.26000]\n",
      " done   :  False\n",
      "   _std :  0.209\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2132.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  127\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.31000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.67000 0.18000]\n",
      " done   :  False\n",
      "   _std :  0.208\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2707.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  128\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.48000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.82000 0.90000]\n",
      " done   :  False\n",
      "   _std :  0.207\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4377.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  129\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.51000 -0.95000]\n",
      " done   :  False\n",
      "   _std :  0.205\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3591.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  130\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.13000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.98000 -1.16000]\n",
      " done   :  False\n",
      "   _std :  0.204\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2750.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  131\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.32000 -0.03000]\n",
      " done   :  False\n",
      "   _std :  0.203\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3809.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  132\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.07000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.53000 -0.66000]\n",
      " done   :  False\n",
      "   _std :  0.202\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8619.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  133\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.64000 -0.77000]\n",
      " done   :  False\n",
      "   _std :  0.2\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4776.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  134\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.68000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.99000 -0.18000]\n",
      " done   :  False\n",
      "   _std :  0.199\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6443.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  135\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.81000 0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.71000 -1.01000]\n",
      " done   :  False\n",
      "   _std :  0.198\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5934.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  136\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.14000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.01000 -0.67000]\n",
      " done   :  False\n",
      "   _std :  0.197\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3805.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  137\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.37000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.36000 -0.51000]\n",
      " done   :  False\n",
      "   _std :  0.196\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3392.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  138\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.18000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.14000 -1.03000]\n",
      " done   :  False\n",
      "   _std :  0.195\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3935.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  139\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.85000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.61000 0.23000]\n",
      " done   :  False\n",
      "   _std :  0.193\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4358.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  140\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.41000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.192\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2135.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  141\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.45000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.28000 -1.05000]\n",
      " done   :  False\n",
      "   _std :  0.191\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6384.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  142\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.17000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.33000 0.67000]\n",
      " done   :  False\n",
      "   _std :  0.19\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3309.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  143\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.84000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.00000 -0.52000]\n",
      " done   :  False\n",
      "   _std :  0.189\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3930.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  144\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.87000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.49000 0.14000]\n",
      " done   :  False\n",
      "   _std :  0.188\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2791.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  145\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.24000 -0.90000]\n",
      " done   :  False\n",
      "   _std :  0.187\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3037.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  146\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.38000 0.47000]\n",
      " done   :  False\n",
      "   _std :  0.186\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2793.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  147\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.88000]\n",
      " done   :  True\n",
      "   _std :  0.185\n",
      "episode length :  890\n",
      "\n",
      "Episode reward :  -2735.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  148\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.11000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.24000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.184\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3102.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  149\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.74000 0.64000]\n",
      " done   :  False\n",
      "   _std :  0.183\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3348.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  150\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.60000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.71000 -0.30000]\n",
      " done   :  False\n",
      "   _std :  0.182\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4018.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  151\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.12000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.31000 -0.61000]\n",
      " done   :  False\n",
      "   _std :  0.181\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2374.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  152\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.13000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.74000 -0.88000]\n",
      " done   :  False\n",
      "   _std :  0.18\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10742.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  153\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.05000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.07000 -0.56000]\n",
      " done   :  False\n",
      "   _std :  0.179\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2568.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  154\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.13000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.59000 -0.83000]\n",
      " done   :  False\n",
      "   _std :  0.178\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4296.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  155\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.00000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.86000 -0.23000]\n",
      " done   :  False\n",
      "   _std :  0.177\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2477.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  156\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.70000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.07000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.176\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2159.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  157\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.45000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.58000 -0.25000]\n",
      " done   :  False\n",
      "   _std :  0.175\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3056.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  158\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.24000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.73000 0.77000]\n",
      " done   :  False\n",
      "   _std :  0.174\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3364.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  159\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.42000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.36000 -0.33000]\n",
      " done   :  False\n",
      "   _std :  0.173\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6178.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  160\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.57000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.86000 0.97000]\n",
      " done   :  False\n",
      "   _std :  0.172\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3177.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  161\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.81000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.37000 -0.97000]\n",
      " done   :  False\n",
      "   _std :  0.172\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5248.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  162\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.01000 0.99000]\n",
      " done   :  False\n",
      "   _std :  0.171\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3099.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  163\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.17000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.34000 0.60000]\n",
      " done   :  False\n",
      "   _std :  0.17\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2374.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  164\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.34000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.78000 0.98000]\n",
      " done   :  False\n",
      "   _std :  0.169\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2585.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  165\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.55000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.73000 -0.25000]\n",
      " done   :  False\n",
      "   _std :  0.168\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2149.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  166\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.25000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.61000 -0.74000]\n",
      " done   :  False\n",
      "   _std :  0.167\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2691.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  167\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.17000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.81000 0.50000]\n",
      " done   :  False\n",
      "   _std :  0.166\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5479.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  168\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.54000 0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.08000 -0.73000]\n",
      " done   :  False\n",
      "   _std :  0.166\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7485.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  169\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.38000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.21000 0.84000]\n",
      " done   :  False\n",
      "   _std :  0.165\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2885.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  170\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.14000 0.98000]\n",
      " done   :  False\n",
      "   _std :  0.164\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2379.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  171\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.44000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.23000 -0.50000]\n",
      " done   :  False\n",
      "   _std :  0.163\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3996.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  172\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.06000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.13000 -0.32000]\n",
      " done   :  False\n",
      "   _std :  0.162\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2910.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  173\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.58000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.76000 0.82000]\n",
      " done   :  False\n",
      "   _std :  0.162\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2842.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  174\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.55000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.33000]\n",
      " done   :  False\n",
      "   _std :  0.161\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2858.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  175\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.82000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.65000 0.23000]\n",
      " done   :  False\n",
      "   _std :  0.16\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3209.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  176\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.02000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.34000 0.16000]\n",
      " done   :  False\n",
      "   _std :  0.159\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4906.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  177\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.82000 -0.97000]\n",
      " done   :  False\n",
      "   _std :  0.158\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2801.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  178\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.46000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.76000 -1.11000]\n",
      " done   :  False\n",
      "   _std :  0.158\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2852.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  179\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.34000 0.63000]\n",
      " done   :  False\n",
      "   _std :  0.157\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2178.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  180\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.83000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.84000 -0.08000]\n",
      " done   :  False\n",
      "   _std :  0.156\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4830.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  181\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.99000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.96000 -1.08000]\n",
      " done   :  False\n",
      "   _std :  0.156\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7869.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  182\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.08000 -0.21000]\n",
      " done   :  False\n",
      "   _std :  0.155\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3288.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  183\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.35000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.28000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.154\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6700.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  184\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.11000 0.41000]\n",
      " done   :  False\n",
      "   _std :  0.153\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4129.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  185\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.35000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.11000 0.72000]\n",
      " done   :  False\n",
      "   _std :  0.153\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6882.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  186\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.47000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.51000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.152\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2752.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  187\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.37000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.10000 -0.56000]\n",
      " done   :  False\n",
      "   _std :  0.151\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3518.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  188\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.39000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.24000 0.38000]\n",
      " done   :  False\n",
      "   _std :  0.151\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2687.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  189\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.25000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.67000 0.24000]\n",
      " done   :  False\n",
      "   _std :  0.15\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -11036.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  190\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.83000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.93000 -0.16000]\n",
      " done   :  False\n",
      "   _std :  0.149\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2397.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  191\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.65000 0.55000]\n",
      " done   :  False\n",
      "   _std :  0.149\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3955.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  192\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.74000 0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.82000 -1.06000]\n",
      " done   :  False\n",
      "   _std :  0.148\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8482.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  193\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.68000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.60000 0.39000]\n",
      " done   :  False\n",
      "   _std :  0.147\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3845.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  194\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.98000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.69000 0.33000]\n",
      " done   :  False\n",
      "   _std :  0.147\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2770.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  195\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.67000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.37000 0.08000]\n",
      " done   :  False\n",
      "   _std :  0.146\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7061.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  196\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.20000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.99000 0.42000]\n",
      " done   :  False\n",
      "   _std :  0.145\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2087.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  197\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.88000 0.64000]\n",
      " done   :  False\n",
      "   _std :  0.145\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2453.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  198\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.07000 0.66000]\n",
      " done   :  False\n",
      "   _std :  0.144\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2276.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  199\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.22000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.65000 -0.61000]\n",
      " done   :  False\n",
      "   _std :  0.143\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3860.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  200\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.32000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.36000 0.38000]\n",
      " done   :  False\n",
      "   _std :  0.143\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2661.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  201\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.22000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.15000 0.97000]\n",
      " done   :  False\n",
      "   _std :  0.142\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4244.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  202\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.09000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.14000 0.78000]\n",
      " done   :  False\n",
      "   _std :  0.142\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2064.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  203\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.40000 1.09000]\n",
      " done   :  False\n",
      "   _std :  0.141\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3834.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  204\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.14000 -0.47000]\n",
      " done   :  False\n",
      "   _std :  0.14\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3968.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  205\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.87000 0.70000]\n",
      " done   :  True\n",
      "   _std :  0.14\n",
      "episode length :  963\n",
      "\n",
      "Episode reward :  -1825.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  206\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.17000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.68000 -0.82000]\n",
      " done   :  False\n",
      "   _std :  0.139\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7259.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  207\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.04000 -0.06000]\n",
      " done   :  False\n",
      "   _std :  0.139\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4466.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  208\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.21000 0.82000]\n",
      " done   :  False\n",
      "   _std :  0.138\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5038.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  209\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.75000 -0.23000]\n",
      " done   :  True\n",
      "   _std :  0.138\n",
      "episode length :  880\n",
      "\n",
      "Episode reward :  -1541.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  210\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.14000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.59000 0.75000]\n",
      " done   :  False\n",
      "   _std :  0.137\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4308.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  211\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.81000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.56000 -0.25000]\n",
      " done   :  False\n",
      "   _std :  0.136\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5245.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  212\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.24000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.99000 1.02000]\n",
      " done   :  False\n",
      "   _std :  0.136\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2759.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  213\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.67000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.99000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.135\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8122.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  214\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.56000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.87000 -0.37000]\n",
      " done   :  False\n",
      "   _std :  0.135\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6597.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  215\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.24000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.46000 0.78000]\n",
      " done   :  False\n",
      "   _std :  0.134\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3724.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  216\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.15000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.77000 -1.16000]\n",
      " done   :  False\n",
      "   _std :  0.134\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2339.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  217\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.31000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.04000 0.62000]\n",
      " done   :  False\n",
      "   _std :  0.133\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5923.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  218\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.52000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.88000 -0.29000]\n",
      " done   :  False\n",
      "   _std :  0.133\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4146.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  219\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.53000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.84000 -0.14000]\n",
      " done   :  False\n",
      "   _std :  0.132\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3581.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  220\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.72000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.43000 0.98000]\n",
      " done   :  False\n",
      "   _std :  0.132\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4666.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  221\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.10000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.83000 0.38000]\n",
      " done   :  False\n",
      "   _std :  0.131\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4267.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  222\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.58000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.45000 0.87000]\n",
      " done   :  False\n",
      "   _std :  0.131\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2176.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  223\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.14000 0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.75000 0.58000]\n",
      " done   :  False\n",
      "   _std :  0.13\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7733.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  224\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.60000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.45000]\n",
      " done   :  False\n",
      "   _std :  0.13\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3957.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  225\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.06000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 1.03000]\n",
      " done   :  False\n",
      "   _std :  0.129\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3757.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  226\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.27000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.05000 -0.73000]\n",
      " done   :  False\n",
      "   _std :  0.129\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2107.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  227\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.28000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.58000 0.35000]\n",
      " done   :  False\n",
      "   _std :  0.128\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2856.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  228\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.19000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.21000 -1.01000]\n",
      " done   :  False\n",
      "   _std :  0.128\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4371.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  229\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.31000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.19000 0.15000]\n",
      " done   :  False\n",
      "   _std :  0.127\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2603.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  230\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.86000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.47000 1.02000]\n",
      " done   :  False\n",
      "   _std :  0.127\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2541.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  231\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.17000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.56000 -0.91000]\n",
      " done   :  False\n",
      "   _std :  0.126\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3326.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  232\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.30000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.05000 -1.07000]\n",
      " done   :  False\n",
      "   _std :  0.126\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2060.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  233\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.58000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.68000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.125\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2474.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  234\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.40000 0.70000]\n",
      " done   :  False\n",
      "   _std :  0.125\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1271.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  235\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.25000 -0.46000]\n",
      " done   :  False\n",
      "   _std :  0.124\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4658.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  236\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.01000 0.29000]\n",
      " done   :  False\n",
      "   _std :  0.124\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2975.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  237\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.11000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.22000 -1.11000]\n",
      " done   :  False\n",
      "   _std :  0.123\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1823.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  238\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.70000 -0.26000]\n",
      " done   :  False\n",
      "   _std :  0.123\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2283.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  239\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.59000 -0.38000]\n",
      " done   :  False\n",
      "   _std :  0.122\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4409.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  240\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.59000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.64000 0.20000]\n",
      " done   :  False\n",
      "   _std :  0.122\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4592.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  241\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.18000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.76000 -0.66000]\n",
      " done   :  False\n",
      "   _std :  0.122\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6688.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  242\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.68000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.20000 0.58000]\n",
      " done   :  False\n",
      "   _std :  0.121\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2097.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  243\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.25000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.74000 -1.13000]\n",
      " done   :  False\n",
      "   _std :  0.121\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2893.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  244\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.09000 1.07000]\n",
      " done   :  False\n",
      "   _std :  0.12\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2871.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  245\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.67000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.95000 0.94000]\n",
      " done   :  False\n",
      "   _std :  0.12\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3417.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  246\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.70000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.56000 0.15000]\n",
      " done   :  False\n",
      "   _std :  0.119\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2959.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  247\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.23000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.71000 -0.13000]\n",
      " done   :  False\n",
      "   _std :  0.119\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3518.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  248\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.08000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.77000 0.62000]\n",
      " done   :  False\n",
      "   _std :  0.118\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3769.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  249\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.47000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.54000 -1.00000]\n",
      " done   :  False\n",
      "   _std :  0.118\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4130.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  250\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.38000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.90000 -0.39000]\n",
      " done   :  False\n",
      "   _std :  0.118\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3597.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  251\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.36000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.91000 0.96000]\n",
      " done   :  False\n",
      "   _std :  0.117\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3216.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  252\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.31000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.03000 -0.04000]\n",
      " done   :  False\n",
      "   _std :  0.117\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4670.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  253\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.55000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.49000 -0.46000]\n",
      " done   :  False\n",
      "   _std :  0.116\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6620.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  254\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.79000 1.06000]\n",
      " done   :  True\n",
      "   _std :  0.116\n",
      "episode length :  858\n",
      "\n",
      "Episode reward :  -3750.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  255\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.55000 -0.73000]\n",
      " done   :  False\n",
      "   _std :  0.116\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6531.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  256\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.07000 0.40000]\n",
      " done   :  False\n",
      "   _std :  0.115\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4163.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  257\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.08000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.88000 0.19000]\n",
      " done   :  False\n",
      "   _std :  0.115\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3523.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  258\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.45000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.08000 0.96000]\n",
      " done   :  False\n",
      "   _std :  0.114\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4305.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  259\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.06000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.77000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.114\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5032.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  260\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.44000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.64000 -0.69000]\n",
      " done   :  False\n",
      "   _std :  0.114\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5293.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  261\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.63000 0.48000]\n",
      " done   :  False\n",
      "   _std :  0.113\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2856.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  262\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.05000 -0.20000]\n",
      " done   :  False\n",
      "   _std :  0.113\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2520.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  263\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.36000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.64000 -0.80000]\n",
      " done   :  False\n",
      "   _std :  0.112\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3496.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  264\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.21000 -0.97000]\n",
      " done   :  False\n",
      "   _std :  0.112\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5101.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  265\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.23000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.95000 0.38000]\n",
      " done   :  False\n",
      "   _std :  0.112\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4971.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  266\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.59000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.15000 1.14000]\n",
      " done   :  False\n",
      "   _std :  0.111\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3999.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  267\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.31000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.84000 -0.50000]\n",
      " done   :  False\n",
      "   _std :  0.111\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4247.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  268\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.85000 -0.26000]\n",
      " done   :  False\n",
      "   _std :  0.111\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2700.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  269\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.89000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.68000 0.49000]\n",
      " done   :  False\n",
      "   _std :  0.11\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4732.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  270\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.20000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.94000 -0.15000]\n",
      " done   :  False\n",
      "   _std :  0.11\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5316.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  271\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.74000 0.09000]\n",
      " done   :  False\n",
      "   _std :  0.11\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3841.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  272\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.67000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.97000 -0.44000]\n",
      " done   :  False\n",
      "   _std :  0.109\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2183.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  273\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.31000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.01000 0.90000]\n",
      " done   :  False\n",
      "   _std :  0.109\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3310.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  274\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.59000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.57000 -0.38000]\n",
      " done   :  False\n",
      "   _std :  0.108\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2871.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  275\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.46000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.75000 -0.37000]\n",
      " done   :  False\n",
      "   _std :  0.108\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3387.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  276\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.99000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.69000 0.47000]\n",
      " done   :  False\n",
      "   _std :  0.108\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4553.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  277\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.43000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.81000 -0.88000]\n",
      " done   :  False\n",
      "   _std :  0.107\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2098.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  278\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.15000 0.98000]\n",
      " done   :  False\n",
      "   _std :  0.107\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3873.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  279\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.32000 -0.94000]\n",
      " done   :  False\n",
      "   _std :  0.107\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6485.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  280\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.46000 0.82000]\n",
      " done   :  False\n",
      "   _std :  0.106\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2580.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  281\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.42000 0.93000]\n",
      " done   :  False\n",
      "   _std :  0.106\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2680.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  282\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.62000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.53000 -0.58000]\n",
      " done   :  False\n",
      "   _std :  0.106\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4181.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  283\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.15000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.26000]\n",
      " done   :  False\n",
      "   _std :  0.105\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7501.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  284\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.40000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.15000 -0.51000]\n",
      " done   :  False\n",
      "   _std :  0.105\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5503.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  285\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.53000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.13000 -0.85000]\n",
      " done   :  False\n",
      "   _std :  0.105\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3658.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  286\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.19000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 0.55000]\n",
      " done   :  False\n",
      "   _std :  0.104\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5244.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  287\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.57000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.83000 -0.48000]\n",
      " done   :  False\n",
      "   _std :  0.104\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3491.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  288\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.71000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.98000 0.12000]\n",
      " done   :  False\n",
      "   _std :  0.104\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2775.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  289\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.43000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.80000 -0.63000]\n",
      " done   :  False\n",
      "   _std :  0.103\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3972.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  290\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.49000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.81000 0.21000]\n",
      " done   :  False\n",
      "   _std :  0.103\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5227.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  291\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.62000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.26000 0.96000]\n",
      " done   :  False\n",
      "   _std :  0.103\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6217.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  292\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.42000 0.57000]\n",
      " done   :  False\n",
      "   _std :  0.102\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3628.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  293\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.03000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.94000 0.40000]\n",
      " done   :  False\n",
      "   _std :  0.102\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2919.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  294\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.50000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.102\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2360.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  295\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.57000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.37000 -0.75000]\n",
      " done   :  False\n",
      "   _std :  0.102\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6397.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  296\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.84000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.22000 0.80000]\n",
      " done   :  False\n",
      "   _std :  0.101\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3577.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  297\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.44000 0.43000]\n",
      " done   :  False\n",
      "   _std :  0.101\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5841.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  298\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.24000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.61000 -0.67000]\n",
      " done   :  False\n",
      "   _std :  0.101\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5380.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  299\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.55000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.70000 -0.28000]\n",
      " done   :  False\n",
      "   _std :  0.1\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3610.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  300\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.70000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.70000 -0.12000]\n",
      " done   :  False\n",
      "   _std :  0.1\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4848.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  301\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.54000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.80000 -0.70000]\n",
      " done   :  False\n",
      "   _std :  0.1\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3558.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  302\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.56000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.50000 -0.77000]\n",
      " done   :  False\n",
      "   _std :  0.099\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2638.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  303\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.06000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.18000 0.70000]\n",
      " done   :  False\n",
      "   _std :  0.099\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3009.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  304\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.01000 -0.71000]\n",
      " done   :  False\n",
      "   _std :  0.099\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2059.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  305\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.53000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.36000 1.10000]\n",
      " done   :  False\n",
      "   _std :  0.099\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2350.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  306\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.69000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.71000 0.55000]\n",
      " done   :  False\n",
      "   _std :  0.098\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2272.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  307\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.21000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.92000 -0.60000]\n",
      " done   :  False\n",
      "   _std :  0.098\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6007.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  308\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.25000 0.13000]\n",
      " done   :  False\n",
      "   _std :  0.098\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6070.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  309\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.64000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.76000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.097\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6160.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  310\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.22000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.11000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.097\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3331.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  311\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.63000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.59000 0.24000]\n",
      " done   :  False\n",
      "   _std :  0.097\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2433.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  312\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.18000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.55000 -0.32000]\n",
      " done   :  False\n",
      "   _std :  0.097\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3091.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  313\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.42000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.12000 -0.85000]\n",
      " done   :  False\n",
      "   _std :  0.096\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2639.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  314\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.43000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.97000 -0.27000]\n",
      " done   :  False\n",
      "   _std :  0.096\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3521.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  315\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.19000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.31000 0.89000]\n",
      " done   :  False\n",
      "   _std :  0.096\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3853.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  316\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.07000 -1.00000]\n",
      " done   :  False\n",
      "   _std :  0.095\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3774.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  317\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.15000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.34000 -1.01000]\n",
      " done   :  False\n",
      "   _std :  0.095\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3511.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  318\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.11000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.99000 1.13000]\n",
      " done   :  False\n",
      "   _std :  0.095\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3209.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  319\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.10000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.69000 1.05000]\n",
      " done   :  False\n",
      "   _std :  0.095\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2261.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  320\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.08000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.24000 -0.89000]\n",
      " done   :  False\n",
      "   _std :  0.094\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3198.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  321\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.93000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.93000 0.13000]\n",
      " done   :  False\n",
      "   _std :  0.094\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2985.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  322\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.33000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.63000 -0.55000]\n",
      " done   :  False\n",
      "   _std :  0.094\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2219.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  323\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.74000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.37000 0.79000]\n",
      " done   :  False\n",
      "   _std :  0.094\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3815.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  324\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.72000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.38000 0.17000]\n",
      " done   :  False\n",
      "   _std :  0.093\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9188.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  325\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.42000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.67000 1.03000]\n",
      " done   :  False\n",
      "   _std :  0.093\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3404.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  326\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.83000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.64000 -1.17000]\n",
      " done   :  False\n",
      "   _std :  0.093\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5830.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  327\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.66000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.20000 -0.27000]\n",
      " done   :  False\n",
      "   _std :  0.093\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2571.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  328\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.53000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.81000 -0.94000]\n",
      " done   :  False\n",
      "   _std :  0.092\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1895.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  329\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.59000 -0.11000]\n",
      " done   :  False\n",
      "   _std :  0.092\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6043.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  330\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.30000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.22000 0.85000]\n",
      " done   :  False\n",
      "   _std :  0.092\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3303.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  331\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.09000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.99000 0.70000]\n",
      " done   :  False\n",
      "   _std :  0.091\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1895.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  332\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.36000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.20000 1.08000]\n",
      " done   :  False\n",
      "   _std :  0.091\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2906.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  333\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.12000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.02000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.091\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3536.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  334\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.42000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.64000 1.02000]\n",
      " done   :  False\n",
      "   _std :  0.091\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2278.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  335\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.08000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.56000 -0.32000]\n",
      " done   :  False\n",
      "   _std :  0.09\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2202.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  336\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.53000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.59000 0.52000]\n",
      " done   :  False\n",
      "   _std :  0.09\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2210.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  337\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.49000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.38000 -0.91000]\n",
      " done   :  False\n",
      "   _std :  0.09\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2742.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  338\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.25000 0.81000]\n",
      " done   :  False\n",
      "   _std :  0.09\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1572.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  339\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.62000 -1.06000]\n",
      " done   :  False\n",
      "   _std :  0.09\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7997.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  340\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.06000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.05000 0.72000]\n",
      " done   :  False\n",
      "   _std :  0.089\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9314.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  341\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.98000 0.79000]\n",
      " done   :  False\n",
      "   _std :  0.089\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3599.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  342\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.08000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.95000 0.23000]\n",
      " done   :  False\n",
      "   _std :  0.089\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1925.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  343\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.97000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.089\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2050.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  344\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.60000 0.62000]\n",
      " done   :  False\n",
      "   _std :  0.088\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1826.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  345\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.46000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.89000 1.00000]\n",
      " done   :  False\n",
      "   _std :  0.088\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3231.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  346\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.66000 0.06000]\n",
      " done   :  False\n",
      "   _std :  0.088\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3348.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  347\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.34000 -0.15000]\n",
      " done   :  True\n",
      "   _std :  0.088\n",
      "episode length :  853\n",
      "\n",
      "Episode reward :  -1424.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  348\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.49000 0.94000]\n",
      " done   :  False\n",
      "   _std :  0.087\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2262.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  349\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.18000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.66000 1.10000]\n",
      " done   :  False\n",
      "   _std :  0.087\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3773.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  350\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.70000 0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.29000 -0.35000]\n",
      " done   :  False\n",
      "   _std :  0.087\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6098.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  351\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.36000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.83000 0.35000]\n",
      " done   :  False\n",
      "   _std :  0.087\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3644.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  352\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.60000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.09000 -0.38000]\n",
      " done   :  False\n",
      "   _std :  0.087\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4885.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  353\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.74000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.69000]\n",
      " done   :  False\n",
      "   _std :  0.086\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3674.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  354\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.18000 0.14000]\n",
      " done   :  False\n",
      "   _std :  0.086\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2452.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  355\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.52000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.70000 -0.07000]\n",
      " done   :  False\n",
      "   _std :  0.086\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2262.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  356\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.29000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.93000 -0.35000]\n",
      " done   :  False\n",
      "   _std :  0.086\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2986.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  357\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.54000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.62000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.085\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2076.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  358\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.53000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.30000 -0.27000]\n",
      " done   :  False\n",
      "   _std :  0.085\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3550.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  359\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.50000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.27000 -0.84000]\n",
      " done   :  False\n",
      "   _std :  0.085\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2193.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  360\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.09000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.99000 -0.40000]\n",
      " done   :  False\n",
      "   _std :  0.085\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3536.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  361\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.17000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.83000 0.62000]\n",
      " done   :  False\n",
      "   _std :  0.085\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2915.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  362\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.32000 -0.83000]\n",
      " done   :  False\n",
      "   _std :  0.084\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1781.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  363\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.59000 0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.74000 -0.35000]\n",
      " done   :  False\n",
      "   _std :  0.084\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6270.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  364\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.05000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.37000 0.93000]\n",
      " done   :  False\n",
      "   _std :  0.084\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3548.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  365\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.36000 1.09000]\n",
      " done   :  False\n",
      "   _std :  0.084\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3417.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  366\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.79000 -0.13000]\n",
      " done   :  False\n",
      "   _std :  0.083\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4542.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  367\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.02000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.74000 0.55000]\n",
      " done   :  False\n",
      "   _std :  0.083\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5718.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  368\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.42000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.18000 0.51000]\n",
      " done   :  False\n",
      "   _std :  0.083\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4477.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  369\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.98000 1.07000]\n",
      " done   :  False\n",
      "   _std :  0.083\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9313.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  370\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.29000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.58000 0.16000]\n",
      " done   :  False\n",
      "   _std :  0.083\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2816.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  371\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.40000 -0.19000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.21000 -0.73000]\n",
      " done   :  False\n",
      "   _std :  0.082\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10778.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  372\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.13000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.18000 -0.42000]\n",
      " done   :  False\n",
      "   _std :  0.082\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2950.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  373\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.32000 -0.09000]\n",
      " done   :  False\n",
      "   _std :  0.082\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2898.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  374\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.06000 0.32000]\n",
      " done   :  False\n",
      "   _std :  0.082\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3259.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  375\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.11000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.32000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.082\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4742.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  376\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.95000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.73000 -0.79000]\n",
      " done   :  False\n",
      "   _std :  0.081\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7200.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  377\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.97000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.081\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2341.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  378\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.26000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.94000 1.04000]\n",
      " done   :  False\n",
      "   _std :  0.081\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8354.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  379\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.21000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.69000 0.21000]\n",
      " done   :  False\n",
      "   _std :  0.081\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3364.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  380\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.77000 -1.16000]\n",
      " done   :  False\n",
      "   _std :  0.081\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2442.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  381\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.23000 1.16000]\n",
      " done   :  False\n",
      "   _std :  0.08\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6933.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  382\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.14000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.96000 0.19000]\n",
      " done   :  False\n",
      "   _std :  0.08\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3146.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  383\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.41000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.34000 -0.70000]\n",
      " done   :  False\n",
      "   _std :  0.08\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3033.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  384\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.26000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.11000 0.43000]\n",
      " done   :  False\n",
      "   _std :  0.08\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1802.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  385\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.37000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.61000 -1.09000]\n",
      " done   :  False\n",
      "   _std :  0.08\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4158.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  386\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.10000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.83000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.079\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2238.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  387\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.74000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.25000 -0.21000]\n",
      " done   :  False\n",
      "   _std :  0.079\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3927.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  388\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.88000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.09000 -1.06000]\n",
      " done   :  False\n",
      "   _std :  0.079\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1386.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  389\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.60000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.82000 1.06000]\n",
      " done   :  False\n",
      "   _std :  0.079\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2745.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  390\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.94000 1.09000]\n",
      " done   :  False\n",
      "   _std :  0.079\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1861.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  391\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.41000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.27000 1.12000]\n",
      " done   :  False\n",
      "   _std :  0.079\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2104.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  392\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.44000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.04000 -0.48000]\n",
      " done   :  False\n",
      "   _std :  0.078\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3559.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  393\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.20000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.24000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.078\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3913.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  394\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.49000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.28000 -1.07000]\n",
      " done   :  False\n",
      "   _std :  0.078\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4565.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  395\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.58000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.87000 -0.69000]\n",
      " done   :  False\n",
      "   _std :  0.078\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3488.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  396\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.75000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.59000 -0.03000]\n",
      " done   :  False\n",
      "   _std :  0.078\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5221.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  397\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.61000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.30000 0.49000]\n",
      " done   :  False\n",
      "   _std :  0.077\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2376.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  398\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.40000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.05000 0.25000]\n",
      " done   :  False\n",
      "   _std :  0.077\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6583.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  399\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.96000 0.12000]\n",
      " done   :  False\n",
      "   _std :  0.077\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4236.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  400\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.49000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.55000 0.85000]\n",
      " done   :  False\n",
      "   _std :  0.077\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3364.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  401\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.16000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.65000 -0.94000]\n",
      " done   :  False\n",
      "   _std :  0.077\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3467.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  402\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.48000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.62000 -0.38000]\n",
      " done   :  False\n",
      "   _std :  0.077\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2596.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  403\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.84000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.13000 -0.49000]\n",
      " done   :  False\n",
      "   _std :  0.076\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3674.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  404\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.94000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.68000 0.35000]\n",
      " done   :  False\n",
      "   _std :  0.076\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2403.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  405\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.51000 0.64000]\n",
      " done   :  False\n",
      "   _std :  0.076\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3763.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  406\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.86000 -0.11000]\n",
      " done   :  False\n",
      "   _std :  0.076\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4317.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  407\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.32000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.57000 0.54000]\n",
      " done   :  False\n",
      "   _std :  0.076\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1806.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  408\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.65000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.52000 1.08000]\n",
      " done   :  False\n",
      "   _std :  0.076\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6724.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  409\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.25000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.42000 -0.59000]\n",
      " done   :  False\n",
      "   _std :  0.075\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2966.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  410\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.56000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.59000 -0.88000]\n",
      " done   :  False\n",
      "   _std :  0.075\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2732.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  411\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.55000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.24000 -0.24000]\n",
      " done   :  False\n",
      "   _std :  0.075\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3294.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  412\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.11000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.28000 0.61000]\n",
      " done   :  False\n",
      "   _std :  0.075\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5120.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  413\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.88000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.44000 -0.66000]\n",
      " done   :  False\n",
      "   _std :  0.075\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6315.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  414\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.39000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.66000 -0.26000]\n",
      " done   :  False\n",
      "   _std :  0.075\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5040.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  415\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.16000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.60000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.074\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2403.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  416\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.48000 -0.63000]\n",
      " done   :  False\n",
      "   _std :  0.074\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4138.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  417\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.67000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.61000 -0.62000]\n",
      " done   :  False\n",
      "   _std :  0.074\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3495.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  418\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.58000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.54000 1.03000]\n",
      " done   :  False\n",
      "   _std :  0.074\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3141.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  419\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.16000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.88000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.074\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2192.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  420\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.34000 -0.21000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.19000 0.15000]\n",
      " done   :  False\n",
      "   _std :  0.074\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9639.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  421\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.65000 -1.12000]\n",
      " done   :  False\n",
      "   _std :  0.073\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5071.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  422\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.61000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.58000 1.07000]\n",
      " done   :  False\n",
      "   _std :  0.073\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6938.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  423\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.57000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.12000 -0.55000]\n",
      " done   :  False\n",
      "   _std :  0.073\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3217.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  424\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.57000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.49000 -0.23000]\n",
      " done   :  False\n",
      "   _std :  0.073\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4650.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  425\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.56000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.53000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.073\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4083.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  426\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.44000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.50000 0.51000]\n",
      " done   :  False\n",
      "   _std :  0.073\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3484.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  427\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.22000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.88000 -0.27000]\n",
      " done   :  False\n",
      "   _std :  0.072\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2289.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  428\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.19000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.33000 -0.37000]\n",
      " done   :  False\n",
      "   _std :  0.072\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2890.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  429\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.66000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.90000 0.39000]\n",
      " done   :  False\n",
      "   _std :  0.072\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2896.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  430\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.10000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.09000 0.98000]\n",
      " done   :  False\n",
      "   _std :  0.072\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4363.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  431\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.08000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.99000 0.79000]\n",
      " done   :  False\n",
      "   _std :  0.072\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5147.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  432\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.32000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.61000 0.44000]\n",
      " done   :  False\n",
      "   _std :  0.072\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1802.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  433\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.12000 -0.30000]\n",
      " done   :  False\n",
      "   _std :  0.071\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4270.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  434\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.74000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.16000 -0.45000]\n",
      " done   :  False\n",
      "   _std :  0.071\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2653.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  435\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.22000 0.33000]\n",
      " done   :  False\n",
      "   _std :  0.071\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2308.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  436\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.69000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.05000 -0.85000]\n",
      " done   :  False\n",
      "   _std :  0.071\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3800.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  437\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.12000 0.22000]\n",
      " done   :  False\n",
      "   _std :  0.071\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2403.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  438\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.38000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.38000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.071\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2949.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  439\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.27000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.78000 -0.03000]\n",
      " done   :  False\n",
      "   _std :  0.071\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2770.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  440\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.28000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.70000 -0.90000]\n",
      " done   :  False\n",
      "   _std :  0.07\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3762.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  441\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.19000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.12000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.07\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2232.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  442\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.61000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.18000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.07\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2264.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  443\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.62000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.46000 -0.16000]\n",
      " done   :  False\n",
      "   _std :  0.07\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4208.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  444\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.35000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.68000 0.64000]\n",
      " done   :  False\n",
      "   _std :  0.07\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3208.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  445\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.65000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.24000 0.33000]\n",
      " done   :  False\n",
      "   _std :  0.07\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3273.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  446\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.91000 0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.88000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.07\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6958.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  447\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.069\n",
      "episode length :  957\n",
      "\n",
      "Episode reward :  -3060.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  448\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.36000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.54000 0.34000]\n",
      " done   :  False\n",
      "   _std :  0.069\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3859.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  449\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.14000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.54000 0.51000]\n",
      " done   :  False\n",
      "   _std :  0.069\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2552.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  450\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.14000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.95000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.069\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3094.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  451\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 -0.23000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.84000 -0.75000]\n",
      " done   :  False\n",
      "   _std :  0.069\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -18021.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  452\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.90000 -1.02000]\n",
      " done   :  False\n",
      "   _std :  0.069\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6471.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  453\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.78000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.92000 0.53000]\n",
      " done   :  False\n",
      "   _std :  0.069\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4423.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  454\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.74000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.79000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.068\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4661.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  455\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.89000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.67000 1.06000]\n",
      " done   :  False\n",
      "   _std :  0.068\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5452.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  456\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.28000 0.90000]\n",
      " done   :  False\n",
      "   _std :  0.068\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2816.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  457\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.48000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.45000 1.03000]\n",
      " done   :  False\n",
      "   _std :  0.068\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4627.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  458\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.33000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.50000 0.22000]\n",
      " done   :  False\n",
      "   _std :  0.068\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7824.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  459\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.07000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.76000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.068\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1841.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  460\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.93000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.28000 0.61000]\n",
      " done   :  False\n",
      "   _std :  0.068\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3648.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  461\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.08000 -1.00000]\n",
      " done   :  False\n",
      "   _std :  0.067\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1920.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  462\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.12000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.76000 -0.99000]\n",
      " done   :  False\n",
      "   _std :  0.067\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4644.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  463\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.16000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.68000 -1.00000]\n",
      " done   :  False\n",
      "   _std :  0.067\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1969.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  464\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.02000 1.02000]\n",
      " done   :  False\n",
      "   _std :  0.067\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3170.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  465\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.39000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.53000 -0.36000]\n",
      " done   :  False\n",
      "   _std :  0.067\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5168.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  466\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.31000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.57000 -0.50000]\n",
      " done   :  False\n",
      "   _std :  0.067\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1998.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  467\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.75000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.86000 -0.60000]\n",
      " done   :  False\n",
      "   _std :  0.067\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3716.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  468\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.95000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.45000 0.61000]\n",
      " done   :  False\n",
      "   _std :  0.066\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3296.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  469\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.75000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.26000 -0.39000]\n",
      " done   :  False\n",
      "   _std :  0.066\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3130.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  470\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.94000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.98000 1.06000]\n",
      " done   :  False\n",
      "   _std :  0.066\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2311.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  471\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-2.01000 -0.25000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.21000 -0.90000]\n",
      " done   :  False\n",
      "   _std :  0.066\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -12618.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  472\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.57000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.51000 -0.21000]\n",
      " done   :  False\n",
      "   _std :  0.066\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2408.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  473\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.14000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.03000 0.06000]\n",
      " done   :  False\n",
      "   _std :  0.066\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3913.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  474\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.58000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.96000 0.98000]\n",
      " done   :  False\n",
      "   _std :  0.066\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3087.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  475\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.20000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.94000 0.31000]\n",
      " done   :  False\n",
      "   _std :  0.066\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3169.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  476\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.58000 -0.86000]\n",
      " done   :  False\n",
      "   _std :  0.065\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1372.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  477\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.19000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.14000 -0.90000]\n",
      " done   :  False\n",
      "   _std :  0.065\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3457.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  478\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.19000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.89000 0.12000]\n",
      " done   :  False\n",
      "   _std :  0.065\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8774.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  479\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.61000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.73000 -0.26000]\n",
      " done   :  False\n",
      "   _std :  0.065\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2816.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  480\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.06000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.14000 1.05000]\n",
      " done   :  False\n",
      "   _std :  0.065\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2834.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  481\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.63000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.42000 0.06000]\n",
      " done   :  False\n",
      "   _std :  0.065\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2360.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  482\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.42000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.03000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.065\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2285.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  483\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.14000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.33000 -1.02000]\n",
      " done   :  False\n",
      "   _std :  0.065\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2429.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  484\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.08000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.35000]\n",
      " done   :  False\n",
      "   _std :  0.064\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2960.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  485\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.72000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.064\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7308.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  486\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.73000 -0.70000]\n",
      " done   :  False\n",
      "   _std :  0.064\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3917.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  487\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.50000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.16000 -0.45000]\n",
      " done   :  False\n",
      "   _std :  0.064\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2469.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  488\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.25000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.92000 -0.38000]\n",
      " done   :  False\n",
      "   _std :  0.064\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4597.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  489\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.17000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.50000 0.86000]\n",
      " done   :  False\n",
      "   _std :  0.064\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1531.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  490\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.36000 0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.84000 -0.31000]\n",
      " done   :  False\n",
      "   _std :  0.064\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5671.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  491\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.95000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.28000 0.95000]\n",
      " done   :  False\n",
      "   _std :  0.064\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4388.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  492\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.33000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.19000 0.29000]\n",
      " done   :  False\n",
      "   _std :  0.063\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6721.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  493\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.23000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.13000 -1.02000]\n",
      " done   :  False\n",
      "   _std :  0.063\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2578.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  494\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.57000 0.54000]\n",
      " done   :  False\n",
      "   _std :  0.063\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4100.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  495\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.13000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.41000 -0.25000]\n",
      " done   :  False\n",
      "   _std :  0.063\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2383.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  496\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.00000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.88000 -0.68000]\n",
      " done   :  False\n",
      "   _std :  0.063\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3315.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  497\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.08000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.97000 -0.86000]\n",
      " done   :  False\n",
      "   _std :  0.063\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3419.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  498\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.16000]\n",
      " done   :  False\n",
      "   _std :  0.063\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2543.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  499\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.78000 -0.17000]\n",
      " done   :  False\n",
      "   _std :  0.063\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3151.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  500\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.28000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.84000 -1.10000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6155.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  501\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.70000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.76000 0.95000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5766.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  502\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.23000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.07000 0.10000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4135.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  503\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.38000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.76000 0.21000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2543.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  504\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.32000 -0.53000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2777.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  505\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.68000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.08000 0.99000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2327.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  506\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.25000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.68000 0.95000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5054.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  507\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.98000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.30000 -0.71000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2892.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  508\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.82000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.32000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.062\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5145.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  509\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.68000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.63000 0.24000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3430.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  510\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.75000 0.18000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7141.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  511\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.47000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.85000 -0.14000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4878.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  512\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.41000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.87000 0.49000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2066.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  513\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.88000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 -0.88000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3742.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  514\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.33000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.39000 -0.30000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3433.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  515\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.07000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.32000 0.76000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2460.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  516\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.10000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.92000 0.72000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1942.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  517\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.52000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.69000 0.54000]\n",
      " done   :  False\n",
      "   _std :  0.061\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2694.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  518\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.09000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.96000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2485.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  519\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.94000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.19000 0.20000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5898.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  520\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.18000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.91000 0.97000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4709.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  521\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.30000 0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.55000 0.76000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8874.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  522\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.22000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.66000 0.06000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2222.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  523\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.83000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.10000 -1.00000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3084.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  524\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.22000 0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.56000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6828.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  525\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.62000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.92000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2521.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  526\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.25000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.97000 -0.55000]\n",
      " done   :  False\n",
      "   _std :  0.06\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2258.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  527\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.46000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.48000 1.10000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4975.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  528\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.45000 -0.40000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2880.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  529\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.18000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.97000 0.21000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1519.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  530\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.48000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.05000 -0.86000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2561.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  531\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.14000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.01000 -1.08000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2629.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  532\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.56000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.61000 1.13000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2368.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  533\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.97000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.81000 -0.06000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4130.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  534\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.44000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4550.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  535\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.48000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.80000 0.15000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2648.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  536\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.58000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.35000 0.31000]\n",
      " done   :  False\n",
      "   _std :  0.059\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5047.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  537\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.36000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.82000 0.30000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4722.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  538\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.82000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.72000 -0.07000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3464.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  539\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.60000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.85000 1.06000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3686.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  540\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.38000 0.79000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2108.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  541\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.14000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.55000 -0.66000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3730.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  542\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.07000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.61000 -1.06000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5591.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  543\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.15000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.03000 -0.27000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1798.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  544\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.40000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.56000 1.00000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2358.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  545\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.26000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.71000 0.71000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2593.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  546\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.07000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.96000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.058\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3706.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  547\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.33000 0.49000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3023.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  548\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.32000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.17000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2055.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  549\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.26000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.36000 -0.35000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1505.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  550\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.14000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.12000 0.15000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4297.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  551\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.19000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.99000 0.73000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5456.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  552\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.74000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.82000 0.94000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5011.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  553\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.66000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.25000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3905.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  554\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.46000 -0.36000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5619.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  555\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.03000 -0.57000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2696.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  556\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.74000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.57000 0.53000]\n",
      " done   :  False\n",
      "   _std :  0.057\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4850.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  557\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.23000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4252.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  558\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.33000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.38000 1.13000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3553.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  559\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.30000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.38000 -0.96000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2775.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  560\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.17000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.14000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3867.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  561\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.84000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.46000 0.20000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3195.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  562\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.48000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.09000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4038.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  563\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.55000 -0.16000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.25000 0.18000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5724.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  564\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.51000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.15000 0.30000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4326.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  565\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.82000 -0.86000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3884.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  566\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.47000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.54000 1.03000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3169.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  567\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.42000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.61000 0.09000]\n",
      " done   :  False\n",
      "   _std :  0.056\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4765.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  568\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.64000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.22000 -0.34000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2924.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  569\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.22000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.27000 0.56000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2745.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  570\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.36000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.32000 0.63000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3676.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  571\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.23000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.47000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3606.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  572\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.81000 -0.91000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2820.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  573\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.47000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.50000 -0.81000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3815.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  574\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.21000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.44000 0.18000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4355.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  575\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.46000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.09000 0.64000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5974.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  576\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.32000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.25000 0.31000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3698.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  577\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.29000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.73000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -11323.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  578\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.90000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.14000 0.90000]\n",
      " done   :  False\n",
      "   _std :  0.055\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4738.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  579\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.92000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3543.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  580\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.12000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.08000 -0.22000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3753.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  581\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.26000 -0.22000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.61000 0.87000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -11482.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  582\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.46000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.43000 0.52000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6420.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  583\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.44000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.37000 0.68000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4073.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  584\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.37000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.15000 0.63000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5066.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  585\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.55000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.42000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3725.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  586\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.86000 0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.32000 1.09000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -13495.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  587\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.43000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.25000 -1.14000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3377.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  588\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.31000]\n",
      " done   :  True\n",
      "   _std :  0.054\n",
      "episode length :  961\n",
      "\n",
      "Episode reward :  -3322.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  589\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.46000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.50000 -0.14000]\n",
      " done   :  False\n",
      "   _std :  0.054\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3770.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  590\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.46000 0.63000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1778.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  591\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.07000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.72000 0.11000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2581.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  592\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.15000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.51000 -0.59000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6474.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  593\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.74000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.38000 -0.28000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3346.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  594\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.09000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.76000 0.73000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7030.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  595\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.22000 0.67000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5605.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  596\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.33000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.60000 -0.22000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2411.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  597\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.27000 -0.39000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3769.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  598\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.59000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3116.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  599\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.78000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.81000 0.91000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3332.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  600\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.98000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.60000 0.99000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5004.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  601\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.52000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.09000 0.47000]\n",
      " done   :  False\n",
      "   _std :  0.053\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2616.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  602\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.19000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.90000 -0.92000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7422.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  603\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.23000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.03000 -1.16000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2560.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  604\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.32000 0.77000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2040.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  605\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.77000 0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.91000 -1.14000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10096.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  606\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.31000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.33000 -0.28000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3130.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  607\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.26000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.00000 -0.84000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7803.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  608\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.21000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.09000 -1.06000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7432.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  609\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.92000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.15000 0.46000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3980.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  610\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.39000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.62000 0.98000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4414.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  611\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.31000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.80000 -0.68000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4181.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  612\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.41000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.73000 -0.54000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2275.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  613\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.70000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.92000 -0.61000]\n",
      " done   :  False\n",
      "   _std :  0.052\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2068.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  614\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.72000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.56000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2787.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  615\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.88000 -0.36000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2650.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  616\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.75000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.10000 0.19000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2849.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  617\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.09000 1.02000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4868.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  618\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.99000 -0.36000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2609.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  619\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.55000 0.33000]\n",
      " done   :  True\n",
      "   _std :  0.051\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -2686.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  620\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.19000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.51000 -0.14000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2701.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  621\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.08000 -0.66000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3276.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  622\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.49000 -0.21000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6447.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  623\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.37000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.12000 0.19000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5202.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  624\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.79000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.69000 0.31000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4068.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  625\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.37000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2664.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  626\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.83000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.92000 -0.42000]\n",
      " done   :  False\n",
      "   _std :  0.051\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2690.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  627\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.43000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.70000 0.34000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3168.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  628\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.24000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.16000 1.12000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2250.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  629\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.66000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.10000 0.70000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2801.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  630\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.17000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.77000 0.27000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4395.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  631\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.35000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3636.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  632\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.32000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.68000 0.52000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2236.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  633\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.20000 0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.64000 0.87000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6286.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  634\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.92000 0.71000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1462.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  635\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.06000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.85000 0.56000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7020.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  636\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.08000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 -0.46000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6261.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  637\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.66000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.22000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4279.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  638\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.27000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.73000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3931.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  639\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.66000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.26000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2997.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  640\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.32000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.20000 0.48000]\n",
      " done   :  False\n",
      "   _std :  0.05\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2406.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  641\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.69000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.46000 0.45000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5687.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  642\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.25000 -1.09000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3877.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  643\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.62000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.96000 0.43000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4148.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  644\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.06000 0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.53000 -0.10000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7909.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  645\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.35000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.38000 0.66000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4856.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  646\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.46000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.81000 -0.12000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1490.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  647\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.31000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.89000 -0.03000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5770.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  648\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.62000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.04000 -0.24000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4345.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  649\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.38000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.54000 -1.01000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2066.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  650\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.53000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.59000 1.03000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4245.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  651\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.41000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.14000 -0.98000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3054.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  652\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.81000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.33000 -0.53000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2662.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  653\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.00000 -0.43000]\n",
      " done   :  False\n",
      "   _std :  0.049\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2880.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  654\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.37000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.47000 -0.94000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2007.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  655\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.46000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.18000 0.92000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5667.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  656\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.66000 0.88000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5892.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  657\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.49000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4234.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  658\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.40000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.53000 -0.61000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6274.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  659\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.25000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.35000 0.67000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5064.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  660\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.62000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.61000 -0.13000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4722.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  661\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.27000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.97000 -0.99000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6424.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  662\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.17000 0.28000]\n",
      " done   :  True\n",
      "   _std :  0.048\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -1726.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  663\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.09000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.08000 -1.11000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4231.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  664\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.30000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.81000 -1.01000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4671.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  665\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.76000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.20000 0.44000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4149.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  666\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.15000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.19000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5099.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  667\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.07000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.92000 -0.17000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2254.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  668\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.75000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.75000 -0.12000]\n",
      " done   :  False\n",
      "   _std :  0.048\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1761.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  669\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.14000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.53000 0.35000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6297.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  670\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.91000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.45000 -0.71000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2163.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  671\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.67000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.39000 0.36000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3708.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  672\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.41000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.21000 1.10000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6783.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  673\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.28000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.31000 0.47000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4248.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  674\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.25000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.41000 0.54000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6902.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  675\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.65000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.30000 -0.57000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4384.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  676\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.20000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.36000 0.95000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4619.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  677\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.45000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.02000 0.73000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2777.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  678\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.94000 -0.03000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5314.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  679\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.22000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.67000 1.05000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2564.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  680\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.61000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.08000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2224.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  681\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.42000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.30000 0.67000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2572.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  682\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.59000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.49000 -0.70000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2565.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  683\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.23000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.92000 0.48000]\n",
      " done   :  False\n",
      "   _std :  0.047\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2115.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  684\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.38000 -1.16000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3285.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  685\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.04000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.38000 0.74000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4059.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  686\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.22000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.12000 -0.73000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9526.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  687\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.48000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.97000 1.02000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3423.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  688\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.14000 -0.98000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2083.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  689\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.17000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.40000 0.74000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2251.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  690\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.76000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.24000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1954.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  691\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.58000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.13000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2642.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  692\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.18000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.21000 -1.02000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5456.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  693\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.14000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.24000 -0.75000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -11982.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  694\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.50000 0.66000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7232.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  695\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.08000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.47000 0.38000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3556.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  696\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.15000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.98000 0.18000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4260.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  697\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.55000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.75000 -0.29000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3067.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  698\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.56000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.96000 0.46000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6053.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  699\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.19000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.61000 0.53000]\n",
      " done   :  False\n",
      "   _std :  0.046\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4035.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  700\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.09000 1.06000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2225.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  701\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.07000 0.67000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2940.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  702\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.76000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.15000 1.11000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5418.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  703\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.13000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.62000 0.49000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3912.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  704\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.82000 -0.45000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2487.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  705\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.07000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.65000 0.36000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5487.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  706\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.09000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.41000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5220.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  707\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.59000 -0.28000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6511.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  708\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.11000 0.60000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3985.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  709\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.27000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 0.61000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -11554.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  710\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.91000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.77000 1.11000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4653.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  711\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.95000 -0.50000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4191.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  712\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.17000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.48000 -1.04000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3247.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  713\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.15000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.23000 0.35000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2400.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  714\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.91000 -0.11000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2713.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  715\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.25000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.72000 -1.10000]\n",
      " done   :  False\n",
      "   _std :  0.045\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2454.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  716\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.40000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.16000 1.15000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3416.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  717\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.37000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.45000 0.80000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3539.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  718\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.46000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.14000 1.13000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2307.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  719\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.83000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.16000 0.72000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2316.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  720\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.16000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.37000 -0.56000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6148.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  721\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.18000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.03000 0.59000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2031.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  722\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.61000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.55000 0.47000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3249.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  723\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.74000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.24000 1.15000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7241.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  724\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.55000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.13000 0.30000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5650.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  725\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.37000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.60000 -0.74000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6298.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  726\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.13000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.32000 -0.79000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1588.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  727\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.26000 -0.86000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3885.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  728\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.46000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.22000 0.45000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6138.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  729\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.87000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.12000 0.32000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9776.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  730\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.16000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.28000 -0.88000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5460.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  731\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.65000 -0.34000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1562.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  732\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.12000 0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.92000 0.82000]\n",
      " done   :  False\n",
      "   _std :  0.044\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10710.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  733\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.37000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.32000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2729.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  734\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.46000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.86000 -0.12000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4234.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  735\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.73000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.84000 0.19000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4737.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  736\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.56000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.98000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5288.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  737\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.05000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.48000 0.50000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7327.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  738\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.57000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.49000 -0.79000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3370.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  739\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.75000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.73000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3804.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  740\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.68000 -0.58000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3922.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  741\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.25000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.04000 0.61000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1612.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  742\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.64000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.86000 0.43000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8147.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  743\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.77000 1.05000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4104.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  744\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.16000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.69000 0.40000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7876.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  745\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.77000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.08000 -0.31000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2677.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  746\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.28000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.11000 0.60000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1682.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  747\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.26000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.01000 -0.52000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2513.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  748\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.23000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.95000 -0.68000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7221.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  749\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.56000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.59000 -0.24000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5583.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  750\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.26000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.86000 1.04000]\n",
      " done   :  False\n",
      "   _std :  0.043\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9434.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  751\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.63000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.76000 0.63000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3301.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  752\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.20000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.32000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2085.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  753\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.78000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.90000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4406.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  754\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.35000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.60000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4346.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  755\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.52000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.98000 -0.18000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2480.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  756\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.47000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3202.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  757\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.93000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.31000 -1.03000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2343.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  758\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.48000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.84000 0.28000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4453.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  759\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.26000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.02000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7138.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  760\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.23000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.65000 -0.43000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7070.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  761\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.16000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.06000 0.99000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3511.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  762\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.05000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.13000 0.86000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4041.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  763\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.30000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.78000 -1.01000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1917.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  764\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.86000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.49000 1.15000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3429.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  765\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.57000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.33000 -0.50000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3902.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  766\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.14000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.59000 1.13000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1942.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  767\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.86000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.78000 -0.88000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10755.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  768\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.38000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.10000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2812.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  769\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.35000 0.90000]\n",
      " done   :  False\n",
      "   _std :  0.042\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2596.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  770\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.64000 -0.67000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4144.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  771\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.39000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.04000 0.49000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6140.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  772\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.93000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.72000 1.00000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1894.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  773\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.22000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.01000 0.52000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2642.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  774\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.13000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.23000 -0.97000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2015.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  775\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.13000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.59000 0.12000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4462.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  776\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.45000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.48000 0.77000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2794.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  777\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.22000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.20000 0.52000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8869.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  778\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.80000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.19000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4331.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  779\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.52000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.09000 0.47000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4451.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  780\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.35000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.87000 -0.45000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6232.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  781\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.59000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.75000 -1.13000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5164.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  782\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.54000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.61000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4941.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  783\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.99000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.84000 0.06000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6414.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  784\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.17000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.93000 -0.43000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2324.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  785\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.14000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.71000 -0.98000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3631.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  786\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.61000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.54000 -1.12000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4269.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  787\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.92000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.14000 -0.58000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3630.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  788\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.28000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.54000 0.79000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2312.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  789\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.83000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.041\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3059.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  790\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.86000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.55000 0.85000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5974.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  791\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.16000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.30000 -0.26000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2197.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  792\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.07000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.20000 -0.70000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4151.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  793\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.69000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.69000 -0.96000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1547.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  794\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.68000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.05000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5037.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  795\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.09000 -0.88000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3628.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  796\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.78000 0.42000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4140.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  797\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.91000 -0.95000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2482.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  798\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.01000 -1.00000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2300.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  799\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.83000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.20000 -0.53000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1971.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  800\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.37000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.72000 -0.66000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4225.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  801\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.94000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.64000 -0.50000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3446.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  802\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.16000 -0.84000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7103.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  803\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.08000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.23000 0.88000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2802.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  804\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.16000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.67000 -0.25000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1743.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  805\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.97000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.28000 0.22000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3578.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  806\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.30000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.30000 0.45000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2941.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  807\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.10000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.65000 0.79000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3211.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  808\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.01000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.11000 -0.58000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3086.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  809\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.42000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.25000 1.04000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5970.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  810\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.12000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.73000 -0.99000]\n",
      " done   :  False\n",
      "   _std :  0.04\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1812.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  811\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.23000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.75000 -1.04000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2690.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  812\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.70000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.11000 1.08000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2451.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  813\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.04000 0.22000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8948.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  814\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.37000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.05000 0.21000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1320.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  815\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.78000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.20000 -0.64000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3044.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  816\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.47000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.17000 0.63000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6415.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  817\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.89000 0.64000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4441.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  818\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.39000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.26000 -0.28000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4385.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  819\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.06000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.44000 -0.86000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4020.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  820\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.38000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.50000 -0.76000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3395.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  821\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.60000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.32000 -1.17000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3699.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  822\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.62000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.55000 -0.29000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1758.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  823\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.60000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.97000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4562.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  824\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.35000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.15000 -0.04000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4164.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  825\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.88000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.42000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6028.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  826\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.16000 -0.36000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2579.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  827\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.42000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.38000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3360.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  828\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.05000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.48000 -0.37000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2021.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  829\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.25000 0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.78000 0.96000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9326.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  830\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.29000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.39000 0.64000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5658.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  831\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.50000 -0.85000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2062.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  832\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.24000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.53000 0.99000]\n",
      " done   :  False\n",
      "   _std :  0.039\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2029.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  833\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.20000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.79000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2612.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  834\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.74000 -1.09000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1734.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  835\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.11000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.79000 0.99000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2648.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  836\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.05000 -0.18000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2741.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  837\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.48000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.91000 0.79000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2481.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  838\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.16000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.73000 -0.81000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4651.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  839\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.89000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.38000 1.09000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4457.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  840\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.79000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.62000 -0.91000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7582.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  841\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.84000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.94000 -1.15000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4460.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  842\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.99000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.20000 0.76000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3223.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  843\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.25000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.95000 -0.16000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3993.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  844\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.40000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.59000 0.49000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2026.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  845\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.94000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.14000 0.88000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2493.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  846\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.37000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.42000 0.37000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2423.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  847\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.71000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.13000 0.91000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3663.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  848\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.22000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.20000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4438.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  849\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.47000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.80000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3323.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  850\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.07000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.94000 -0.38000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2735.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  851\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.19000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.13000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6201.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  852\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.15000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.72000 -0.55000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2859.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  853\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.63000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.14000 0.10000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2843.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  854\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.50000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.97000 -0.04000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3704.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  855\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.81000 1.09000]\n",
      " done   :  False\n",
      "   _std :  0.038\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2752.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  856\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.14000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.09000 0.66000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2959.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  857\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.59000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.78000 -0.32000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3575.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  858\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.37000 -0.22000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3906.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  859\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.33000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.21000 0.68000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3616.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  860\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.49000 -0.23000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6897.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  861\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.22000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.52000 -0.78000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4279.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  862\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.07000 -0.16000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.23000 0.49000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7438.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  863\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.74000 0.58000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1492.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  864\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.41000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.64000 -0.23000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2938.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  865\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.44000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.85000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3907.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  866\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.35000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.38000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2769.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  867\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.29000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.39000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2867.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  868\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.36000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.32000 -0.10000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1665.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  869\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.18000 -0.14000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5333.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  870\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.20000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.88000 1.04000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3584.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  871\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.85000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.94000 0.31000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4003.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  872\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.36000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.96000 -0.17000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6126.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  873\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.93000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.09000 -0.25000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4237.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  874\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.09000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6355.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  875\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.00000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.76000 1.02000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3355.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  876\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.07000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.51000 -0.11000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2275.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  877\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.58000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-17.19000 1.06000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6093.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  878\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.07000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.41000 0.19000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2122.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  879\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.73000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [12.43000 -0.82000]\n",
      " done   :  False\n",
      "   _std :  0.037\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2687.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  880\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.81000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.53000 1.12000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1799.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  881\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.25000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.67000 0.08000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2771.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  882\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.97000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.73000 -0.46000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4352.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  883\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.56000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.03000 0.72000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3207.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  884\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.65000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.40000 0.62000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2581.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  885\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.12000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.30000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3318.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  886\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.07000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.43000 -0.19000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3161.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  887\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.09000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.92000 0.60000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2388.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  888\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.57000 -0.93000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2359.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  889\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.36000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.71000 0.70000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3409.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  890\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.89000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-10.39000 -0.33000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5433.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  891\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.97000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.43000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2630.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  892\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.05000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.75000 -0.47000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3563.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  893\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 0.45000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2166.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  894\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.34000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.13000 -0.24000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4755.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  895\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.81000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.56000 -0.39000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6559.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  896\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.80000 -0.92000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4258.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  897\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.47000 0.92000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3407.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  898\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.63000 0.22000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4540.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  899\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.94000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.76000 -0.17000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2134.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  900\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.52000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.92000 -0.51000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8304.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  901\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.23000 0.35000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2558.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  902\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.66000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.96000 0.32000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5521.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  903\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.64000 -0.13000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.01000 -0.49000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6691.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  904\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.46000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 0.98000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4107.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  905\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.59000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.60000 -0.27000]\n",
      " done   :  False\n",
      "   _std :  0.036\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3547.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  906\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.04000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.77000 0.37000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3823.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  907\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.64000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.28000 0.50000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2864.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  908\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.11000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.34000 -0.43000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4959.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  909\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.34000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.44000 -1.13000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2450.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  910\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.14000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.40000 0.37000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3878.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  911\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.13000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.82000 0.78000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2202.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  912\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.37000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.73000 1.07000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1625.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  913\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.00000 0.21000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2087.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  914\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [3.46000 0.96000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3152.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  915\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.09000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.55000 -0.22000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4271.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  916\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.53000 0.52000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5934.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  917\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.13000 -0.98000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4157.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  918\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.43000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [11.46000 0.29000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2435.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  919\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.68000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.38000 -0.70000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3645.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  920\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.28000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.88000 0.63000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2277.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  921\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.59000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [7.58000 0.58000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2945.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  922\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.15000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.19000 -1.09000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4265.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  923\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.41000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.46000 0.29000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2144.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  924\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.39000 -1.04000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2199.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  925\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.98000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.04000 0.25000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3073.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  926\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.47000 0.12000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3564.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  927\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.42000 0.12000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5316.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  928\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.79000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.72000 0.86000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4794.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  929\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.46000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.66000 0.16000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2999.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  930\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.33000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.35000 0.42000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4150.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  931\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.43000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.87000 -0.57000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2293.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  932\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.25000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.85000 0.19000]\n",
      " done   :  False\n",
      "   _std :  0.035\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3162.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  933\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.64000 0.37000]\n",
      " done   :  True\n",
      "   _std :  0.034\n",
      "episode length :  847\n",
      "\n",
      "Episode reward :  -2016.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  934\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.89000 0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.38000 0.29000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5429.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  935\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.23000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.61000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5332.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  936\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.92000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5407.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  937\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.44000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-4.96000 -0.44000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3868.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  938\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.20000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [18.63000 -0.56000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2378.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  939\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.29000 -0.15000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-3.50000 -0.96000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5203.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  940\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.38000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.95000 -0.11000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10430.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  941\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.99000 0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.97000 -0.90000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4150.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  942\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.23000 0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.39000 1.11000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7890.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  943\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.10000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.73000 -0.98000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2474.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  944\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.83000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.82000 -0.57000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2367.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  945\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.30000 -0.14000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.86000 0.10000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4317.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  946\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.49000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.50000 0.92000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5468.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  947\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.17000 -0.16000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.60000 0.16000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7897.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  948\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.60000 -0.16000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.99000 0.80000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9751.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  949\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.52000 1.11000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2984.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  950\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.21000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.37000 -0.65000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3980.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  951\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-14.27000 -0.33000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2195.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  952\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.34000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.58000 -0.79000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5099.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  953\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.68000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.16000 -0.15000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3310.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  954\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.46000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-5.09000 0.91000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3044.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  955\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.39000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.94000 -1.01000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2567.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  956\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.79000 0.16000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.91000 0.46000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9915.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  957\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.82000 -0.18000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.84000 0.93000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -9600.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  958\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.19000 -0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [15.62000 0.94000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3774.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  959\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.80000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-15.61000 1.03000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7490.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  960\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.43000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.93000 -0.25000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2312.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  961\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-8.97000 1.16000]\n",
      " done   :  False\n",
      "   _std :  0.034\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4604.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  962\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.41000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.66000 -1.01000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1668.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  963\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.21000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.39000 -0.84000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1778.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  964\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.75000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.70000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3525.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  965\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.67000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.88000 0.84000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3550.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  966\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.47000 -0.08000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.88000 -0.18000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2049.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  967\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.94000 0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [14.42000 -0.46000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3179.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  968\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.51000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.41000 -0.80000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10837.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  969\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.81000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.41000 -0.46000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -10741.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  970\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.20000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-6.41000 0.42000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3418.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  971\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [5.53000 0.33000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4236.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  972\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.73000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.19000 0.62000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2390.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  973\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.39000 -0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-9.41000 -1.04000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4604.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  974\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.82000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.32000 -0.33000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -7733.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  975\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.24000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [8.00000 0.55000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2396.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  976\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [4.35000 1.01000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2625.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  977\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.21000 -0.11000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.61000 -0.92000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4601.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  978\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.71000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-18.77000 -1.03000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2030.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  979\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.81000 0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.20000 -0.47000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5485.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  980\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.33000 0.02000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-16.50000 0.69000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4608.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  981\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.64000 -0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [10.71000 -1.14000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2435.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  982\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.77000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.46000 0.08000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2261.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  983\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.76000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.80000 0.48000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2691.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  984\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.90000 0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.35000 -0.62000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4426.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  985\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.53000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 0.97000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3689.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  986\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.06000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.21000 -0.24000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -4629.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  987\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 -0.07000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.10000 -0.23000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5618.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  988\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.12000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.74000 -0.92000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3592.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  989\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [1.02000 0.12000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.65000 -0.79000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -8818.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  990\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-1.05000 -0.10000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-7.00000 -0.47000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -5404.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  991\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.15000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-12.68000 1.07000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1849.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  992\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [19.53000 -0.53000]\n",
      " done   :  False\n",
      "   _std :  0.033\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3830.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  993\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.18000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-11.23000 0.74000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6480.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  994\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.39000 0.01000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [17.34000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3230.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  995\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.46000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [9.63000 0.93000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -3799.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  996\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.72000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [16.92000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -1773.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  997\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.14000 0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-13.03000 0.42000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -6724.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  998\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.27000 -0.09000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [13.28000 -0.36000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2621.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  999\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.79000 -0.06000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.87000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2320.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1000\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.44000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [6.20000 -1.11000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -2482.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1001\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -30.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1002\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -29.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1003\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  970\n",
      "\n",
      "Episode reward :  -30.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1004\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.67000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -32.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1005\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -30.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1006\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.36000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -30.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1007\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.05000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -31.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1008\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.69000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  944\n",
      "\n",
      "Episode reward :  -31.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1009\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.54000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -31.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1010\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  926\n",
      "\n",
      "Episode reward :  -32.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1011\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  925\n",
      "\n",
      "Episode reward :  -32.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1012\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  923\n",
      "\n",
      "Episode reward :  -33.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1013\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -34.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1014\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  949\n",
      "\n",
      "Episode reward :  -34.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1015\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  945\n",
      "\n",
      "Episode reward :  -34.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  1016\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  950\n",
      "\n",
      "Episode reward :  -34.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1017\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  966\n",
      "\n",
      "Episode reward :  -33.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1018\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  966\n",
      "\n",
      "Episode reward :  -33.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  1019\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.032\n",
      "episode length :  971\n",
      "\n",
      "Episode reward :  -33.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  1020\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.56000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -36.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1021\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.00000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -36.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1022\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -36.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  1023\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.04000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -37.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1024\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.49000 0.06000]\n",
      " done   :  False\n",
      "   _std :  0.032\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -38.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1025\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.67000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -39.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1026\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.68000 0.06000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -38.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1027\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.52000 0.08000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -38.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1028\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  995\n",
      "\n",
      "Episode reward :  -37.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1029\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -36.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1030\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.73000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -35.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1031\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -34.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1032\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -33.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1033\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -33.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1034\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.47000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  1035\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1036\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1037\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.70000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1038\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1039\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1040\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.84000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1041\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1042\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.82000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  1043\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.92000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1044\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1045\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  1046\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 0.04000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1047\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1048\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.82000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -32.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1049\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -31.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1050\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.96000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -31.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1051\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.17000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  947\n",
      "\n",
      "Episode reward :  -31.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1052\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  981\n",
      "\n",
      "Episode reward :  -31.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1053\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.95000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -31.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1054\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.94000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -30.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  1055\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -31.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1056\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -31.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1057\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  997\n",
      "\n",
      "Episode reward :  -32.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1058\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.09000]\n",
      " done   :  False\n",
      "   _std :  0.031\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1059\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.88000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.031\n",
      "episode length :  996\n",
      "\n",
      "Episode reward :  -33.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1060\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.84000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  1061\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.08000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  1062\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.44000 -0.07000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1063\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.22000 -0.13000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1064\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.08000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  1065\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.81000 -0.09000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1066\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.08000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1067\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 -0.13000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  1068\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.93000 -0.15000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1069\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 -0.12000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1070\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.12000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1071\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.80000 -0.07000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  980\n",
      "\n",
      "Episode reward :  -34.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1072\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.55000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.03\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -31.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1073\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1074\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.97000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -30.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1075\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  925\n",
      "\n",
      "Episode reward :  -30.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1076\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.89000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -30.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1077\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  925\n",
      "\n",
      "Episode reward :  -30.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  1078\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  926\n",
      "\n",
      "Episode reward :  -31.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1079\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.67000 0.09000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  926\n",
      "\n",
      "Episode reward :  -31.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1080\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.09000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -31.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1081\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -30.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1082\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.47000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -31.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1083\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.56000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -30.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1084\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.20000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -30.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  1085\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.66000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -31.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1086\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -31.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1087\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -30.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1088\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -30.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1089\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.67000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -30.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1090\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1091\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -30.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  1092\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -30.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1093\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.91000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1094\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -30.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  1095\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -29.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  1096\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.41000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.03\n",
      "episode length :  945\n",
      "\n",
      "Episode reward :  -29.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  1097\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  947\n",
      "\n",
      "Episode reward :  -29.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1098\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  946\n",
      "\n",
      "Episode reward :  -29.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  1099\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.71000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  948\n",
      "\n",
      "Episode reward :  -29.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1100\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -29.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1101\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -29.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1102\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.07000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -30.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  1103\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.03000 -0.07000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -30.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  1104\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.87000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  926\n",
      "\n",
      "Episode reward :  -31.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1105\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.10000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -30.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1106\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -29.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  1107\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1108\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1109\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -30.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1110\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  1111\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1112\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.93000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  1113\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.27000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  1114\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1115\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-2.20000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -29.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1116\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1117\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1118\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  1119\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.79000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  1120\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -29.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  1121\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  1122\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1123\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -30.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1124\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1125\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  1126\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.83000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1127\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.63000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1128\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -30.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1129\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1130\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  1131\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.92000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1132\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  1133\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.52000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1134\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  1135\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.50000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1136\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.28000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.029\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1137\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1138\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -30.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1139\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.21000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1140\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.82000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1141\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1142\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1143\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1144\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1145\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.74000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -29.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1146\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1147\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.23000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  1148\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1149\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -29.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1150\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.49000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -29.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1151\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -29.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  1152\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.57000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -30.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1153\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -29.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1154\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.63000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1155\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.90000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1156\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.50000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1157\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1158\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1159\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  948\n",
      "\n",
      "Episode reward :  -28.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1160\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1161\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -37.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1162\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -29.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1163\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1164\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1165\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1166\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.53000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1167\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1168\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.28000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1169\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  1170\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1171\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.57000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  1172\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1173\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.88000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -31.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  1174\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.96000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -29.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1175\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  1176\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.72000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  1177\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  1178\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.79000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.028\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  1179\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.57000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1180\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1181\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.90000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -29.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1182\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1183\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.72000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1184\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1185\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1186\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1187\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -33.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1188\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.56000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1189\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.46000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1190\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.89000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1191\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.51000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  1192\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.13000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1193\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.90000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1194\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  1195\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.72000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -32.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1196\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.63000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -29.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1197\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  1198\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.22000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1199\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.68000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1200\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1201\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1202\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  1203\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.75000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1204\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1205\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1206\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.66000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1207\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.95000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1208\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.78000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1209\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1210\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  1211\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  1212\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  1213\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.67000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1214\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.96000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  1215\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1216\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.74000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1217\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1218\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -29.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1219\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1220\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  1221\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  1222\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.96000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  1223\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1224\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.00000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.027\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1225\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1226\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.50000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1227\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1228\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.93000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1229\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1230\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1231\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1232\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  1233\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1234\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1235\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -29.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1236\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  1237\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.74000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1238\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.36000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1239\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  1240\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.85000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  1241\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1242\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.47000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1243\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.22000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -29.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1244\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  1245\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1246\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -29.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1247\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  946\n",
      "\n",
      "Episode reward :  -28.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  1248\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1249\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.47000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1250\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.68000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  1251\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1252\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.54000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1253\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1254\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  1255\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1256\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  1257\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.40000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1258\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  1259\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.21000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1260\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  1261\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1262\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.23000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1263\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1264\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.46000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1265\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.67000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1266\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.59000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1267\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1268\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1269\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.68000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1270\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1271\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1272\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1273\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.09000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.026\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  1274\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.47000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1275\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.65000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1276\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1277\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1278\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -28.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1279\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1280\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1281\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -28.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1282\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  1283\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.70000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  1284\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1285\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.82000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1286\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1287\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.91000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -30.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  1288\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.56000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1289\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.00000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  1290\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1291\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1292\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1293\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1294\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1295\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.52000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1296\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.60000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1297\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  1298\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.81000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1299\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1300\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.54000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1301\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  1302\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1303\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1304\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1305\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.78000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1306\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1307\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1308\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1309\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  1310\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.82000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1311\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1312\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1313\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1314\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.22000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1315\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1316\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1317\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.66000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1318\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.66000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1319\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.47000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1320\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.67000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1321\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.68000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1322\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  1323\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1324\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1325\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  1326\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  1327\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.025\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1328\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1329\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1330\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.02000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  1331\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1332\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.87000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1333\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  950\n",
      "\n",
      "Episode reward :  -27.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1334\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.68000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  1335\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1336\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.70000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  1337\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1338\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.18000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1339\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1340\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  1341\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1342\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.67000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1343\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1344\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.53000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1345\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.46000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1346\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.81000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1347\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1348\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.95000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1349\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -31.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1350\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1351\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  1352\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1353\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1354\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -29.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1355\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1356\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1357\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  1358\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.80000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  1359\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1360\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.68000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1361\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1362\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1363\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1364\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1365\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1366\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1367\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1368\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1369\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1370\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  1371\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.87000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1372\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1373\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.34000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1374\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.58000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1375\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.52000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1376\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1377\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1378\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.41000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  1379\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1380\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  1381\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1382\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  1383\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1384\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1385\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.54000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.024\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1386\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1387\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.49000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1388\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.71000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1389\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1390\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1391\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1392\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1393\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.22000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1394\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.79000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1395\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1396\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  1397\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1398\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1399\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  1400\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1401\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1402\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  972\n",
      "\n",
      "Episode reward :  -75.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1403\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  1404\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.61000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  954\n",
      "\n",
      "Episode reward :  -28.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1405\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.39000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1406\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  1407\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1408\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.94000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1409\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -30.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1410\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.62000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1411\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1412\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1413\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.66000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1414\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.023\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1415\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -28.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1416\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  949\n",
      "\n",
      "Episode reward :  -28.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1417\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  996\n",
      "\n",
      "Episode reward :  -32.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  1418\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -33.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  1419\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1420\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  983\n",
      "\n",
      "Episode reward :  -28.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1421\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  1422\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.44000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1423\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.39000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1424\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1425\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  1426\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1427\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  1428\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  1429\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  1430\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.87000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1431\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1432\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.46000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1433\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1434\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  1435\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  1436\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  945\n",
      "\n",
      "Episode reward :  -27.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1437\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1438\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1439\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1440\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  1441\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.96000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1442\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1443\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1444\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1445\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.60000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  1446\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1447\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.96000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1448\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.023\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1449\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.56000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1450\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.70000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1451\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1452\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1453\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1454\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  1455\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.53000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1456\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  1457\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1458\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1459\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.66000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1460\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1461\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1462\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1463\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1464\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.39000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1465\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1466\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1467\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1468\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.93000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1469\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1470\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.39000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  1471\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1472\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1473\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1474\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1475\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1476\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.88000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1477\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1478\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  1479\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1480\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1481\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1482\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.51000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1483\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.14000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1484\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1485\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1486\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  1487\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  1488\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1489\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1490\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1491\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1492\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  1493\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.65000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  1494\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1495\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1496\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1497\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1498\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.71000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  1499\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1500\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1501\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1502\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.04000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1503\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1504\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -30.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1505\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1506\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.59000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1507\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.98000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  1508\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1509\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  1510\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1511\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1512\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  1513\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1514\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1515\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1516\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1517\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.022\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  1518\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1519\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1520\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1521\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  1522\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.54000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1523\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1524\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.28000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1525\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  1526\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  1527\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1528\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1529\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1530\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1531\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.50000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1532\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1533\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1534\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1535\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1536\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  1537\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.51000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1538\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  1539\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.89000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1540\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  1541\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.97000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1542\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.44000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1543\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.86000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1544\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1545\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.63000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1546\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  1547\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1548\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1549\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1550\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  1551\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  1552\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.55000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1553\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.39000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  1554\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1555\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  1556\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  1557\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1558\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.61000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1559\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1560\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1561\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1562\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1563\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1564\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1565\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1566\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.63000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1567\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1568\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1569\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1570\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1571\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1572\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  1573\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  1574\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  1575\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  1576\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.13000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1577\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.60000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1578\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  1579\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1580\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -1097.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  1581\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.81000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -34.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  1582\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.59000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -40.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  1583\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.62000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  924\n",
      "\n",
      "Episode reward :  -31.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1584\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  1585\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1586\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  1587\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1588\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  1589\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -33.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1590\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  1591\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1592\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.021\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1593\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -29.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1594\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  945\n",
      "\n",
      "Episode reward :  -29.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1595\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 -0.11000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  950\n",
      "\n",
      "Episode reward :  -30.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1596\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 -0.07000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  948\n",
      "\n",
      "Episode reward :  -29.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1597\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.39000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  945\n",
      "\n",
      "Episode reward :  -29.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1598\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.64000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  945\n",
      "\n",
      "Episode reward :  -30.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1599\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1600\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -29.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1601\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.75000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -29.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1602\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 0.10000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  923\n",
      "\n",
      "Episode reward :  -30.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1603\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1604\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1605\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.10000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  946\n",
      "\n",
      "Episode reward :  -29.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1606\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1607\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.69000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1608\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.09000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  1609\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -31.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1610\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 -0.09000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -30.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1611\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.39000 0.08000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  921\n",
      "\n",
      "Episode reward :  -32.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1612\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  1613\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.09000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  949\n",
      "\n",
      "Episode reward :  -31.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1614\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  953\n",
      "\n",
      "Episode reward :  -32.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1615\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 -0.08000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  954\n",
      "\n",
      "Episode reward :  -31.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1616\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -30.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  1617\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  1618\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.39000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -28.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1619\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1620\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.82000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  1621\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  1622\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.60000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1623\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.84000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1624\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1625\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.49000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  1626\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1627\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  1628\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1629\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.44000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  1630\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  1631\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.44000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  1632\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1633\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1634\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1635\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1636\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1637\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  1638\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1639\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  1640\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1641\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1642\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1643\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  1644\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1645\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1646\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.58\n",
      "\n",
      " \n",
      " \n",
      " episode :  1647\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1648\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1649\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1650\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  1651\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1652\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1653\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1654\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1655\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  1656\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1657\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  1658\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.87000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  1659\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1660\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -32.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1661\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -31.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1662\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.51000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -34.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1663\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -33.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1664\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -30.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1665\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.99000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -29.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1666\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1667\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1668\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1669\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1670\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -28.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1671\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.67000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  1672\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1673\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  1674\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1675\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1676\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.02\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1677\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.73000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1678\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1679\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1680\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  1681\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1682\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  961\n",
      "\n",
      "Episode reward :  -31.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1683\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1684\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  1685\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  1686\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.85000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  1687\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.92000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1688\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1689\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -30.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1690\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.78000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  1691\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  1692\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.77000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1693\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  1694\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1695\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1696\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1697\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1698\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.55000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1699\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.93000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1700\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1701\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  1702\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1703\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1704\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  1705\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1706\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.55000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  1707\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  1708\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.66000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1709\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1710\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1711\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1712\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.29000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1713\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1714\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.84000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1715\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1716\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  1717\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.72000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1718\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1719\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  1720\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  1721\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  1722\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1723\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1724\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1725\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1726\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  1727\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1728\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  1729\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1730\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  1731\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.63000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  1732\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.90000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1733\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  1734\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -30.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1735\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1736\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1737\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-1.00000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1738\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  1739\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1740\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  1741\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1742\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  1743\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1744\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.66000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  1745\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -29.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1746\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1747\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  1748\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  1749\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  1750\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.83000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  1751\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1752\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1753\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1754\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1755\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1756\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1757\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  1758\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1759\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1760\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  1761\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  957\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1762\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  1763\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1764\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  1765\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  1766\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1767\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  1768\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.019\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  1769\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.51000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1770\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.56000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  1771\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  1772\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  1773\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  1774\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1775\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  1776\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.53000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  1777\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1778\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1779\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1780\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  1781\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1782\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1783\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  1784\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1785\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1786\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  1787\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  1788\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1789\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1790\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1791\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1792\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  1793\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.51000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  1794\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1795\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.46000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1796\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1797\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1798\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  1799\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1800\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.64000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1801\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1802\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  1803\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1804\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.63000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1805\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1806\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  1807\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1808\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1809\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  1810\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  1811\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  1812\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.56000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1813\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  1814\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.72000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1815\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1816\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1817\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1818\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1819\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1820\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.89000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1821\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  1822\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1823\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1824\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1825\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  1826\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.55000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1827\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1828\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1829\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1830\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1831\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1832\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1833\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  1834\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1835\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1836\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.83000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1837\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.59000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1838\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.72000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  1839\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.74000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1840\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1841\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.58000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1842\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  1843\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1844\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1845\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.79000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1846\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1847\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.39000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  1848\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1849\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.68000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1850\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.52000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1851\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1852\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1853\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1854\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1855\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.56000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1856\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1857\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1858\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.70000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1859\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1860\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  1861\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.87000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1862\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1863\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1864\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1865\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1866\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  1867\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1868\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  1869\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  1870\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1871\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.018\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1872\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1873\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1874\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  1875\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.74000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  1876\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.66000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  1877\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1878\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1879\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1880\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  1881\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1882\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.75000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  1883\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.96000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1884\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  1885\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  1886\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.50000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  1887\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.47000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1888\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1889\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -36.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  1890\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1891\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  1892\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1893\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  1894\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1895\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  1896\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  1897\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  1898\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1899\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.64000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1900\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.47000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  1901\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  1902\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  1903\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  1904\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1905\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1906\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1907\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1908\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1909\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1910\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1911\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1912\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1913\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1914\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.57000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1915\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1916\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1917\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.65000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1918\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1919\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1920\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.54000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  1921\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1922\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  1923\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  1924\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  1925\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  1926\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1927\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [1.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1928\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  1929\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  1930\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  1931\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1932\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  1933\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  1934\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1935\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1936\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1937\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.71000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1938\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1939\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.69000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  1940\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  1941\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.58000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  1942\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  1943\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  1944\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  1945\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  1946\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  1947\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  1948\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  1949\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1950\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  1951\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  1952\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  1953\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  1954\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1955\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  1956\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  1957\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1958\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1959\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1960\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1961\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  1962\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.52000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1963\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1964\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1965\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  1966\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1967\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  1968\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  1969\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1970\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  1971\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  1972\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  1973\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.52000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  1974\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  1975\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  1976\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1977\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  1978\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  1979\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.22000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  1980\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1981\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1982\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  1983\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  1984\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  1985\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  1986\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.017\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  1987\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  1988\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  1989\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1990\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  1991\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  1992\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.60000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  1993\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  1994\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  1995\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  1996\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  1997\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  1998\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.96000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  1999\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2000\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2001\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  2002\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.54000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  2003\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2004\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2005\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2006\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  2007\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.60000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2008\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2009\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  2010\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.47000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2011\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2012\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.39000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2013\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2014\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2015\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2016\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2017\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2018\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2019\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2020\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2021\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2022\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2023\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  2024\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2025\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2026\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2027\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.69000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2028\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2029\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2030\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2031\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2032\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.76000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  2033\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2034\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2035\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.64000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2036\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2037\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2038\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.50000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2039\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.54000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2040\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2041\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2042\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2043\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2044\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.88000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2045\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2046\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.53000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2047\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2048\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2049\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2050\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2051\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2052\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2053\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2054\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2055\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2056\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.80000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2057\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  2058\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2059\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.51000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2060\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2061\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2062\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.74000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2063\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2064\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2065\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2066\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2067\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2068\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2069\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2070\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2071\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.90000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2072\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2073\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2074\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2075\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2076\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2077\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2078\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.49000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2079\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2080\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2081\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2082\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2083\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.70000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2084\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2085\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2086\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2087\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2088\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.83000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2089\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2090\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2091\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2092\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2093\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  2094\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2095\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2096\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2097\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2098\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2099\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2100\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2101\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2102\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2103\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2104\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2105\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2106\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.78000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2107\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2108\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2109\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2110\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2111\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2112\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2113\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2114\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.65000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2115\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2116\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2117\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.016\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2118\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2119\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2120\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2121\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2122\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2123\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.55000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2124\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.58000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2125\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2126\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.54000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2127\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2128\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2129\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2130\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2131\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  2132\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2133\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2134\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2135\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2136\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2137\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2138\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.50000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2139\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2140\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2141\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2142\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.75000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2143\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2144\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2145\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2146\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2147\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2148\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2149\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.61000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2150\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2151\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2152\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.67000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2153\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2154\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.46000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2155\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2156\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2157\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2158\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2159\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2160\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2161\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2162\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2163\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  2164\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2165\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2166\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2167\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2168\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.70000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2169\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.79000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2170\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2171\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2172\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2173\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  2174\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  2175\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2176\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2177\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  951\n",
      "\n",
      "Episode reward :  -101.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  2178\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -32.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2179\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  2180\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.90000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  2181\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2182\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.56000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -30.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2183\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2184\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  2185\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2186\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2187\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2188\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.74000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2189\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  2190\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.66000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2191\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2192\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2193\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  2194\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2195\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2196\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.00000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  988\n",
      "\n",
      "Episode reward :  -1252.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2197\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 0.08000]\n",
      " done   :  False\n",
      "   _std :  0.015\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -88.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  2198\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.60000 -0.00000]\n",
      " done   :  False\n",
      "   _std :  0.015\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -41.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  2199\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [2.22000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -102.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2200\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  987\n",
      "\n",
      "Episode reward :  -31.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  2201\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.00000]\n",
      " done   :  False\n",
      "   _std :  0.015\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -35.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2202\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.04000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.00000]\n",
      " done   :  False\n",
      "   _std :  0.015\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -41.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  2203\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.09000]\n",
      " done   :  False\n",
      "   _std :  0.015\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -44.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  2204\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 -0.09000]\n",
      " done   :  False\n",
      "   _std :  0.015\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -49.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2205\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.06000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.19000]\n",
      " done   :  False\n",
      "   _std :  0.015\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -54.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2206\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.05000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.14000]\n",
      " done   :  False\n",
      "   _std :  0.015\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -45.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  2207\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  978\n",
      "\n",
      "Episode reward :  -39.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2208\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.09000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  923\n",
      "\n",
      "Episode reward :  -50.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  2209\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -44.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2210\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -37.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  2211\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -43.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  2212\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.08000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  956\n",
      "\n",
      "Episode reward :  -48.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2213\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -33.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2214\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  971\n",
      "\n",
      "Episode reward :  -35.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2215\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.08000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -31.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  2216\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  977\n",
      "\n",
      "Episode reward :  -30.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2217\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -30.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  2218\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  969\n",
      "\n",
      "Episode reward :  -29.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  2219\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  2220\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  2221\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -28.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  2222\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2223\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  2224\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -27.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2225\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2226\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -28.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  2227\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.08000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  950\n",
      "\n",
      "Episode reward :  -28.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2228\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  2229\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2230\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -31.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2231\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  946\n",
      "\n",
      "Episode reward :  -94.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  2232\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  947\n",
      "\n",
      "Episode reward :  -30.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2233\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2234\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -28.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2235\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.09000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  926\n",
      "\n",
      "Episode reward :  -29.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2236\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 0.08000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  926\n",
      "\n",
      "Episode reward :  -28.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  2237\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.62000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -28.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  2238\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2239\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -28.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  2240\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.55000 0.08000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2241\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -27.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2242\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -27.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2243\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2244\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.51000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -28.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  2245\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -28.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2246\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -28.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2247\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -28.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  2248\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -28.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2249\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2250\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -27.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2251\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -28.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2252\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  948\n",
      "\n",
      "Episode reward :  -28.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  2253\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2254\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -28.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2255\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -28.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  2256\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2257\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2258\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -29.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2259\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -28.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2260\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2261\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.69000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2262\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  2263\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -29.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  2264\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -29.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2265\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 0.07000]\n",
      " done   :  True\n",
      "   _std :  0.015\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2266\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2267\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2268\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -29.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2269\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -30.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2270\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.87000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -30.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2271\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -30.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  2272\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2273\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2274\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2275\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2276\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -29.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2277\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  2278\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2279\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.56000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2280\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  2281\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -29.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  2282\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2283\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2284\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.73000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2285\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2286\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.59000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -29.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2287\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2288\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.61000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  2289\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2290\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2291\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.25000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2292\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  2293\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  2294\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2295\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2296\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  2297\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.59000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2298\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2299\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2300\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2301\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2302\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2303\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.57000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2304\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2305\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.014\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2306\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  2307\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.65000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2308\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2309\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  2310\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.68000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  2311\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2312\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.46000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2313\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2314\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2315\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2316\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.82000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2317\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  2318\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.57000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  2319\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2320\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  2321\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2322\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  2323\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2324\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  2325\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  2326\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  2327\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  2328\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  2329\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  2330\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2331\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2332\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  2333\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2334\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.49000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2335\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2336\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  2337\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2338\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2339\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  2340\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.68000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.55\n",
      "\n",
      " \n",
      " \n",
      " episode :  2341\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2342\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2343\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.22000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  2344\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  2345\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2346\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  2347\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2348\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2349\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2350\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2351\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2352\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  2353\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.29000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  2354\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2355\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  2356\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2357\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2358\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2359\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.53000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2360\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.59000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2361\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.47000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2362\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2363\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  2364\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2365\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2366\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2367\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2368\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.51000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  2369\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.46000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -26.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2370\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  2371\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2372\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  2373\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2374\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2375\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  2376\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.51000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2377\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  2378\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2379\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2380\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2381\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.63000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2382\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2383\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2384\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2385\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.28000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2386\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2387\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.71000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2388\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2389\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2390\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2391\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.43000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2392\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.58000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  2393\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2394\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  2395\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2396\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2397\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2398\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.59000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.22\n",
      "\n",
      " \n",
      " \n",
      " episode :  2399\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2400\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  2401\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2402\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  2403\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  2404\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  2405\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.32\n",
      "\n",
      " \n",
      " \n",
      " episode :  2406\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  2407\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  2408\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  2409\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2410\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2411\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  2412\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.46000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2413\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2414\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2415\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2416\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2417\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.71000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2418\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2419\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2420\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2421\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2422\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2423\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  2424\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  2425\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.46000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2426\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  2427\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2428\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2429\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2430\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2431\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2432\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.61000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2433\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.51000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2434\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2435\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.014\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2436\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2437\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.27000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2438\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2439\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2440\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2441\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2442\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2443\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2444\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  2445\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2446\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2447\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.66000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2448\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.47000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2449\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2450\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2451\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2452\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2453\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2454\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2455\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2456\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2457\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2458\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2459\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  2460\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.58000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2461\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.40000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2462\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2463\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2464\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.57000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -39.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  2465\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  2466\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.52000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2467\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  2468\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2469\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  2470\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2471\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2472\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.84000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2473\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2474\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2475\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2476\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2477\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.64000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2478\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2479\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2480\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2481\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2482\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.39000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2483\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2484\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2485\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2486\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2487\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2488\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2489\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.76000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  2490\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.28000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2491\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  2492\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2493\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  2494\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.44\n",
      "\n",
      " \n",
      " \n",
      " episode :  2495\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -44.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2496\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2497\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  2498\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2499\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2500\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.54000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2501\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.22000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  2502\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.62000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2503\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.64000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2504\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  2505\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2506\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2507\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2508\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2509\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.49000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2510\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2511\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2512\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2513\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.37\n",
      "\n",
      " \n",
      " \n",
      " episode :  2514\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.25\n",
      "\n",
      " \n",
      " \n",
      " episode :  2515\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.15\n",
      "\n",
      " \n",
      " \n",
      " episode :  2516\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2517\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2518\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2519\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -31.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2520\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2521\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2522\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2523\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2524\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2525\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2526\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2527\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2528\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2529\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2530\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2531\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.31000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2532\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2533\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2534\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2535\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2536\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2537\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  2538\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2539\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2540\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2541\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2542\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2543\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.39000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2544\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.72\n",
      "\n",
      " \n",
      " \n",
      " episode :  2545\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2546\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2547\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2548\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2549\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2550\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2551\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2552\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2553\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2554\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.55000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2555\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2556\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2557\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2558\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2559\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2560\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2561\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2562\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2563\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2564\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2565\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2566\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2567\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2568\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2569\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2570\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2571\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2572\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2573\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2574\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2575\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2576\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2577\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2578\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2579\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2580\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.51000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2581\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.74000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2582\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2583\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2584\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.03\n",
      "\n",
      " \n",
      " \n",
      " episode :  2585\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.47000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2586\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2587\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.71000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2588\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2589\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2590\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2591\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2592\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2593\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2594\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2595\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2596\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.53000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2597\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2598\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2599\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2600\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.44000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2601\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2602\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2603\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.51000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2604\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2605\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.57000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2606\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -27.54\n",
      "\n",
      " \n",
      " \n",
      " episode :  2607\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2608\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2609\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2610\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2611\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2612\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2613\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2614\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.28000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2615\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  989\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2616\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2617\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2618\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2619\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2620\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2621\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2622\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2623\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2624\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.39000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2625\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2626\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.78000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2627\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2628\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2629\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2630\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.39000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2631\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2632\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2633\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.013\n",
      "episode length :  951\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2634\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2635\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.58000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2636\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2637\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2638\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2639\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2640\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2641\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2642\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2643\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2644\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  2645\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2646\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2647\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2648\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2649\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2650\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  2651\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2652\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2653\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2654\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2655\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2656\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2657\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.22000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2658\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2659\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2660\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2661\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  2662\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2663\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2664\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2665\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2666\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2667\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2668\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2669\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2670\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2671\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2672\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2673\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.25000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2674\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2675\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.54000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2676\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2677\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  2678\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  2679\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2680\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2681\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2682\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2683\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2684\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.84000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2685\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2686\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2687\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.50000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2688\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2689\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.41000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2690\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2691\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2692\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2693\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2694\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2695\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2696\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2697\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2698\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2699\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2700\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2701\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  2702\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2703\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2704\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.45000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2705\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.50000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2706\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2707\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2708\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2709\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2710\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2711\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2712\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2713\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2714\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2715\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2716\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2717\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2718\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2719\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2720\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2721\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2722\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2723\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2724\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2725\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2726\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2727\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.69000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2728\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2729\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2730\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2731\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2732\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.62000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -26.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2733\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2734\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.91\n",
      "\n",
      " \n",
      " \n",
      " episode :  2735\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.74000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -26.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2736\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.58000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2737\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2738\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2739\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.32000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2740\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.31\n",
      "\n",
      " \n",
      " \n",
      " episode :  2741\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2742\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2743\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  2744\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.35000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2745\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2746\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 0.06000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2747\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2748\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2749\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  2750\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  2751\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -26.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2752\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2753\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2754\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -26.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2755\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2756\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.06000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2757\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2758\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2759\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  2760\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  2761\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.06000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2762\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.38000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2763\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2764\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.16000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.29\n",
      "\n",
      " \n",
      " \n",
      " episode :  2765\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2766\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2767\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2768\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.68000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2769\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.00000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2770\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -26.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2771\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.09\n",
      "\n",
      " \n",
      " \n",
      " episode :  2772\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2773\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2774\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2775\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2776\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.24000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2777\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2778\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2779\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2780\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2781\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2782\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2783\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2784\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.33000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2785\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.31000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2786\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2787\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2788\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2789\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2790\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.44000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2791\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2792\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.43000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2793\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -26.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2794\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.41000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2795\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.26000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2796\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -26.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2797\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.1\n",
      "\n",
      " \n",
      " \n",
      " episode :  2798\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -47.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  2799\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -3096.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2800\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2801\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -33.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2802\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -32.26\n",
      "\n",
      " \n",
      " \n",
      " episode :  2803\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.28000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -30.95\n",
      "\n",
      " \n",
      " \n",
      " episode :  2804\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -29.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2805\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -29.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2806\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -30.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2807\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.49000 0.09000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -30.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2808\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -32.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2809\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.09000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -34.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  2810\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.12000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  922\n",
      "\n",
      "Episode reward :  -33.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2811\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.12000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  946\n",
      "\n",
      "Episode reward :  -33.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2812\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -35.14\n",
      "\n",
      " \n",
      " \n",
      " episode :  2813\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  945\n",
      "\n",
      "Episode reward :  -30.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2814\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.62000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -38.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2815\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -35.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  2816\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  962\n",
      "\n",
      "Episode reward :  -38.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2817\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.07000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -37.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2818\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 0.08000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -36.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  2819\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.06000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  2820\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -35.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  2821\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.32000 -0.06000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -40.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2822\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.03000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 0.05000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -34.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2823\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 -0.07000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -35.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  2824\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -33.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2825\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.00000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -30.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2826\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -31.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2827\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -31.64\n",
      "\n",
      " \n",
      " \n",
      " episode :  2828\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.03000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -31.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  2829\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.05000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -29.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2830\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.03000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -30.53\n",
      "\n",
      " \n",
      " \n",
      " episode :  2831\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -30.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2832\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.64000 -0.06000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -30.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2833\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.54000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-19.56000 -0.85000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -53.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  2834\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -30.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2835\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 -0.00000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -30.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2836\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -30.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2837\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.03000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -32.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2838\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.51000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  944\n",
      "\n",
      "Episode reward :  -41.51\n",
      "\n",
      " \n",
      " \n",
      " episode :  2839\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  994\n",
      "\n",
      "Episode reward :  -32.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2840\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 -0.04000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -29.18\n",
      "\n",
      " \n",
      " \n",
      " episode :  2841\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.19000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -33.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  2842\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -47.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2843\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  973\n",
      "\n",
      "Episode reward :  -28.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  2844\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.02000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.30000 0.03000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -29.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2845\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  2846\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.26000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  948\n",
      "\n",
      "Episode reward :  -28.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2847\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 0.00000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -30.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2848\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.75\n",
      "\n",
      " \n",
      " \n",
      " episode :  2849\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2850\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  955\n",
      "\n",
      "Episode reward :  -29.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2851\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -29.35\n",
      "\n",
      " \n",
      " \n",
      " episode :  2852\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.11000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -29.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2853\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  955\n",
      "\n",
      "Episode reward :  -28.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2854\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2855\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2856\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -28.05\n",
      "\n",
      " \n",
      " \n",
      " episode :  2857\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  944\n",
      "\n",
      "Episode reward :  -27.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2858\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.28000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  944\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2859\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  943\n",
      "\n",
      "Episode reward :  -28.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  2860\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -29.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2861\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.03000 -0.03000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.52000 -0.04000]\n",
      " done   :  False\n",
      "   _std :  0.012\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -31.34\n",
      "\n",
      " \n",
      " \n",
      " episode :  2862\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.43\n",
      "\n",
      " \n",
      " \n",
      " episode :  2863\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.23000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -30.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2864\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  2865\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.012\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -29.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  2866\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.62\n",
      "\n",
      " \n",
      " \n",
      " episode :  2867\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  960\n",
      "\n",
      "Episode reward :  -28.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2868\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.10000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  951\n",
      "\n",
      "Episode reward :  -28.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2869\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  986\n",
      "\n",
      "Episode reward :  -29.49\n",
      "\n",
      " \n",
      " \n",
      " episode :  2870\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.27000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -29.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  2871\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  952\n",
      "\n",
      "Episode reward :  -28.36\n",
      "\n",
      " \n",
      " \n",
      " episode :  2872\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -29.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2873\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2874\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -28.07\n",
      "\n",
      " \n",
      " \n",
      " episode :  2875\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2876\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.28000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  2877\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -29.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2878\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -29.4\n",
      "\n",
      " \n",
      " \n",
      " episode :  2879\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2880\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.02000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.82\n",
      "\n",
      " \n",
      " \n",
      " episode :  2881\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.30000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  2882\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.11\n",
      "\n",
      " \n",
      " \n",
      " episode :  2883\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2884\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.12\n",
      "\n",
      " \n",
      " \n",
      " episode :  2885\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2886\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.36000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2887\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.05000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2888\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -28.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  2889\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2890\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2891\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.34000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -28.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  2892\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.42000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.71\n",
      "\n",
      " \n",
      " \n",
      " episode :  2893\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2894\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -27.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2895\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2896\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2897\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  944\n",
      "\n",
      "Episode reward :  -29.56\n",
      "\n",
      " \n",
      " \n",
      " episode :  2898\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -33.87\n",
      "\n",
      " \n",
      " \n",
      " episode :  2899\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -31.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  2900\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -34.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2901\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -31.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2902\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -30.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2903\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -29.97\n",
      "\n",
      " \n",
      " \n",
      " episode :  2904\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -30.2\n",
      "\n",
      " \n",
      " \n",
      " episode :  2905\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.47000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -30.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2906\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -29.65\n",
      "\n",
      " \n",
      " \n",
      " episode :  2907\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  927\n",
      "\n",
      "Episode reward :  -28.98\n",
      "\n",
      " \n",
      " \n",
      " episode :  2908\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.37000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  926\n",
      "\n",
      "Episode reward :  -29.17\n",
      "\n",
      " \n",
      " \n",
      " episode :  2909\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.48000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  925\n",
      "\n",
      "Episode reward :  -29.16\n",
      "\n",
      " \n",
      " \n",
      " episode :  2910\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  925\n",
      "\n",
      "Episode reward :  -29.24\n",
      "\n",
      " \n",
      " \n",
      " episode :  2911\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  925\n",
      "\n",
      "Episode reward :  -29.38\n",
      "\n",
      " \n",
      " \n",
      " episode :  2912\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -29.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2913\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -29.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  2914\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -28.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2915\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.18000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  925\n",
      "\n",
      "Episode reward :  -30.96\n",
      "\n",
      " \n",
      " \n",
      " episode :  2916\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.03000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -29.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2917\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  941\n",
      "\n",
      "Episode reward :  -28.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2918\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.08000 -0.05000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  942\n",
      "\n",
      "Episode reward :  -28.48\n",
      "\n",
      " \n",
      " \n",
      " episode :  2919\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.36000 -0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  944\n",
      "\n",
      "Episode reward :  -28.13\n",
      "\n",
      " \n",
      " \n",
      " episode :  2920\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.37000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2921\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.15000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2922\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  2923\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2924\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.40000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2925\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.55000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2926\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.48000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2927\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  987\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2928\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.22000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2929\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.42000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.21\n",
      "\n",
      " \n",
      " \n",
      " episode :  2930\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 -0.02000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2931\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.11000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  993\n",
      "\n",
      "Episode reward :  -27.9\n",
      "\n",
      " \n",
      " \n",
      " episode :  2932\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 -0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  954\n",
      "\n",
      "Episode reward :  -27.92\n",
      "\n",
      " \n",
      " \n",
      " episode :  2933\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 -0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  2934\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.33000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -28.04\n",
      "\n",
      " \n",
      " \n",
      " episode :  2935\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2936\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -127.69\n",
      "\n",
      " \n",
      " \n",
      " episode :  2937\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.07000 0.02000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2938\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.02000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.01000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -28.94\n",
      "\n",
      " \n",
      " \n",
      " episode :  2939\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  959\n",
      "\n",
      "Episode reward :  -28.23\n",
      "\n",
      " \n",
      " \n",
      " episode :  2940\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.17000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2941\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  956\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2942\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.24000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  939\n",
      "\n",
      "Episode reward :  -27.7\n",
      "\n",
      " \n",
      " \n",
      " episode :  2943\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  940\n",
      "\n",
      "Episode reward :  -27.68\n",
      "\n",
      " \n",
      " \n",
      " episode :  2944\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.04000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.8\n",
      "\n",
      " \n",
      " \n",
      " episode :  2945\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.39000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2946\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.28\n",
      "\n",
      " \n",
      " \n",
      " episode :  2947\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.09000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  2948\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.18000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.39\n",
      "\n",
      " \n",
      " \n",
      " episode :  2949\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.52\n",
      "\n",
      " \n",
      " \n",
      " episode :  2950\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2951\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.10000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -28.01\n",
      "\n",
      " \n",
      " \n",
      " episode :  2952\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.53000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.88\n",
      "\n",
      " \n",
      " \n",
      " episode :  2953\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.09000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.02\n",
      "\n",
      " \n",
      " \n",
      " episode :  2954\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2955\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.12000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2956\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.66\n",
      "\n",
      " \n",
      " \n",
      " episode :  2957\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.16000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.63\n",
      "\n",
      " \n",
      " \n",
      " episode :  2958\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  2959\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.44000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.57\n",
      "\n",
      " \n",
      " \n",
      " episode :  2960\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.68000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.5\n",
      "\n",
      " \n",
      " \n",
      " episode :  2961\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.35000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.73\n",
      "\n",
      " \n",
      " \n",
      " episode :  2962\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.04000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2963\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.12000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  933\n",
      "\n",
      "Episode reward :  -27.59\n",
      "\n",
      " \n",
      " \n",
      " episode :  2964\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.61\n",
      "\n",
      " \n",
      " \n",
      " episode :  2965\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.21000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.41\n",
      "\n",
      " \n",
      " \n",
      " episode :  2966\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -27.33\n",
      "\n",
      " \n",
      " \n",
      " episode :  2967\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.45\n",
      "\n",
      " \n",
      " \n",
      " episode :  2968\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.21000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.6\n",
      "\n",
      " \n",
      " \n",
      " episode :  2969\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.29000 -0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2970\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.34000 0.02000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2971\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.45000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2972\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  930\n",
      "\n",
      "Episode reward :  -27.84\n",
      "\n",
      " \n",
      " \n",
      " episode :  2973\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  931\n",
      "\n",
      "Episode reward :  -27.77\n",
      "\n",
      " \n",
      " \n",
      " episode :  2974\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.17000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -27.86\n",
      "\n",
      " \n",
      " \n",
      " episode :  2975\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  928\n",
      "\n",
      "Episode reward :  -27.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2976\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  934\n",
      "\n",
      "Episode reward :  -27.99\n",
      "\n",
      " \n",
      " \n",
      " episode :  2977\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.06000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  935\n",
      "\n",
      "Episode reward :  -28.0\n",
      "\n",
      " \n",
      " \n",
      " episode :  2978\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.05000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.19\n",
      "\n",
      " \n",
      " \n",
      " episode :  2979\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.01000 0.04000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  932\n",
      "\n",
      "Episode reward :  -28.78\n",
      "\n",
      " \n",
      " \n",
      " episode :  2980\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -28.46\n",
      "\n",
      " \n",
      " \n",
      " episode :  2981\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 0.03000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  929\n",
      "\n",
      "Episode reward :  -28.06\n",
      "\n",
      " \n",
      " \n",
      " episode :  2982\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.51000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  936\n",
      "\n",
      "Episode reward :  -27.93\n",
      "\n",
      " \n",
      " \n",
      " episode :  2983\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.03000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2984\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.89\n",
      "\n",
      " \n",
      " \n",
      " episode :  2985\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -28.08\n",
      "\n",
      " \n",
      " \n",
      " episode :  2986\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.13000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.85\n",
      "\n",
      " \n",
      " \n",
      " episode :  2987\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.13000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.79\n",
      "\n",
      " \n",
      " \n",
      " episode :  2988\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.07000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2989\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.20000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.76\n",
      "\n",
      " \n",
      " \n",
      " episode :  2990\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.06000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.83\n",
      "\n",
      " \n",
      " \n",
      " episode :  2991\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.14000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.81\n",
      "\n",
      " \n",
      " \n",
      " episode :  2992\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.74\n",
      "\n",
      " \n",
      " \n",
      " episode :  2993\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.38000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2994\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.01000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.47\n",
      "\n",
      " \n",
      " \n",
      " episode :  2995\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.02000 0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.42\n",
      "\n",
      " \n",
      " \n",
      " episode :  2996\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.08000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.27\n",
      "\n",
      " \n",
      " \n",
      " episode :  2997\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.00000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.19000 -0.01000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  937\n",
      "\n",
      "Episode reward :  -27.3\n",
      "\n",
      " \n",
      " \n",
      " episode :  2998\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.05000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [-0.23000 -0.00000]\n",
      " done   :  True\n",
      "   _std :  0.011\n",
      "episode length :  938\n",
      "\n",
      "Episode reward :  -27.67\n",
      "\n",
      " \n",
      " \n",
      " episode :  2999\n",
      " step   :  [0.00000 0.00000]\n",
      " state  :  [-0.01000 -0.04000]\n",
      " step a :  [0.00000 0.00000]\n",
      " action :  [0.14000 -0.04000]\n",
      " done   :  False\n",
      "   _std :  0.011\n",
      "episode length :  1000\n",
      "\n",
      "Episode reward :  -29.36\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\zhuxinji\\\\Desktop\\\\zhuxinji\\\\actor-critic\\\\DDPG\\\\2_Federated RL_home/data/mat/reward_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# creating the buffer which is used to save the tranistions [s, a, s', r, done]\u001b[39;00m\n\u001b[0;32m     22\u001b[0m buffer \u001b[38;5;241m=\u001b[39m bf\u001b[38;5;241m.\u001b[39mReplayBuffer(state_dim_, action_dim_, buffer_size)  \n\u001b[1;32m---> 24\u001b[0m \u001b[43mactor_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcstr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mddpg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# batch size used to update the actor-critic.\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# warm-up episodes till episode_length episodes there is no update in the actor-critic network. \u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#episode_length,\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# totoal number of episodes used to train the actor-critic network.\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_ep_training\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 220\u001b[0m, in \u001b[0;36mactor_training\u001b[1;34m(env, policy, batch_size, replay_buffer, start_timesteps, total_ep_training)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mprint\u001b[39m() \n\u001b[0;32m    219\u001b[0m file  \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mglobal_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/mat/reward_list.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 220\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mep_reward_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m    222\u001b[0m dir_l \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mglobal_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    223\u001b[0m policy\u001b[38;5;241m.\u001b[39msave(dir_l, \u001b[38;5;241m17\u001b[39m) \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\npyio.py:1556\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1553\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_string_like(fname):\n\u001b[0;32m   1555\u001b[0m     \u001b[38;5;66;03m# datasource doesn't support creating a new file ...\u001b[39;00m\n\u001b[1;32m-> 1556\u001b[0m     \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1557\u001b[0m     fh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m_datasource\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[0;32m   1558\u001b[0m     own_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\zhuxinji\\\\Desktop\\\\zhuxinji\\\\actor-critic\\\\DDPG\\\\2_Federated RL_home/data/mat/reward_list.csv'"
     ]
    }
   ],
   "source": [
    "## second-order cstr example\n",
    "    ## creating the environment. \n",
    "    cstr = e.cstr_env() \n",
    "\n",
    "    state_dim_ = cstr.observation_space.shape[0] \n",
    "    action_dim_ = cstr.action_space.shape[0]  \n",
    "\n",
    "    print(\"state dim : \", state_dim_) \n",
    "    print(\"action dim : \", action_dim_ )   \n",
    "    \n",
    "    # create the DDPG object. \n",
    "    ddpg = dg.DDPG( \n",
    "            state_dim=state_dim_, \n",
    "            action_dim=action_dim_, \n",
    "            discount=1, \n",
    "            tau=0.001\n",
    "        )    \n",
    "\n",
    "    ## buffer size \n",
    "    buffer_size = int(1e6)  \n",
    "\n",
    "    # creating the buffer which is used to save the tranistions [s, a, s', r, done]\n",
    "    buffer = bf.ReplayBuffer(state_dim_, action_dim_, buffer_size)  \n",
    "\n",
    "    actor_training( \n",
    "        env= cstr,\n",
    "        policy= ddpg,\n",
    "        # batch size used to update the actor-critic.\n",
    "        batch_size= 256,\n",
    "        replay_buffer= buffer,\n",
    "        # warm-up episodes till episode_length episodes there is no update in the actor-critic network. \n",
    "        start_timesteps=  1000, #episode_length,\n",
    "        # totoal number of episodes used to train the actor-critic network.\n",
    "        total_ep_training = 3000 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93a2f880-5c22-4ded-b1e8-0e866706606a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb699a05c0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange[0:1500000], ddpg.critic_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d3e51a0-c86a-4a67-b54e-0577f564a4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb6940f350>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange[:1500000], ddpg.actor_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad9e59c-5332-4a61-9bf9-2994e24dbbce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
