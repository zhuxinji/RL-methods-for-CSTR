{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ac5833c-5ded-406e-ac52-41350c82cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b7629042-5a6e-479c-b7c0-88305ec82066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network for NAF\n",
    "class NAFNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(NAFNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "\n",
    "        self.fc_value = nn.Linear(256, 1)\n",
    "        self.fc_mu = nn.Linear(256, action_size)\n",
    "        self.fc_l = nn.Linear(256, action_size * action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "\n",
    "        value = self.fc_value(x)\n",
    "        mu = torch.tanh(self.fc_mu(x))*torch.tensor([1, 0.167])\n",
    "        l = self.fc_l(x)\n",
    "\n",
    "        l_matrix = l.view(-1, action_size, action_size)\n",
    "        l_matrix = torch.tril(l_matrix, -1) + torch.diag_embed(torch.exp(torch.diagonal(l_matrix, dim1=-2, dim2=-1)))\n",
    "        p_matrix = torch.bmm(l_matrix, l_matrix.transpose(2, 1))\n",
    "\n",
    "        return value, mu, p_matrix\n",
    "\n",
    "    def q_value(self, state, action):\n",
    "        value, mu, p_matrix = self.forward(state)\n",
    "        action_diff = action - mu\n",
    "        advantage = -0.5 * torch.bmm(action_diff.unsqueeze(1), torch.bmm(p_matrix, action_diff.unsqueeze(2))).squeeze(2)\n",
    "        q_value = value + advantage\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f277494d-0c7f-441e-8e6f-daa020fa580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, size):\n",
    "        self.memory = deque(maxlen=size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.memory.append(experience)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8bf41011-f469-4b54-a33e-888854179614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    if len(memory) < batch_size*10:\n",
    "        return\n",
    "\n",
    "    minibatch = memory.sample(batch_size)\n",
    "    states = torch.FloatTensor([e[0] for e in minibatch])\n",
    "    actions = torch.FloatTensor([e[1] for e in minibatch])\n",
    "    rewards = torch.FloatTensor([e[2] for e in minibatch])\n",
    "    next_states = torch.FloatTensor([e[3] for e in minibatch])\n",
    "    dones = torch.FloatTensor([e[4] for e in minibatch])\n",
    "\n",
    "    q_values = naf_network.q_value(states, actions)\n",
    "    next_actions = target_naf_network(next_states)[1]\n",
    "    next_q_values = target_naf_network.q_value(next_states, next_actions)\n",
    "    target_q_values = rewards.unsqueeze(1) + (1 - dones).unsqueeze(1) * discount_factor * next_q_values\n",
    "\n",
    "    loss = loss_fn(q_values, target_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    for target_param, param in zip(target_naf_network.parameters(), naf_network.parameters()):\n",
    "        target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5fbc1d7d-3a4b-4c0a-8b48-583b9db8785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    state = torch.FloatTensor(state).unsqueeze(0)\n",
    "    _, mu, _ = naf_network(state)\n",
    "    return mu.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f4ae35a-d5ee-49e3-8955-e623fe4171e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cstr_env(gym.Env):\n",
    "\n",
    "    def __init__(self): \n",
    "        # Define action & observation space   \n",
    "        self.action_space = spaces.Box(low = np.array([-1.0, -1.0], dtype=np.float32), \n",
    "                                       high = np.array([1.0 , 1.0], dtype=np.float32), \n",
    "                                       dtype=np.float32, shape=(2, ))   \n",
    "        self.observation_space = spaces.Box(low=np.array([-1.0, -1.0], dtype=np.float32), \n",
    "                                            high=np.array([1.0, 1.0], dtype=np.float32), \n",
    "                                            dtype=np.float32, shape=(2, ))\n",
    "        self.n_episode = 0 # current episode number.\n",
    "\n",
    "        \n",
    "    def is_done(self, x_next):\n",
    "        done = False\n",
    "        c1 = (abs(x_next[0] - self.setpoint_states[0]) < 0.01)\n",
    "        c2 = (abs(x_next[1] - self.setpoint_states[1]) < 0.01)\n",
    "        steady_state = c1 and c2  \n",
    "\n",
    "        # Record the steady state status for the current step\n",
    "        self.goal_state_done[self.ep_step] = steady_state\n",
    "        \n",
    "        # Check if there are at least 4 previous steps\n",
    "        if self.ep_step > 3: \n",
    "            # Get the steady state status for the last three steps\n",
    "            p3 = self.goal_state_done[self.ep_step-2] \n",
    "            p2 = self.goal_state_done[self.ep_step-1] \n",
    "            p1 = self.goal_state_done[self.ep_step-0] \n",
    "            # If the last three steps were steady states, set 'done' to True\n",
    "            if  p3 and p2 and p1:\n",
    "                done = True  \n",
    "        return done \n",
    "\n",
    "    \n",
    "    def get_dx(self, x, u):\n",
    "        Q = torch.tensor([[9.35, 0.41], [0.41, 0.02]])\n",
    "        R = torch.tensor([[1/500, 0], [0, 1/100]])\n",
    "        P = torch.tensor([[9.35, 0.41], [0.41, 0.02]])\n",
    "        \n",
    "        params = [0.5734, 395.3268, 100e-3, 0.1, 72e+9, 8.314e+4, 8.314, 310, -4.78e+4, 0.239, 1000, 1]\n",
    "        CAs, Ts, CF, CV, Ck0, CE, CR, CT0, CDh, Ccp, Crho, CA0s = params                   \n",
    "        g1, g2 = CF/CV, 1/(Crho*Ccp*CV)\n",
    "        x1, x2 = x[0], x[1]\n",
    "        \n",
    "        f1 = (CF/CV)*(-x1) - Ck0*np.exp(-CE/(CR*(x2+Ts))) * (x1+CAs)+(CF/CV) * (CA0s-CAs)\n",
    "        f2 = (CF/CV)*(-x2) + (-CDh/(Crho*Ccp))*Ck0*np.exp(-CE/(CR*(x2+Ts)))*(x1+CAs) + CF*(CT0-Ts)/CV\n",
    "        dx = [f1, f2] + u*[g1, g2]\n",
    "        return dx\n",
    "\n",
    "    \n",
    "    def step(self, action):\n",
    "        dt = 5e-3\n",
    "        self.current_u = action\n",
    "        state = self.current_s\n",
    "        x_next = self.current_s + dt*self.get_dx(self.current_s, action)\n",
    "        done = self.is_done(x_next) \n",
    "        reward = -np.sum((x_next - self.setpoint_states)**2)*0.01 + np.sum((self.current_u - self.setpoint_actions)**2)  \n",
    " \n",
    "        # changing the previous state to the current state. \n",
    "        self.previous_u = self.current_u \n",
    "        # changing the current state to next state\n",
    "        self.current_s = x_next \n",
    "        # increase the step by one \n",
    "        self.ep_step += 1  \n",
    "\n",
    "        # this is the trancated condition. \n",
    "        trancated = False \n",
    "        if self.ep_step == episode_length:\n",
    "            trancated = True\n",
    "\n",
    "        if self.ep_step == episode_length-1 or done:      \n",
    "            self.n_episode += 1 \n",
    "        \n",
    "        # if done is true i.e. terminated is equal to done. \n",
    "        terminated = done\n",
    "\n",
    "        return x_next, reward, done\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.ep_step = 0 \n",
    "        self.current_u= None \n",
    "        self.previous_u = None \n",
    "        self.current_s = None \n",
    "\n",
    "        ## list of true false which stores the weather the state is near to the goal state or not. \n",
    "        self.goal_state_done = [False] * (episode_length+5)\n",
    "\n",
    "        self.setpoint_states = None\n",
    "        self.setpoint_actions = None \n",
    "\n",
    "        ## this function is set the setpoint for the current state and actions. \n",
    "        self.setpoint_states  =  np.array([.0, .0], dtype=float)     \n",
    "        self.setpoint_actions =  np.array([.0, .0], dtype=float)\n",
    "\n",
    "        # this is the fixed initial state. \n",
    "        state, action = np.array([0.2, -5]),  np.array([1.5, 0.1]) \n",
    "\n",
    "        self.current_u = action \n",
    "        self.previous_u = action  \n",
    "        self.current_s = state  \n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9640bf2-ffde-400c-bd69-955b7dfb1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-4\n",
    "discount_factor = 0.99\n",
    "batch_size = 256\n",
    "tau = 0.001\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.01\n",
    "memory_size = 100000\n",
    "num_episodes = 3000\n",
    "episode_length = num_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b119a2-3554-4cd6-acc1-0d4515cf9e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/3000, Reward: -5239.6881169957305, done: False\n",
      "state: [  0.27954507 -63.21722602], action: [ 0.22517358 -0.39738828]\n",
      "Episode: 2/3000, Reward: -3907.569274965583, done: False\n",
      "state: [  0.30741021 -59.14238107], action: [-0.66914266 -0.22523071]\n",
      "Episode: 3/3000, Reward: -6812.965087777302, done: False\n",
      "state: [  0.36885861 -66.80320907], action: [-0.97807145 -0.83533347]\n",
      "Episode: 4/3000, Reward: -5554.499742730859, done: False\n",
      "state: [  0.32082394 -63.98188787], action: [0.25814047 0.97887915]\n",
      "Episode: 5/3000, Reward: -6613.8933134667195, done: False\n",
      "state: [  0.26951161 -66.37712568], action: [-0.05953976 -0.9532626 ]\n",
      "Episode: 6/3000, Reward: -6837.878454153776, done: False\n",
      "state: [  0.32616873 -66.74862398], action: [-0.51179653 -0.86600846]\n",
      "Episode: 7/3000, Reward: -5384.213796864692, done: False\n",
      "state: [  0.36175728 -63.48980431], action: [0.23639834 0.94055015]\n",
      "Episode: 8/3000, Reward: -7613.589143012114, done: False\n",
      "state: [  0.37240414 -68.27154159], action: [-0.17893514 -0.90554047]\n",
      "Episode: 9/3000, Reward: -25153.570908018253, done: False\n",
      "state: [ -0.56341999 111.46015676], action: [ 0.908821  -0.1695281]\n",
      "Episode: 10/3000, Reward: -37385.995173729236, done: False\n",
      "state: [ -0.57238241 111.84431018], action: [-0.7915634  -0.15548606]\n",
      "Episode: 11/3000, Reward: -1562.9125380933344, done: False\n",
      "state: [  0.32054987 -46.60637071], action: [-0.41451085  0.20893076]\n",
      "Episode: 12/3000, Reward: -32614.050796747157, done: False\n",
      "state: [ -0.5682045  105.81975932], action: [ 0.01826294 -0.775587  ]\n",
      "Episode: 13/3000, Reward: -33875.83248525464, done: False\n",
      "state: [ -0.56940033 115.1715421 ], action: [-0.05417474  0.2983299 ]\n",
      "Episode: 14/3000, Reward: -5675.567135773915, done: False\n",
      "state: [  0.42685636 -64.1856826 ], action: [ 0.62567365 -0.42980176]\n",
      "Episode: 15/3000, Reward: -43000.22052615567, done: False\n",
      "state: [-0.56400489 97.55785594], action: [ 0.45507994 -0.19505426]\n",
      "Episode: 16/3000, Reward: -38986.317784965075, done: False\n",
      "state: [ -0.56716577 110.35590952], action: [0.107861   0.81800306]\n",
      "Episode: 17/3000, Reward: -48594.51763610302, done: False\n",
      "state: [ -0.57344395 113.44655071], action: [-0.988396   -0.13788249]\n",
      "Episode: 18/3000, Reward: -43380.756903317575, done: False\n",
      "state: [ -0.57291486 102.44810916], action: [-1.    -0.167]\n",
      "Episode: 19/3000, Reward: -39804.498154387584, done: False\n",
      "state: [ -0.57047782 107.05530039], action: [-0.7272254  0.1407749]\n",
      "Episode: 20/3000, Reward: -34992.084022811905, done: False\n",
      "state: [-0.5641087  99.81209619], action: [0.5701962  0.89231837]\n",
      "Episode: 21/3000, Reward: -51414.421329812525, done: False\n",
      "state: [ -0.57032268 105.00872537], action: [-0.44241866 -0.77428406]\n",
      "Episode: 22/3000, Reward: -2073.0897667156178, done: False\n",
      "state: [  0.37626976 -50.23036937], action: [0.5091449  0.24261092]\n",
      "Episode: 23/3000, Reward: -41925.733697941156, done: False\n",
      "state: [-0.56779762 94.98901517], action: [-0.41141284 -0.13973837]\n",
      "Episode: 24/3000, Reward: -3017.051374290222, done: False\n",
      "state: [  0.40083544 -55.02434739], action: [ 0.27441508 -0.14635889]\n",
      "Episode: 25/3000, Reward: -28594.091041112588, done: False\n",
      "state: [ -0.56525086 107.51698976], action: [0.50327647 0.40550032]\n",
      "Episode: 26/3000, Reward: -41168.33444746627, done: False\n",
      "state: [-0.55726093 83.90027474], action: [0.90024745 0.1807686 ]\n",
      "Episode: 27/3000, Reward: -43888.356211280865, done: False\n",
      "state: [-0.56386475 88.07924412], action: [0.12967484 0.74273145]\n",
      "Episode: 28/3000, Reward: -43570.89186197396, done: False\n",
      "state: [ -0.56128823 103.49749232], action: [ 0.86954117 -0.29141912]\n",
      "Episode: 29/3000, Reward: -42570.529701580126, done: False\n",
      "state: [-0.57182778 89.74920778], action: [-0.96162575 -0.5856057 ]\n",
      "Episode: 30/3000, Reward: -36129.7279574561, done: False\n",
      "state: [ -0.56153277 104.74841431], action: [ 0.7069188 -0.9078348]\n",
      "Episode: 31/3000, Reward: -41262.889910142054, done: False\n",
      "state: [-0.57105579 94.93618269], action: [-1.     0.167]\n",
      "Episode: 32/3000, Reward: -46916.37370899484, done: False\n",
      "state: [ -0.56800946 103.7011592 ], action: [-0.09344561 -0.0490927 ]\n",
      "Episode: 33/3000, Reward: -50942.420258334096, done: False\n",
      "state: [ -0.57028969 105.92314472], action: [-0.5456248  -0.11987649]\n",
      "Episode: 34/3000, Reward: -39721.35690285613, done: False\n",
      "state: [ -0.57004641 104.62368181], action: [-0.49522138 -0.7321701 ]\n",
      "Episode: 35/3000, Reward: -41391.57044667263, done: False\n",
      "state: [-0.56972327 94.82326596], action: [-1.     0.167]\n",
      "Episode: 36/3000, Reward: -38899.89411040682, done: False\n",
      "state: [-0.5650157 84.659936 ], action: [-1.     0.167]\n",
      "Episode: 37/3000, Reward: -42084.38494023325, done: False\n",
      "state: [-0.56516633 91.79977395], action: [0.42341438 0.30012316]\n",
      "Episode: 38/3000, Reward: -43119.123486123746, done: False\n",
      "state: [-0.55846154 92.10847706], action: [-0.37639493  0.2113714 ]\n",
      "Episode: 39/3000, Reward: -46543.13487660224, done: False\n",
      "state: [-0.56263298 98.45688705], action: [0.18668935 0.6781048 ]\n",
      "Episode: 40/3000, Reward: -42449.033159926854, done: False\n",
      "state: [-0.55881963 83.39951099], action: [ 0.5815696  -0.44426405]\n",
      "Episode: 41/3000, Reward: -42298.99114195833, done: False\n",
      "state: [-0.55894736 90.42006714], action: [-0.11453174 -0.9726047 ]\n",
      "Episode: 42/3000, Reward: -36854.14289272553, done: False\n",
      "state: [-0.56044596 88.1916195 ], action: [-0.24182358 -0.57822114]\n",
      "Episode: 43/3000, Reward: -41615.92035110115, done: False\n",
      "state: [-0.5613067  82.70570313], action: [-0.9615616   0.74551255]\n",
      "Episode: 44/3000, Reward: -37028.38107296411, done: False\n",
      "state: [-0.56310291 90.31361456], action: [-0.82444495 -0.3931462 ]\n",
      "Episode: 45/3000, Reward: -32716.06361454984, done: False\n",
      "state: [-0.55670764 84.21317779], action: [0.54809844 0.65835536]\n",
      "Episode: 46/3000, Reward: -38638.3971026477, done: False\n",
      "state: [-0.5606764  86.22580646], action: [-0.2927171  -0.01277469]\n",
      "Episode: 47/3000, Reward: -38372.94404726659, done: False\n",
      "state: [-0.55507168 89.95392815], action: [0.9240651 0.9235811]\n",
      "Episode: 48/3000, Reward: -36782.22595593136, done: False\n",
      "state: [-0.56034202 91.0092504 ], action: [ 0.5906675  -0.92700595]\n",
      "Episode: 49/3000, Reward: -41798.39948498976, done: False\n",
      "state: [-0.56152754 87.5002586 ], action: [-0.5269815 -0.5343894]\n",
      "Episode: 50/3000, Reward: -40322.07153083402, done: False\n",
      "state: [-0.5681164  82.63963867], action: [-1.     0.167]\n",
      "Episode: 51/3000, Reward: -42880.29600817485, done: False\n",
      "state: [-0.56204824 84.36081794], action: [-0.080746    0.67683786]\n",
      "Episode: 52/3000, Reward: -40216.59671623815, done: False\n",
      "state: [-0.56260123 81.68505499], action: [ 0.34662202 -0.2814856 ]\n",
      "Episode: 53/3000, Reward: -31601.966484843102, done: False\n",
      "state: [-0.55828846 74.93827149], action: [-1.     0.167]\n",
      "Episode: 54/3000, Reward: -40543.9034568564, done: False\n",
      "state: [-0.56419725 86.04252836], action: [-0.09059194 -0.61513233]\n",
      "Episode: 55/3000, Reward: -41932.702644146586, done: False\n",
      "state: [-0.55748457 87.85650298], action: [ 0.06521126 -0.3639059 ]\n",
      "Episode: 56/3000, Reward: -33370.13156072517, done: False\n",
      "state: [-0.55843233 92.47279509], action: [ 0.8710377  -0.13798995]\n",
      "Episode: 57/3000, Reward: -38466.26474085518, done: False\n",
      "state: [-0.55631503 78.50344183], action: [-0.77283186  0.36060515]\n",
      "Episode: 58/3000, Reward: -37270.44513986389, done: False\n",
      "state: [-0.566773   84.67622447], action: [-1.     0.167]\n",
      "Episode: 59/3000, Reward: -41364.11449584784, done: False\n",
      "state: [-0.56647887 80.4146011 ], action: [-1.     0.167]\n",
      "Episode: 60/3000, Reward: -35800.64314992654, done: False\n",
      "state: [-0.55219265 76.00674879], action: [ 0.95917404 -0.27270833]\n",
      "Episode: 61/3000, Reward: -33915.71560284245, done: False\n",
      "state: [-0.54397009 71.4035305 ], action: [0.10924715 0.99045324]\n",
      "Episode: 62/3000, Reward: -36141.93412404728, done: False\n",
      "state: [-0.55814399 72.64233933], action: [-1.     0.167]\n",
      "Episode: 63/3000, Reward: -30962.129726868283, done: False\n",
      "state: [-0.56457889 67.20092287], action: [-1.     0.167]\n",
      "Episode: 64/3000, Reward: -34859.22203529373, done: False\n",
      "state: [-0.55678921 77.32794042], action: [ 0.6472238  -0.71098584]\n",
      "Episode: 65/3000, Reward: -29196.857386730077, done: False\n",
      "state: [-0.53773995 57.99777285], action: [-1.     0.167]\n",
      "Episode: 66/3000, Reward: -35851.399912822875, done: False\n",
      "state: [-0.56073581 71.14007281], action: [-0.00183329 -0.88677365]\n",
      "Episode: 67/3000, Reward: -29364.80743380675, done: False\n",
      "state: [-0.54602601 68.10141977], action: [-0.5278745 -0.4804952]\n",
      "Episode: 68/3000, Reward: -31709.450581808924, done: False\n",
      "state: [-0.56322108 66.29192491], action: [-0.96659565 -0.7768279 ]\n",
      "Episode: 69/3000, Reward: -34825.03792285371, done: False\n",
      "state: [-0.54226618 62.22156469], action: [-0.3325027  -0.00185373]\n",
      "Episode: 70/3000, Reward: -32152.93926145142, done: False\n",
      "state: [-0.54962758 66.42706091], action: [-0.3835407   0.49760762]\n",
      "Episode: 71/3000, Reward: -27326.067483970288, done: False\n",
      "state: [-0.56168461 59.54841022], action: [-1.     0.167]\n",
      "Episode: 72/3000, Reward: -30445.374427983905, done: False\n",
      "state: [-0.54252007 61.55819256], action: [0.31641743 0.53953415]\n",
      "Episode: 73/3000, Reward: -36336.19960919606, done: False\n",
      "state: [-0.54235482 65.25907916], action: [-0.7157042  0.8266907]\n",
      "Episode: 74/3000, Reward: -35126.638490914636, done: False\n",
      "state: [-0.55405321 68.556101  ], action: [-0.8704036   0.09582192]\n",
      "Episode: 75/3000, Reward: -33741.260151835835, done: False\n",
      "state: [-0.52737657 61.29062407], action: [-0.06289847 -0.95634687]\n",
      "Episode: 76/3000, Reward: -33212.94285884508, done: False\n",
      "state: [-0.55732298 64.86285606], action: [-1.     0.167]\n",
      "Episode: 77/3000, Reward: -32650.647047585477, done: False\n",
      "state: [-0.5586092  64.65207729], action: [-1.     0.167]\n",
      "Episode: 78/3000, Reward: -34846.18768050709, done: False\n",
      "state: [-0.5534511  69.75947832], action: [-0.9740173  -0.10197596]\n",
      "Episode: 79/3000, Reward: -44170.17218141373, done: False\n",
      "state: [  0.78766203 -92.93948103], action: [-0.793883   -0.10385612]\n",
      "Episode: 80/3000, Reward: -27335.366521847405, done: False\n",
      "state: [-0.53634529 57.87318271], action: [0.54286456 0.10826077]\n",
      "Episode: 81/3000, Reward: -26978.150882198664, done: False\n",
      "state: [-0.53822236 59.40272321], action: [-1.     0.167]\n",
      "Episode: 82/3000, Reward: -31457.54213798136, done: False\n",
      "state: [-0.54206898 59.32741149], action: [0.45204145 0.95352596]\n",
      "Episode: 83/3000, Reward: -31471.969787802118, done: False\n",
      "state: [-0.54179465 57.66916678], action: [ 0.89554507 -0.17098726]\n",
      "Episode: 84/3000, Reward: -33173.73380169478, done: False\n",
      "state: [-0.55346905 65.84357869], action: [0.830164  0.9332783]\n",
      "Episode: 85/3000, Reward: -32678.011160724127, done: False\n",
      "state: [-0.53882802 61.00195752], action: [-1.     0.167]\n",
      "Episode: 86/3000, Reward: -27619.58716546179, done: False\n",
      "state: [-0.52650495 47.49677471], action: [ 0.8959222 -0.5585294]\n",
      "Episode: 87/3000, Reward: -29610.968384701056, done: False\n",
      "state: [-0.54789616 55.08964642], action: [-1.     0.167]\n",
      "Episode: 88/3000, Reward: -32413.409900611266, done: False\n",
      "state: [-0.53400055 47.2972729 ], action: [-0.25048408  0.32610974]\n",
      "Episode: 89/3000, Reward: -25100.659154398872, done: False\n",
      "state: [-0.48499751 41.6213421 ], action: [-1.     0.167]\n",
      "Episode: 90/3000, Reward: -25010.618977920956, done: False\n",
      "state: [-0.50580389 41.38945369], action: [-0.05428714 -0.14953765]\n",
      "Episode: 91/3000, Reward: -26684.394040449257, done: False\n",
      "state: [-0.54253727 55.44868737], action: [-1.     0.167]\n",
      "Episode: 92/3000, Reward: -28582.663302581666, done: False\n",
      "state: [-0.50842829 42.20030454], action: [-0.5930509 -0.1883636]\n",
      "Episode: 93/3000, Reward: -28232.502348120066, done: False\n",
      "state: [-0.49500641 29.64335736], action: [-0.5966473 -0.5781816]\n",
      "Episode: 94/3000, Reward: -29877.175220771478, done: False\n",
      "state: [-0.53266282 50.93123703], action: [ 0.92193604 -0.69924295]\n",
      "Episode: 95/3000, Reward: -21784.659336538727, done: False\n",
      "state: [-0.51776358 38.96741488], action: [-1.     0.167]\n",
      "Episode: 96/3000, Reward: -24818.045057738003, done: False\n",
      "state: [-0.52497776 53.80630781], action: [ 0.4661448 -0.2969048]\n",
      "Episode: 97/3000, Reward: -20985.4153357397, done: False\n",
      "state: [-0.4713738  27.00197397], action: [-0.16444664 -0.5608687 ]\n",
      "Episode: 98/3000, Reward: -23686.58383032177, done: False\n",
      "state: [-0.50840936 35.53505213], action: [0.23532245 0.20851362]\n",
      "Episode: 99/3000, Reward: -28983.8991764005, done: False\n",
      "state: [-0.5406645  52.56432861], action: [ 0.6748761 -0.4432057]\n",
      "Episode: 100/3000, Reward: -26855.171562516407, done: False\n",
      "state: [-0.53204588 57.73652769], action: [-1.     0.167]\n",
      "Episode: 101/3000, Reward: -30242.036823370167, done: False\n",
      "state: [-0.54127164 56.14864398], action: [-1.     0.167]\n",
      "Episode: 102/3000, Reward: -29495.025463320602, done: False\n",
      "state: [-0.49503171 37.88940386], action: [-1.     0.167]\n",
      "Episode: 103/3000, Reward: -28926.21671357047, done: False\n",
      "state: [-0.53757021 54.06785986], action: [-1.     0.167]\n",
      "Episode: 104/3000, Reward: -22716.44309088171, done: False\n",
      "state: [-0.51543796 50.13276317], action: [-0.98693216 -0.44775417]\n",
      "Episode: 105/3000, Reward: -21878.27430774038, done: False\n",
      "state: [-0.49843927 26.12511907], action: [-0.11066698  0.45252964]\n",
      "Episode: 106/3000, Reward: -19278.123620210925, done: False\n",
      "state: [-0.49698232 19.44914121], action: [-1.     0.167]\n",
      "Episode: 107/3000, Reward: -24165.767558658525, done: False\n",
      "state: [-0.49355472 27.93801785], action: [-1.     0.167]\n",
      "Episode: 108/3000, Reward: -22250.585618338388, done: False\n",
      "state: [-0.51830574 37.37757649], action: [-0.45800662  0.3221061 ]\n",
      "Episode: 109/3000, Reward: -20844.197437675448, done: False\n",
      "state: [-0.47352382 13.02151022], action: [-0.9999995  0.167    ]\n",
      "Episode: 110/3000, Reward: -18486.670147424218, done: False\n",
      "state: [-0.46449956 26.93290685], action: [0.32322285 0.03182318]\n",
      "Episode: 111/3000, Reward: -19745.66357751277, done: False\n",
      "state: [-0.51749207 33.62650504], action: [-0.32462272 -0.04487127]\n",
      "Episode: 112/3000, Reward: -22255.291642878863, done: False\n",
      "state: [-0.4537482  16.13368596], action: [-0.03688608 -0.96942705]\n",
      "Episode: 113/3000, Reward: -19645.643190199524, done: False\n",
      "state: [-0.47723043 26.9970984 ], action: [-0.81483346 -0.9838204 ]\n",
      "Episode: 114/3000, Reward: -23570.603354546893, done: False\n",
      "state: [-0.44871187 19.40851822], action: [-0.9007248   0.70250535]\n",
      "Episode: 115/3000, Reward: -16273.646091600123, done: False\n",
      "state: [-0.4456079  12.79033166], action: [-0.99999976  0.167     ]\n",
      "Episode: 116/3000, Reward: -25943.085160805924, done: False\n",
      "state: [-0.52627717 39.65051553], action: [-0.05765628 -0.37339875]\n",
      "Episode: 117/3000, Reward: -23029.653379548672, done: False\n",
      "state: [-0.48892598 23.05485736], action: [-0.05515691  0.6270431 ]\n",
      "Episode: 118/3000, Reward: -19465.88317631638, done: False\n",
      "state: [-0.36620425  4.70722586], action: [-0.8874057  0.167    ]\n",
      "Episode: 119/3000, Reward: -19229.442761669063, done: False\n",
      "state: [-0.49576047 36.17059994], action: [0.7602511 0.8137468]\n",
      "Episode: 120/3000, Reward: -16503.780296318517, done: False\n",
      "state: [-0.36280336  1.12240538], action: [-0.48664144 -0.7511193 ]\n",
      "Episode: 121/3000, Reward: -20604.20296626972, done: False\n",
      "state: [-0.48911284 21.20046448], action: [-0.07331617  0.64463675]\n",
      "Episode: 122/3000, Reward: -21894.360075529476, done: False\n",
      "state: [-0.46765784 10.75407909], action: [-0.9999997 -0.167    ]\n",
      "Episode: 123/3000, Reward: -19579.032023082484, done: False\n",
      "state: [-0.4841719  14.64927464], action: [-1.    -0.167]\n",
      "Episode: 124/3000, Reward: -22602.102719138613, done: False\n",
      "state: [-0.47904015 20.24164716], action: [-1.    -0.167]\n",
      "Episode: 125/3000, Reward: -21998.84534034106, done: False\n",
      "state: [-0.44436307 16.59396731], action: [-1.    -0.167]\n",
      "Episode: 126/3000, Reward: -20783.12704015276, done: False\n",
      "state: [-0.46110025 15.33685928], action: [-1.    -0.167]\n",
      "Episode: 127/3000, Reward: -20235.71414791586, done: False\n",
      "state: [-0.46583789 22.70259095], action: [-1.    -0.167]\n",
      "Episode: 128/3000, Reward: -16738.397296109288, done: False\n",
      "state: [-0.40485476  4.29699687], action: [ 0.02147949 -0.167     ]\n",
      "Episode: 129/3000, Reward: -18958.314127012494, done: False\n",
      "state: [-0.37830906  3.75469363], action: [ 0.81982976 -0.167     ]\n",
      "Episode: 130/3000, Reward: -23604.984106085638, done: False\n",
      "state: [-0.45295967 13.47812504], action: [-0.9999994 -0.167    ]\n",
      "Episode: 131/3000, Reward: -17104.518312797532, done: False\n",
      "state: [-0.42325855  6.2774109 ], action: [-0.8975508 -0.167    ]\n",
      "Episode: 132/3000, Reward: -17927.456919695403, done: False\n",
      "state: [-0.47510568 20.58370566], action: [-1.    -0.167]\n",
      "Episode: 133/3000, Reward: -15067.015289451178, done: False\n",
      "state: [-0.40322448  4.83582733], action: [-0.5613192  0.8227126]\n",
      "Episode: 134/3000, Reward: -12860.515953024582, done: False\n",
      "state: [-0.34227313  1.88156922], action: [ 0.04486885 -0.10363897]\n",
      "Episode: 135/3000, Reward: -21284.61612651397, done: False\n",
      "state: [-0.43137204 15.4371726 ], action: [0.7248171 0.5651951]\n",
      "Episode: 136/3000, Reward: -17694.180799368965, done: False\n",
      "state: [-0.46538517 26.21395372], action: [-0.79179114  0.70355576]\n",
      "Episode: 137/3000, Reward: -16997.69846848706, done: False\n",
      "state: [-0.40610788 11.06228216], action: [-0.9978231 -0.167    ]\n",
      "Episode: 138/3000, Reward: -18979.38097560083, done: False\n",
      "state: [-0.4320788  10.45886548], action: [-0.97759074 -0.167     ]\n",
      "Episode: 139/3000, Reward: -19163.67658577873, done: False\n",
      "state: [-0.35778313  3.26760125], action: [0.3772716 0.7082967]\n",
      "Episode: 140/3000, Reward: -17564.5433836158, done: False\n",
      "state: [-0.42840334  7.13142323], action: [ 0.8723095 -0.167    ]\n",
      "Episode: 141/3000, Reward: -15478.450638688353, done: False\n",
      "state: [-0.35393733  6.18397322], action: [-0.12875654  0.0739447 ]\n",
      "Episode: 142/3000, Reward: -21701.402577497665, done: False\n",
      "state: [-0.43436603 10.74609471], action: [-0.3170749 -0.167    ]\n",
      "Episode: 143/3000, Reward: -15016.842579234042, done: False\n",
      "state: [-0.09629035  0.67961577], action: [0.47966194 0.8730308 ]\n",
      "Episode: 144/3000, Reward: -19745.035131448614, done: False\n",
      "state: [-0.25805514  5.50347943], action: [ 0.9955854 -0.167    ]\n",
      "Episode: 145/3000, Reward: -20770.144714591876, done: False\n",
      "state: [-0.37281323  8.61900117], action: [ 0.97913736 -0.167     ]\n",
      "Episode: 146/3000, Reward: -19240.528910352987, done: False\n",
      "state: [-0.30678539  8.88817732], action: [ 0.95378184 -0.167     ]\n",
      "Episode: 147/3000, Reward: -15401.647524796344, done: False\n",
      "state: [-0.04723715  0.88599586], action: [-0.07909163 -0.83502024]\n",
      "Episode: 148/3000, Reward: -17082.208626983625, done: False\n",
      "state: [-0.28808312  9.89140999], action: [ 0.27682889 -0.31555825]\n",
      "Episode: 149/3000, Reward: -12081.586718390616, done: False\n",
      "state: [-0.15598149  9.86925576], action: [0.7063408  0.25207925]\n",
      "Episode: 150/3000, Reward: -18424.937856194578, done: False\n",
      "state: [-0.43478388 14.49234719], action: [ 0.8163191 -0.167    ]\n",
      "Episode: 151/3000, Reward: -13802.745037703125, done: False\n",
      "state: [-0.19485692  9.67793127], action: [-0.05055468 -0.167     ]\n",
      "Episode: 152/3000, Reward: -11539.83013071737, done: False\n",
      "state: [-0.21241258  8.90451856], action: [-0.14099887 -0.167     ]\n",
      "Episode: 153/3000, Reward: -11597.298126978441, done: False\n",
      "state: [-0.30112428  9.45822844], action: [ 0.8843057 -0.4744585]\n",
      "Episode: 154/3000, Reward: -13784.670935544556, done: False\n",
      "state: [-0.23374267  8.7799317 ], action: [ 0.1589945 -0.167    ]\n",
      "Episode: 155/3000, Reward: -10135.642938455636, done: False\n",
      "state: [-0.16329368  5.51669592], action: [ 0.10795356 -0.167     ]\n",
      "Episode: 156/3000, Reward: -10218.922120510666, done: False\n",
      "state: [-0.21523705  7.6614913 ], action: [-0.14311068 -0.167     ]\n",
      "Episode: 157/3000, Reward: -7348.6780355838955, done: False\n",
      "state: [-0.16151679  4.8904881 ], action: [ 0.4609021  -0.80561614]\n",
      "Episode: 158/3000, Reward: -10164.483652244806, done: False\n",
      "state: [-0.22969742  6.15135382], action: [ 0.52612406 -0.167     ]\n",
      "Episode: 159/3000, Reward: -7141.541268769994, done: False\n",
      "state: [-0.14631937  3.92589854], action: [ 0.24196194 -0.167     ]\n",
      "Episode: 160/3000, Reward: -10885.402427156356, done: False\n",
      "state: [-0.19769084  5.85743494], action: [-0.978935  0.870978]\n",
      "Episode: 161/3000, Reward: -2812.106554730691, done: False\n",
      "state: [-0.09715401  3.22621873], action: [-0.10758341 -0.167     ]\n",
      "Episode: 162/3000, Reward: -6052.981500451366, done: False\n",
      "state: [-0.14026163  3.45792964], action: [-0.3955631   0.14298062]\n",
      "Episode: 163/3000, Reward: -10718.024972153267, done: False\n",
      "state: [-0.17773338  5.45476801], action: [0.82087857 0.01522288]\n",
      "Episode: 164/3000, Reward: -9129.802364929199, done: False\n",
      "state: [-0.14327513  4.64324936], action: [ 0.04056453 -0.167     ]\n",
      "Episode: 165/3000, Reward: -10940.937909753738, done: False\n",
      "state: [-0.21963912  7.07950151], action: [-0.06396436 -0.8228858 ]\n",
      "Episode: 166/3000, Reward: -8022.17201901329, done: False\n",
      "state: [-0.21264978  7.24717295], action: [ 0.07945097 -0.167     ]\n",
      "Episode: 167/3000, Reward: -4335.8836842421615, done: False\n",
      "state: [-0.20957618  7.57638791], action: [-0.18765071 -0.167     ]\n",
      "Episode: 168/3000, Reward: -5867.615572899456, done: False\n",
      "state: [-0.20746406  7.10299323], action: [-0.16304035 -0.167     ]\n",
      "Episode: 169/3000, Reward: -4098.132572521855, done: False\n",
      "state: [-0.21023084  6.27480602], action: [0.9490653  0.15163025]\n",
      "Episode: 170/3000, Reward: -10588.616876576123, done: False\n",
      "state: [-0.28513841 10.32874165], action: [ 0.00700781 -0.167     ]\n",
      "Episode: 171/3000, Reward: -9200.465715586472, done: False\n",
      "state: [-0.23206009  7.09347777], action: [-0.26249585 -0.33481985]\n",
      "Episode: 172/3000, Reward: -9127.981250186831, done: False\n",
      "state: [-0.25164584  8.04352877], action: [ 0.0393572 -0.167    ]\n",
      "Episode: 173/3000, Reward: -5637.999253820569, done: False\n",
      "state: [-0.19872092  5.82767296], action: [ 0.08313624 -0.167     ]\n",
      "Episode: 174/3000, Reward: -5947.554974540921, done: False\n",
      "state: [-0.21529765  6.53024089], action: [ 0.197622 -0.422289]\n",
      "Episode: 175/3000, Reward: -6767.016484625651, done: False\n",
      "state: [-0.22774497  7.81310213], action: [-0.20263816 -0.167     ]\n",
      "Episode: 176/3000, Reward: -9487.169659018706, done: False\n",
      "state: [-0.25731047  8.64358428], action: [ 0.13974115 -0.167     ]\n",
      "Episode: 177/3000, Reward: -3164.4327940025464, done: False\n",
      "state: [-0.22256018  7.65631515], action: [ 0.07068873 -0.167     ]\n",
      "Episode: 178/3000, Reward: -5443.519802553168, done: False\n",
      "state: [-0.23776159  8.83783953], action: [-0.25035572 -0.167     ]\n",
      "Episode: 179/3000, Reward: -6252.527564385655, done: False\n",
      "state: [-0.22920651  8.50995586], action: [ 0.796092   -0.13463774]\n",
      "Episode: 180/3000, Reward: -3906.8517146231793, done: False\n",
      "state: [-0.23270831  8.6154219 ], action: [0.29580155 0.10105787]\n",
      "Episode: 181/3000, Reward: -4595.1031426914105, done: False\n",
      "state: [-0.26189471 10.37403158], action: [-0.20996289 -0.167     ]\n",
      "Episode: 182/3000, Reward: -3495.668237025994, done: False\n",
      "state: [-0.26973669 10.77947488], action: [-0.10182413 -0.167     ]\n",
      "Episode: 183/3000, Reward: -1704.8984275178636, done: False\n",
      "state: [-0.25000164 10.69898766], action: [-0.5080787 -0.167    ]\n",
      "Episode: 184/3000, Reward: -5596.47042400856, done: False\n",
      "state: [-0.26646145 11.54753677], action: [ 0.7668684  -0.97423583]\n",
      "Episode: 185/3000, Reward: -8062.686037544777, done: False\n",
      "state: [-0.2991295  12.80700903], action: [-0.13343456 -0.167     ]\n",
      "Episode: 186/3000, Reward: -5855.248171259082, done: False\n",
      "state: [-0.28536625 12.62684792], action: [0.15590793 0.39562938]\n",
      "Episode: 187/3000, Reward: -3976.4527534248946, done: False\n",
      "state: [-0.31198527 14.0204102 ], action: [-0.6219758  0.1519759]\n",
      "Episode: 188/3000, Reward: -2986.242668305019, done: False\n",
      "state: [-0.30031677 13.89022757], action: [0.4426111 0.3224483]\n",
      "Episode: 189/3000, Reward: -4581.664879146112, done: False\n",
      "state: [-0.31106314 14.48779364], action: [-0.21213883 -0.167     ]\n",
      "Episode: 190/3000, Reward: -2559.938203980612, done: False\n",
      "state: [-0.31360481 15.46679367], action: [0.326975   0.42976686]\n",
      "Episode: 191/3000, Reward: -6148.025640902348, done: False\n",
      "state: [-0.31715422 15.86246004], action: [ 0.35448313 -0.4705939 ]\n",
      "Episode: 192/3000, Reward: -3809.962094949152, done: False\n",
      "state: [-0.3360481  16.56683212], action: [-0.19533655 -0.167     ]\n",
      "Episode: 193/3000, Reward: -6545.433323140881, done: False\n",
      "state: [-0.33793351 16.62357002], action: [-0.25173676  0.17608586]\n",
      "Episode: 194/3000, Reward: -8287.071166405703, done: False\n",
      "state: [-0.33393774 17.03725021], action: [-0.00121821  0.2535186 ]\n",
      "Episode: 195/3000, Reward: -8234.617530964511, done: False\n",
      "state: [-0.34182385 17.7462162 ], action: [-0.3839803 -0.167    ]\n",
      "Episode: 196/3000, Reward: -5164.886982332165, done: False\n",
      "state: [-0.35024925 18.11178606], action: [ 0.5384891 -0.6273321]\n",
      "Episode: 197/3000, Reward: -6590.262474011406, done: False\n",
      "state: [-0.35234898 18.79706379], action: [-0.39116704 -0.167     ]\n",
      "Episode: 198/3000, Reward: -6196.64559217002, done: False\n",
      "state: [-0.35224643 19.83689153], action: [ 0.75052744 -0.38382453]\n",
      "Episode: 199/3000, Reward: -4089.6448174082393, done: False\n",
      "state: [-0.35853256 19.6378168 ], action: [-0.4014086 -0.167    ]\n",
      "Episode: 200/3000, Reward: -3895.555290677641, done: False\n",
      "state: [-0.38433473 21.46347648], action: [-0.294527 -0.167   ]\n",
      "Episode: 201/3000, Reward: -8001.164410827981, done: False\n",
      "state: [-0.37957318 21.05466949], action: [-0.27753648 -0.167     ]\n",
      "Episode: 202/3000, Reward: -6173.312239005576, done: False\n",
      "state: [-0.38188415 21.5412627 ], action: [-0.37513188 -0.167     ]\n",
      "Episode: 203/3000, Reward: -6433.479324227718, done: False\n",
      "state: [-0.37340489 21.57844285], action: [-0.5751989 -0.167    ]\n",
      "Episode: 204/3000, Reward: -4994.342152766054, done: False\n",
      "state: [-0.3929624  22.29947519], action: [-0.37829393 -0.167     ]\n",
      "Episode: 205/3000, Reward: -8072.443633306299, done: False\n",
      "state: [-0.38381701 22.13108157], action: [-0.41790578 -0.167     ]\n",
      "Episode: 206/3000, Reward: -9383.805347452446, done: False\n",
      "state: [-0.38907263 22.84581671], action: [-0.43675336 -0.167     ]\n",
      "Episode: 207/3000, Reward: -10668.666992461332, done: False\n",
      "state: [-0.38921672 23.10544274], action: [-0.6480948 -0.167    ]\n",
      "Episode: 208/3000, Reward: -7200.930694467519, done: False\n",
      "state: [-0.38979261 23.15212439], action: [-0.48960254 -0.167     ]\n",
      "Episode: 209/3000, Reward: -9156.35295955258, done: False\n",
      "state: [-0.395812   23.45687813], action: [-0.44890913 -0.167     ]\n",
      "Episode: 210/3000, Reward: -9477.10703146149, done: False\n",
      "state: [-0.40095829 23.66811078], action: [-0.47814164 -0.167     ]\n",
      "Episode: 211/3000, Reward: -9000.833453439236, done: False\n",
      "state: [-0.40547605 24.31337203], action: [-0.36245963 -0.167     ]\n",
      "Episode: 212/3000, Reward: -7242.84225845841, done: False\n",
      "state: [-0.40476635 26.02871345], action: [-0.92236924 -0.167     ]\n",
      "Episode: 213/3000, Reward: -5471.807118893219, done: False\n",
      "state: [-0.40005163 24.34216488], action: [-0.53614646 -0.167     ]\n",
      "Episode: 214/3000, Reward: -6363.176019034793, done: False\n",
      "state: [-0.41505562 24.661417  ], action: [-0.34033626 -0.167     ]\n",
      "Episode: 215/3000, Reward: -10232.81963381486, done: False\n",
      "state: [-0.40538637 24.44226574], action: [-0.54696745 -0.167     ]\n",
      "Episode: 216/3000, Reward: -8268.27802245182, done: False\n",
      "state: [-0.41141541 24.573022  ], action: [-0.029433 -0.167   ]\n",
      "Episode: 217/3000, Reward: -5090.106996532873, done: False\n",
      "state: [-0.41478148 25.19970232], action: [-0.33160535 -0.167     ]\n",
      "Episode: 218/3000, Reward: -5662.596303725248, done: False\n",
      "state: [-0.41084728 25.76843774], action: [0.9324826  0.04477238]\n",
      "Episode: 219/3000, Reward: -9706.31099343665, done: False\n",
      "state: [-0.42192526 26.76303352], action: [-0.54244727  0.11584229]\n",
      "Episode: 220/3000, Reward: -7799.264227551377, done: False\n",
      "state: [-0.41751504 26.34040003], action: [ 0.87256444 -0.8936857 ]\n",
      "Episode: 221/3000, Reward: -5748.634931639495, done: False\n",
      "state: [-0.42263253 26.56354249], action: [-0.3724803 -0.167    ]\n",
      "Episode: 222/3000, Reward: -8590.474552576938, done: False\n",
      "state: [-0.42257281 27.46496013], action: [-0.6628851 -0.167    ]\n",
      "Episode: 223/3000, Reward: -7516.3486725597695, done: False\n",
      "state: [-0.43030248 27.57464113], action: [-0.37963986 -0.167     ]\n",
      "Episode: 224/3000, Reward: -10849.364178382248, done: False\n",
      "state: [-0.42413643 27.36196675], action: [-0.41607165 -0.167     ]\n",
      "Episode: 225/3000, Reward: -8165.343954915145, done: False\n",
      "state: [-0.43764232 28.4880582 ], action: [-0.83342403  0.47390303]\n",
      "Episode: 226/3000, Reward: -9268.10940627924, done: False\n",
      "state: [-0.42818572 28.2045506 ], action: [ 0.00731207 -0.6435203 ]\n",
      "Episode: 227/3000, Reward: -9980.571367723816, done: False\n",
      "state: [-0.43748805 28.87033488], action: [ 0.53939843 -0.5499103 ]\n",
      "Episode: 228/3000, Reward: -11690.810144682224, done: False\n",
      "state: [-0.43438322 28.5492029 ], action: [-0.38643304 -0.167     ]\n",
      "Episode: 229/3000, Reward: -7113.207819916916, done: False\n",
      "state: [-0.44003272 29.16877889], action: [-0.32679936 -0.167     ]\n",
      "Episode: 230/3000, Reward: -7736.8620731333385, done: False\n",
      "state: [-0.43941775 29.12322704], action: [-0.21496585 -0.167     ]\n",
      "Episode: 231/3000, Reward: -10726.118408908696, done: False\n",
      "state: [-0.44301849 30.11890065], action: [-0.07516719  0.5081098 ]\n",
      "Episode: 232/3000, Reward: -9298.502536706732, done: False\n",
      "state: [-0.44912061 29.9968688 ], action: [-0.22213273 -0.167     ]\n",
      "Episode: 233/3000, Reward: -7266.2895425873185, done: False\n",
      "state: [-0.4466732  30.78495211], action: [-0.6447638 -0.167    ]\n",
      "Episode: 234/3000, Reward: -9273.580842833917, done: False\n",
      "state: [-0.43926925 31.03111369], action: [ 0.71021956 -0.5671197 ]\n",
      "Episode: 235/3000, Reward: -11435.824417491587, done: False\n",
      "state: [-0.45177844 31.03364944], action: [-0.3200877 -0.167    ]\n",
      "Episode: 236/3000, Reward: -8698.635171864526, done: False\n",
      "state: [-0.4490723  31.27562527], action: [-0.5101487 -0.167    ]\n",
      "Episode: 237/3000, Reward: -10826.391822807811, done: False\n",
      "state: [-0.45520084 31.52543238], action: [-0.26616463 -0.167     ]\n",
      "Episode: 238/3000, Reward: -9020.183686760849, done: False\n",
      "state: [-0.45518894 31.37010968], action: [-0.1634228 -0.167    ]\n",
      "Episode: 239/3000, Reward: -9462.918732648208, done: False\n",
      "state: [-0.45490016 31.83436168], action: [-0.3762589 -0.167    ]\n",
      "Episode: 240/3000, Reward: -8698.892361542605, done: False\n",
      "state: [-0.45365322 32.11974894], action: [ 0.19795524 -0.11459607]\n",
      "Episode: 241/3000, Reward: -8753.019636875872, done: False\n",
      "state: [-0.46121511 32.66866235], action: [-0.4076936 -0.167    ]\n",
      "Episode: 242/3000, Reward: -10090.608771347801, done: False\n",
      "state: [-0.46412868 32.81627845], action: [-0.31714696 -0.167     ]\n",
      "Episode: 243/3000, Reward: -8358.494412728109, done: False\n",
      "state: [-0.45841082 32.88920505], action: [-0.48484612 -0.167     ]\n",
      "Episode: 244/3000, Reward: -9197.348588007297, done: False\n",
      "state: [-0.46457422 33.74717528], action: [-0.28654623 -0.167     ]\n",
      "Episode: 245/3000, Reward: -8655.716605673495, done: False\n",
      "state: [-0.46654017 33.9597875 ], action: [-0.4572339 -0.167    ]\n",
      "Episode: 246/3000, Reward: -7631.941099406153, done: False\n",
      "state: [-0.4708583  34.47327732], action: [-0.35457426 -0.167     ]\n",
      "Episode: 247/3000, Reward: -8089.408455784225, done: False\n",
      "state: [-0.46977507 34.66973756], action: [-0.36653492 -0.167     ]\n",
      "Episode: 248/3000, Reward: -10363.968106826025, done: False\n",
      "state: [-0.4680838  34.65250318], action: [-0.27682862 -0.167     ]\n",
      "Episode: 249/3000, Reward: -9071.00182442738, done: False\n",
      "state: [-0.47485672 35.3781612 ], action: [-0.4283374 -0.167    ]\n",
      "Episode: 250/3000, Reward: -8604.454528660843, done: False\n",
      "state: [-0.47893749 35.71058848], action: [-0.9973223  -0.28995228]\n",
      "Episode: 251/3000, Reward: -9539.530242247978, done: False\n",
      "state: [-0.47279116 36.10183141], action: [-0.17055185 -0.54441833]\n",
      "Episode: 252/3000, Reward: -9184.283797767239, done: False\n",
      "state: [-0.47758725 36.35230773], action: [-0.35559928  0.35972843]\n",
      "Episode: 253/3000, Reward: -10016.355440136262, done: False\n",
      "state: [-0.48373317 37.0752084 ], action: [-0.26802447 -0.167     ]\n",
      "Episode: 254/3000, Reward: -10428.62159482988, done: False\n",
      "state: [-0.47587228 36.67260433], action: [-0.26003268 -0.167     ]\n",
      "Episode: 255/3000, Reward: -11194.256567622271, done: False\n",
      "state: [-0.48106512 37.15176232], action: [-0.39554584 -0.167     ]\n",
      "Episode: 256/3000, Reward: -9538.20372607899, done: False\n",
      "state: [-0.48276912 37.50289183], action: [-0.4767928 -0.167    ]\n",
      "Episode: 257/3000, Reward: -11374.643637949, done: False\n",
      "state: [-0.48146764 37.3128138 ], action: [-0.26070836 -0.167     ]\n",
      "Episode: 258/3000, Reward: -8389.256239790919, done: False\n",
      "state: [-0.48445867 38.26959838], action: [ 0.31521007 -0.87704355]\n",
      "Episode: 259/3000, Reward: -9949.984677275, done: False\n",
      "state: [-0.48910609 38.44388825], action: [-0.46788356  0.06473204]\n",
      "Episode: 260/3000, Reward: -10098.066311424785, done: False\n",
      "state: [-0.48466862 39.05256626], action: [0.20174162 0.59923553]\n",
      "Episode: 261/3000, Reward: -9380.661894329376, done: False\n",
      "state: [-0.49225088 39.40663802], action: [-0.44506907 -0.167     ]\n",
      "Episode: 262/3000, Reward: -10093.797525610355, done: False\n",
      "state: [-0.49352223 39.6662765 ], action: [-0.29610434 -0.167     ]\n",
      "Episode: 263/3000, Reward: -9423.242260575707, done: False\n",
      "state: [-0.4919643  40.41995704], action: [-0.4835992 -0.167    ]\n",
      "Episode: 264/3000, Reward: -9626.224536901373, done: False\n",
      "state: [-0.49012727 40.69943596], action: [-0.6029545 -0.167    ]\n",
      "Episode: 265/3000, Reward: -10648.636292633879, done: False\n",
      "state: [-0.49598572 41.01301733], action: [-0.12076622 -0.03644171]\n",
      "Episode: 266/3000, Reward: -9891.414045424524, done: False\n",
      "state: [-0.49885666 41.6444416 ], action: [-0.2931991 -0.167    ]\n",
      "Episode: 267/3000, Reward: -11031.657677902722, done: False\n",
      "state: [-0.49574087 41.30785937], action: [-0.32847813 -0.167     ]\n",
      "Episode: 268/3000, Reward: -10456.209970692107, done: False\n",
      "state: [-0.49111466 41.88002818], action: [0.3066315  0.11546384]\n",
      "Episode: 269/3000, Reward: -9935.160074943562, done: False\n",
      "state: [-0.50136523 42.31958526], action: [-0.31692392 -0.167     ]\n",
      "Episode: 270/3000, Reward: -9905.230835333738, done: False\n",
      "state: [-0.49815957 42.03714474], action: [-0.4287329 -0.167    ]\n",
      "Episode: 271/3000, Reward: -10316.62399301024, done: False\n",
      "state: [-0.49996976 42.5470891 ], action: [-0.46058849 -0.167     ]\n",
      "Episode: 272/3000, Reward: -11181.86895709245, done: False\n",
      "state: [-0.49063851 42.74241476], action: [0.76537585 0.3250483 ]\n",
      "Episode: 273/3000, Reward: -11081.521332151386, done: False\n",
      "state: [-0.50310991 43.38510541], action: [-0.46728224 -0.167     ]\n",
      "Episode: 274/3000, Reward: -11663.843455583334, done: False\n",
      "state: [-0.50231867 43.65216143], action: [ 0.28026593 -0.5934175 ]\n",
      "Episode: 275/3000, Reward: -11330.358118589895, done: False\n",
      "state: [-0.50315205 44.06837228], action: [-0.48003444 -0.167     ]\n",
      "Episode: 276/3000, Reward: -9939.675773932868, done: False\n",
      "state: [-0.50754276 44.64064845], action: [-0.36845523 -0.167     ]\n",
      "Episode: 277/3000, Reward: -11331.14937765578, done: False\n",
      "state: [-0.50752534 45.11016304], action: [-0.3269629 -0.167    ]\n",
      "Episode: 278/3000, Reward: -10867.872426634014, done: False\n",
      "state: [-0.50823326 45.33557121], action: [-0.28765932 -0.167     ]\n",
      "Episode: 279/3000, Reward: -11327.065023813882, done: False\n",
      "state: [-0.51341622 46.43923543], action: [-0.6283825 -0.167    ]\n",
      "Episode: 280/3000, Reward: -10573.111731933675, done: False\n",
      "state: [-0.51063891 45.99909518], action: [-0.2687112 -0.167    ]\n",
      "Episode: 281/3000, Reward: -11395.500319775669, done: False\n",
      "state: [-0.51212984 46.43409962], action: [-0.212443 -0.167   ]\n",
      "Episode: 282/3000, Reward: -11884.82077567456, done: False\n",
      "state: [-0.51580784 47.02022216], action: [-0.23528558 -0.59847593]\n",
      "Episode: 283/3000, Reward: -11743.558955455106, done: False\n",
      "state: [-0.50181628 46.88187136], action: [ 0.5191871  -0.23223412]\n",
      "Episode: 284/3000, Reward: -12249.971878783168, done: False\n",
      "state: [-0.51620249 47.81354265], action: [-0.42358804 -0.167     ]\n",
      "Episode: 285/3000, Reward: -12442.544256097353, done: False\n",
      "state: [-0.51482178 47.67316147], action: [-0.32513216 -0.167     ]\n",
      "Episode: 286/3000, Reward: -11264.460508524802, done: False\n",
      "state: [-0.51622138 48.08477602], action: [-0.24760945 -0.167     ]\n",
      "Episode: 287/3000, Reward: -13398.027180803289, done: False\n",
      "state: [-0.5215417  48.87470514], action: [-0.24714388 -0.167     ]\n",
      "Episode: 288/3000, Reward: -11684.538156141623, done: False\n",
      "state: [-0.52273655 48.85953897], action: [-0.856639   0.3621267]\n",
      "Episode: 289/3000, Reward: -11717.452841828117, done: False\n",
      "state: [-0.52047137 49.37712114], action: [-0.16431744 -0.167     ]\n",
      "Episode: 290/3000, Reward: -11839.098741262427, done: False\n",
      "state: [-0.51895817 49.97300236], action: [0.32906187 0.01209142]\n",
      "Episode: 291/3000, Reward: -12035.839996943154, done: False\n",
      "state: [-0.52041647 50.00932579], action: [-0.23694137 -0.167     ]\n",
      "Episode: 292/3000, Reward: -11769.365162471833, done: False\n",
      "state: [-0.52125405 50.34908718], action: [-0.21904075 -0.167     ]\n",
      "Episode: 293/3000, Reward: -13794.86204118316, done: False\n",
      "state: [-0.52181604 50.77900492], action: [-0.3683959 -0.167    ]\n",
      "Episode: 294/3000, Reward: -12811.57524397914, done: False\n",
      "state: [-0.52240906 51.15223426], action: [-0.32127187 -0.167     ]\n",
      "Episode: 295/3000, Reward: -11675.585118073217, done: False\n",
      "state: [-0.52511519 51.88126761], action: [-0.3798292 -0.167    ]\n",
      "Episode: 296/3000, Reward: -12444.806324788502, done: False\n",
      "state: [-0.5260905  52.22215844], action: [-0.218772 -0.167   ]\n",
      "Episode: 297/3000, Reward: -13206.263898342577, done: False\n",
      "state: [-0.52616357 52.38957274], action: [-0.34249645 -0.167     ]\n",
      "Episode: 298/3000, Reward: -12928.892035578241, done: False\n",
      "state: [-0.5279006  52.97761674], action: [-0.30655771 -0.167     ]\n",
      "Episode: 299/3000, Reward: -13656.72686623681, done: False\n",
      "state: [-0.52945608 53.35792798], action: [-0.34629577 -0.167     ]\n",
      "Episode: 300/3000, Reward: -12258.346752514988, done: False\n",
      "state: [-0.52515768 53.12196341], action: [-0.5012024 -0.167    ]\n",
      "Episode: 301/3000, Reward: -13221.171609458665, done: False\n",
      "state: [-0.52455134 53.72356332], action: [-0.6476809 -0.167    ]\n",
      "Episode: 302/3000, Reward: -13417.154878589097, done: False\n",
      "state: [-0.52738048 53.49532247], action: [-0.269426 -0.167   ]\n",
      "Episode: 303/3000, Reward: -12567.888776850952, done: False\n",
      "state: [-0.52786669 54.0857846 ], action: [-0.5553334 -0.167    ]\n",
      "Episode: 304/3000, Reward: -12818.072260467543, done: False\n",
      "state: [-0.53022384 53.83071925], action: [-0.26720992 -0.167     ]\n",
      "Episode: 305/3000, Reward: -13509.97776584094, done: False\n",
      "state: [-0.52712098 53.59103531], action: [-0.24376336 -0.167     ]\n",
      "Episode: 306/3000, Reward: -12591.47480915743, done: False\n",
      "state: [-0.53038962 54.28776967], action: [-0.261334 -0.167   ]\n",
      "Episode: 307/3000, Reward: -14012.5043486668, done: False\n",
      "state: [-0.53119531 54.24182039], action: [-0.06592868 -0.167     ]\n",
      "Episode: 308/3000, Reward: -13666.585173490155, done: False\n",
      "state: [-0.52975123 54.37858144], action: [-0.30401176 -0.167     ]\n",
      "Episode: 309/3000, Reward: -14206.66131396461, done: False\n",
      "state: [-0.53113707 54.86791405], action: [-0.3481208 -0.167    ]\n",
      "Episode: 310/3000, Reward: -13501.929400991954, done: False\n",
      "state: [-0.52462486 54.87866201], action: [0.5457236 0.7139616]\n",
      "Episode: 311/3000, Reward: -12502.205897854958, done: False\n",
      "state: [-0.53355311 55.15703725], action: [-0.21988313 -0.167     ]\n",
      "Episode: 312/3000, Reward: -13667.566242909834, done: False\n",
      "state: [-0.53119072 55.42067666], action: [-0.17153518 -0.167     ]\n",
      "Episode: 313/3000, Reward: -13385.66022811496, done: False\n",
      "state: [-0.52935293 55.93780139], action: [0.4989474  0.15676247]\n",
      "Episode: 314/3000, Reward: -13960.645269850549, done: False\n",
      "state: [-0.53181023 55.96167188], action: [-0.3448043 -0.167    ]\n",
      "Episode: 315/3000, Reward: -13924.567332956925, done: False\n",
      "state: [-0.53197581 55.8802333 ], action: [-0.25585222 -0.167     ]\n",
      "Episode: 316/3000, Reward: -14158.53002582584, done: False\n",
      "state: [-0.53378561 56.56675498], action: [-0.26383436 -0.167     ]\n",
      "Episode: 317/3000, Reward: -13255.860522092718, done: False\n",
      "state: [-0.53453261 56.80975419], action: [-0.16360101 -0.167     ]\n",
      "Episode: 318/3000, Reward: -13491.35453810713, done: False\n",
      "state: [-0.5324132  56.89692422], action: [-0.5231156 -0.167    ]\n",
      "Episode: 319/3000, Reward: -13744.224439067017, done: False\n",
      "state: [-0.53586813 57.79495804], action: [-0.5626193 -0.167    ]\n",
      "Episode: 320/3000, Reward: -13917.065827931023, done: False\n",
      "state: [-0.53375238 57.10153232], action: [-0.19671209 -0.167     ]\n",
      "Episode: 321/3000, Reward: -14006.199640057752, done: False\n",
      "state: [-0.52921766 57.5781586 ], action: [0.2803368  0.84133637]\n",
      "Episode: 322/3000, Reward: -14088.432594472217, done: False\n",
      "state: [-0.53569921 58.03751513], action: [-0.5112231 -0.167    ]\n",
      "Episode: 323/3000, Reward: -15128.999633875146, done: False\n",
      "state: [-0.53849174 58.29654551], action: [-0.17536831 -0.167     ]\n",
      "Episode: 324/3000, Reward: -14133.164201903961, done: False\n",
      "state: [-0.53636769 58.29424607], action: [-0.17212752 -0.167     ]\n",
      "Episode: 325/3000, Reward: -13747.401145185635, done: False\n",
      "state: [-0.53556317 58.52761019], action: [-0.40793848 -0.167     ]\n",
      "Episode: 326/3000, Reward: -14108.800104996306, done: False\n",
      "state: [-0.53984338 59.07205257], action: [-0.22023886 -0.167     ]\n",
      "Episode: 327/3000, Reward: -13608.31287623862, done: False\n",
      "state: [-0.5374817  58.95718124], action: [-0.2677341 -0.167    ]\n",
      "Episode: 328/3000, Reward: -14643.906102143217, done: False\n",
      "state: [-0.53768797 59.13652562], action: [-0.1552659 -0.167    ]\n",
      "Episode: 329/3000, Reward: -14180.135350875778, done: False\n",
      "state: [-0.53739328 58.94360934], action: [-0.37909448 -0.167     ]\n",
      "Episode: 330/3000, Reward: -13460.562981373592, done: False\n",
      "state: [-0.53828486 59.3351612 ], action: [-0.30700696 -0.167     ]\n",
      "Episode: 331/3000, Reward: -13591.98930538379, done: False\n",
      "state: [-0.53783685 59.32904764], action: [-0.39812344 -0.167     ]\n",
      "Episode: 332/3000, Reward: -14742.539222557487, done: False\n",
      "state: [-0.53208898 59.40570249], action: [ 0.6393173 -0.4701907]\n",
      "Episode: 333/3000, Reward: -15706.184724908388, done: False\n",
      "state: [-0.54121242 60.20942935], action: [-0.464358 -0.167   ]\n",
      "Episode: 334/3000, Reward: -15140.328398471866, done: False\n",
      "state: [-0.54348065 59.95022899], action: [-0.99451    -0.77701914]\n",
      "Episode: 335/3000, Reward: -15064.247781799515, done: False\n",
      "state: [-0.53895365 59.84488452], action: [ 0.09031448 -0.167     ]\n",
      "Episode: 336/3000, Reward: -14549.012587701156, done: False\n",
      "state: [-0.53713428 60.14107344], action: [0.13834192 0.88035315]\n",
      "Episode: 337/3000, Reward: -14566.84818248645, done: False\n",
      "state: [-0.54194631 60.7308315 ], action: [-0.35941395 -0.167     ]\n",
      "Episode: 338/3000, Reward: -15232.524479245763, done: False\n",
      "state: [-0.53806949 60.14033961], action: [-0.17782228 -0.167     ]\n",
      "Episode: 339/3000, Reward: -14664.337969352002, done: False\n",
      "state: [-0.53862546 60.27597183], action: [-0.18464763 -0.167     ]\n",
      "Episode: 340/3000, Reward: -15076.838981184883, done: False\n",
      "state: [-0.53910509 60.5271119 ], action: [-0.25470394 -0.167     ]\n",
      "Episode: 341/3000, Reward: -16418.834472261835, done: False\n",
      "state: [-0.53950392 60.47525174], action: [-0.18954358 -0.167     ]\n",
      "Episode: 342/3000, Reward: -13967.41254680319, done: False\n",
      "state: [-0.5349087  61.32407741], action: [ 0.5731319  -0.04859759]\n",
      "Episode: 343/3000, Reward: -15425.59922955416, done: False\n",
      "state: [-0.53396444 60.6999283 ], action: [0.81219983 0.5822291 ]\n",
      "Episode: 344/3000, Reward: -14907.94992122622, done: False\n",
      "state: [-0.53867689 60.37521128], action: [-0.29851076 -0.167     ]\n",
      "Episode: 345/3000, Reward: -14461.040782702861, done: False\n",
      "state: [-0.53256524 60.76200888], action: [0.7846705  0.48110396]\n",
      "Episode: 346/3000, Reward: -13836.830732407037, done: False\n",
      "state: [-0.53999435 60.43096973], action: [-0.24079739 -0.167     ]\n",
      "Episode: 347/3000, Reward: -14796.350290066219, done: False\n",
      "state: [-0.53846389 60.59455118], action: [-0.3296857 -0.167    ]\n",
      "Episode: 348/3000, Reward: -14941.525968527132, done: False\n",
      "state: [-0.53337999 60.3279598 ], action: [0.8849231  0.38346627]\n",
      "Episode: 349/3000, Reward: -14362.91413213148, done: False\n",
      "state: [-0.53962286 60.29960958], action: [-0.12141463 -0.167     ]\n",
      "Episode: 350/3000, Reward: -13687.994818489604, done: False\n",
      "state: [-0.53984818 60.23524535], action: [-0.3737445 -0.167    ]\n",
      "Episode: 351/3000, Reward: -13259.512522673911, done: False\n",
      "state: [-0.54238823 60.47228689], action: [-0.7352572  -0.41002694]\n",
      "Episode: 352/3000, Reward: -14825.206274337153, done: False\n",
      "state: [-0.53695123 60.18706847], action: [-0.5096378 -0.167    ]\n",
      "Episode: 353/3000, Reward: -14482.151125435623, done: False\n",
      "state: [-0.53898197 60.06621613], action: [-0.2743929 -0.167    ]\n",
      "Episode: 354/3000, Reward: -14075.333965918393, done: False\n",
      "state: [-0.53895232 59.98446984], action: [-0.20096217 -0.167     ]\n",
      "Episode: 355/3000, Reward: -13154.185691360397, done: False\n",
      "state: [-0.53932024 60.09517895], action: [-0.30530605 -0.167     ]\n",
      "Episode: 356/3000, Reward: -13319.644141091158, done: False\n",
      "state: [-0.54029026 60.04631715], action: [-0.26728076 -0.167     ]\n",
      "Episode: 357/3000, Reward: -14548.403573282763, done: False\n",
      "state: [-0.53806514 59.49383803], action: [-0.15251733 -0.167     ]\n",
      "Episode: 358/3000, Reward: -13725.780673559137, done: False\n",
      "state: [-0.5373426  59.22829778], action: [-0.37947333 -0.167     ]\n",
      "Episode: 359/3000, Reward: -14215.626111387784, done: False\n",
      "state: [-0.53802027 59.44157012], action: [-0.27388486 -0.167     ]\n",
      "Episode: 360/3000, Reward: -13350.065782326528, done: False\n",
      "state: [-0.53751813 59.28753744], action: [-0.17124638 -0.167     ]\n",
      "Episode: 361/3000, Reward: -13803.831623090588, done: False\n",
      "state: [-0.53887495 59.4794885 ], action: [-0.21271981 -0.167     ]\n",
      "Episode: 362/3000, Reward: -13967.891756250023, done: False\n",
      "state: [-0.53711399 59.87476259], action: [-0.60117924 -0.167     ]\n",
      "Episode: 363/3000, Reward: -14348.81087238401, done: False\n",
      "state: [-0.53831493 59.76712069], action: [-0.19966596 -0.167     ]\n",
      "Episode: 364/3000, Reward: -13565.444958111815, done: False\n",
      "state: [-0.54067353 60.16382974], action: [-0.1931304 -0.167    ]\n",
      "Episode: 365/3000, Reward: -13330.843953332756, done: False\n",
      "state: [-0.54012275 60.25283974], action: [-0.27902162 -0.167     ]\n",
      "Episode: 366/3000, Reward: -13939.381998470923, done: False\n",
      "state: [-0.54031057 60.7144574 ], action: [-0.3437552 -0.167    ]\n",
      "Episode: 367/3000, Reward: -13333.718561825972, done: False\n",
      "state: [-0.54127898 60.99153974], action: [-0.30713132 -0.167     ]\n",
      "Episode: 368/3000, Reward: -14747.942994004827, done: False\n",
      "state: [-0.54072221 60.94319651], action: [-0.74947274 -0.45368752]\n",
      "Episode: 369/3000, Reward: -15985.116775831515, done: False\n",
      "state: [-0.53995358 61.28245313], action: [-0.31546822 -0.167     ]\n",
      "Episode: 370/3000, Reward: -13830.567959697175, done: False\n",
      "state: [-0.54326106 61.23016488], action: [-0.93662405  0.3902073 ]\n",
      "Episode: 371/3000, Reward: -14642.419496607075, done: False\n",
      "state: [-0.53527006 61.51114114], action: [ 0.8195026  -0.45352134]\n",
      "Episode: 372/3000, Reward: -14591.757245188142, done: False\n",
      "state: [-0.54235704 61.98021288], action: [-0.21795097 -0.167     ]\n",
      "Episode: 373/3000, Reward: -14795.771645209734, done: False\n",
      "state: [-0.54198391 62.02288622], action: [-0.23079668 -0.167     ]\n",
      "Episode: 374/3000, Reward: -14112.796178088895, done: False\n",
      "state: [-0.54324338 62.44066356], action: [-0.39977852 -0.167     ]\n",
      "Episode: 375/3000, Reward: -15952.766298811044, done: False\n",
      "state: [-0.54204603 62.45185304], action: [-0.13812624 -0.167     ]\n",
      "Episode: 376/3000, Reward: -14572.01264954683, done: False\n",
      "state: [-0.54043567 62.84173173], action: [-0.52711606 -0.167     ]\n",
      "Episode: 377/3000, Reward: -15150.593290564047, done: False\n",
      "state: [-0.54264389 62.89890694], action: [-0.19574378 -0.167     ]\n",
      "Episode: 378/3000, Reward: -14445.17955358857, done: False\n",
      "state: [-0.54238935 63.18641451], action: [-0.41453117 -0.167     ]\n",
      "Episode: 379/3000, Reward: -14826.764091848145, done: False\n",
      "state: [-0.53988773 63.38374831], action: [0.4388037  0.86460775]\n",
      "Episode: 380/3000, Reward: -14569.537306092136, done: False\n",
      "state: [-0.54383058 63.7416746 ], action: [-0.3477654 -0.167    ]\n",
      "Episode: 381/3000, Reward: -15299.62300002978, done: False\n",
      "state: [-0.54543076 64.17110383], action: [-0.8272489 -0.3124454]\n",
      "Episode: 382/3000, Reward: -15998.444381790725, done: False\n",
      "state: [-0.54702813 64.18904456], action: [-0.80648476  0.5609061 ]\n",
      "Episode: 383/3000, Reward: -13991.190513273204, done: False\n",
      "state: [-0.54422235 64.4471512 ], action: [-0.20280643 -0.167     ]\n",
      "Episode: 384/3000, Reward: -14987.915926721766, done: False\n",
      "state: [-0.54351438 64.69531516], action: [ 0.0594057 -0.6316071]\n",
      "Episode: 385/3000, Reward: -14791.707399034165, done: False\n",
      "state: [-0.5454203  65.21337712], action: [-0.18523711 -0.167     ]\n",
      "Episode: 386/3000, Reward: -14790.198924464315, done: False\n",
      "state: [-0.54540126 65.4066235 ], action: [-0.22423504 -0.167     ]\n",
      "Episode: 387/3000, Reward: -15952.11369586388, done: False\n",
      "state: [-0.54585575 65.81184191], action: [-0.19063927 -0.167     ]\n",
      "Episode: 388/3000, Reward: -15238.855565455562, done: False\n",
      "state: [-0.54372057 66.48971927], action: [-0.6371608 -0.167    ]\n",
      "Episode: 389/3000, Reward: -14954.901316429088, done: False\n",
      "state: [-0.54649044 66.71015067], action: [-0.3615182 -0.167    ]\n",
      "Episode: 390/3000, Reward: -16139.84883876089, done: False\n",
      "state: [-0.54678615 67.06924917], action: [-0.2038962 -0.167    ]\n",
      "Episode: 391/3000, Reward: -15973.450734179516, done: False\n",
      "state: [-0.54852674 67.86330973], action: [-0.2965428 -0.167    ]\n",
      "Episode: 392/3000, Reward: -16573.863753073678, done: False\n",
      "state: [-0.54888135 68.83170435], action: [-0.1679712 -0.167    ]\n",
      "Episode: 393/3000, Reward: -16668.219843680665, done: False\n",
      "state: [-0.54088309 69.93030662], action: [ 0.7291719  -0.00779181]\n",
      "Episode: 394/3000, Reward: -18380.71692340507, done: False\n",
      "state: [-0.55055448 70.20675781], action: [-0.2137248 -0.167    ]\n",
      "Episode: 395/3000, Reward: -17528.40605994701, done: False\n",
      "state: [-0.54803405 70.8950383 ], action: [0.35408404 0.9214583 ]\n",
      "Episode: 396/3000, Reward: -18111.836965152077, done: False\n",
      "state: [-0.55406159 71.48590426], action: [-0.6144691  -0.52182126]\n",
      "Episode: 397/3000, Reward: -17452.74226171588, done: False\n",
      "state: [-0.55148223 71.99268007], action: [-0.14253145 -0.167     ]\n",
      "Episode: 398/3000, Reward: -19002.34043200558, done: False\n",
      "state: [-0.55320159 73.00392368], action: [-0.32775986 -0.167     ]\n",
      "Episode: 399/3000, Reward: -18511.083199248515, done: False\n",
      "state: [-0.55294542 73.34965799], action: [-0.18405065 -0.167     ]\n",
      "Episode: 400/3000, Reward: -17915.885005550193, done: False\n",
      "state: [-0.55415959 73.83111249], action: [-0.1917345 -0.167    ]\n",
      "Episode: 401/3000, Reward: -18767.187175330553, done: False\n",
      "state: [-0.55586226 73.46315783], action: [-0.83112925  0.51710564]\n",
      "Episode: 402/3000, Reward: -18522.80877860166, done: False\n",
      "state: [-0.55325242 74.03313229], action: [-0.0662781 -0.167    ]\n",
      "Episode: 403/3000, Reward: -18116.873499292393, done: False\n",
      "state: [-0.55350986 74.15622007], action: [-0.16117941 -0.167     ]\n",
      "Episode: 404/3000, Reward: -20090.499171323234, done: False\n",
      "state: [-0.55465589 74.46792916], action: [-0.19898462 -0.167     ]\n",
      "Episode: 405/3000, Reward: -19493.047924853494, done: False\n",
      "state: [-0.55325329 74.82548622], action: [0.06473692 0.9969631 ]\n",
      "Episode: 406/3000, Reward: -18220.645409588476, done: False\n",
      "state: [-0.5544848  74.88951441], action: [-0.26675645 -0.167     ]\n",
      "Episode: 407/3000, Reward: -18349.87727872751, done: False\n",
      "state: [-0.55271819 75.21363831], action: [ 0.11162748 -0.12344848]\n",
      "Episode: 408/3000, Reward: -18898.190433498527, done: False\n",
      "state: [-0.55422095 75.49449183], action: [-0.07253441 -0.167     ]\n",
      "Episode: 409/3000, Reward: -18870.531226649295, done: False\n",
      "state: [-0.55478281 76.19643717], action: [-0.08524153 -0.167     ]\n",
      "Episode: 410/3000, Reward: -19709.757866626038, done: False\n",
      "state: [-0.55206051 76.74437986], action: [0.5221748  0.20374578]\n",
      "Episode: 411/3000, Reward: -19767.464959382887, done: False\n",
      "state: [-0.55767511 77.45625279], action: [-0.1980612 -0.167    ]\n",
      "Episode: 412/3000, Reward: -20635.826032267683, done: False\n",
      "state: [-0.55517722 76.908305  ], action: [-0.09643217 -0.167     ]\n",
      "Episode: 413/3000, Reward: -19171.230889551338, done: False\n",
      "state: [-0.55577076 77.72463392], action: [-0.06581473 -0.167     ]\n",
      "Episode: 414/3000, Reward: -19751.242260523384, done: False\n",
      "state: [-0.55666278 78.28235392], action: [-0.2783531 -0.167    ]\n",
      "Episode: 415/3000, Reward: -19408.970815986595, done: False\n",
      "state: [-0.55584657 78.64290841], action: [ 0.13022667 -0.64279205]\n",
      "Episode: 416/3000, Reward: -19725.84051214867, done: False\n",
      "state: [-0.55820315 78.98255737], action: [-0.19863288 -0.167     ]\n",
      "Episode: 417/3000, Reward: -20375.891791909093, done: False\n",
      "state: [-0.55722138 79.12099364], action: [-0.18022236 -0.167     ]\n",
      "Episode: 418/3000, Reward: -20153.07375038449, done: False\n",
      "state: [-0.55957315 80.28914284], action: [-0.21844508 -0.167     ]\n",
      "Episode: 419/3000, Reward: -20181.203970842056, done: False\n",
      "state: [-0.55827343 80.58279143], action: [-0.21881558 -0.167     ]\n",
      "Episode: 420/3000, Reward: -21482.775592181053, done: False\n",
      "state: [-0.55748    80.65076652], action: [-0.12982467 -0.167     ]\n",
      "Episode: 421/3000, Reward: -20726.420607971835, done: False\n",
      "state: [-0.55897945 81.6870401 ], action: [-0.11423727 -0.167     ]\n",
      "Episode: 422/3000, Reward: -21797.82638697015, done: False\n",
      "state: [-0.5582309 81.1277059], action: [-0.18659976 -0.167     ]\n",
      "Episode: 423/3000, Reward: -20986.54578497746, done: False\n",
      "state: [-0.55926868 81.67573645], action: [-0.18312174 -0.167     ]\n",
      "Episode: 424/3000, Reward: -21433.921861320367, done: False\n",
      "state: [-0.55885356 82.34686887], action: [-0.15515423 -0.167     ]\n",
      "Episode: 425/3000, Reward: -23096.152400048384, done: False\n",
      "state: [-0.5585439  82.39993143], action: [-0.0718058 -0.167    ]\n",
      "Episode: 426/3000, Reward: -21619.23681165254, done: False\n",
      "state: [-0.55794808 82.9314655 ], action: [-0.45870203 -0.167     ]\n",
      "Episode: 427/3000, Reward: -21185.365749027056, done: False\n",
      "state: [-0.56033382 83.10640749], action: [-0.17602636 -0.167     ]\n",
      "Episode: 428/3000, Reward: -22216.64240575093, done: False\n",
      "state: [-0.56105903 83.47698789], action: [-0.27848682 -0.167     ]\n",
      "Episode: 429/3000, Reward: -22321.13488807245, done: False\n",
      "state: [-0.56141608 83.63915636], action: [-0.32197297 -0.167     ]\n",
      "Episode: 430/3000, Reward: -21790.459752368322, done: False\n",
      "state: [-0.5633664  83.58361367], action: [-0.94074833  0.44338655]\n",
      "Episode: 431/3000, Reward: -22435.316574491095, done: False\n",
      "state: [-0.55950099 83.60482115], action: [-0.1675634 -0.167    ]\n",
      "Episode: 432/3000, Reward: -22131.137122204123, done: False\n",
      "state: [-0.55994389 83.96964336], action: [-0.11328088 -0.167     ]\n",
      "Episode: 433/3000, Reward: -21927.3182898833, done: False\n",
      "state: [-0.56033588 84.13934634], action: [-0.23747417 -0.167     ]\n",
      "Episode: 434/3000, Reward: -22255.8067647477, done: False\n",
      "state: [-0.55990249 84.31235888], action: [-0.03278071  0.16256826]\n",
      "Episode: 435/3000, Reward: -22147.68181185768, done: False\n",
      "state: [-0.56193931 84.77649653], action: [-0.5039441 -0.6277794]\n",
      "Episode: 436/3000, Reward: -22331.968754460162, done: False\n",
      "state: [-0.56053612 84.73475184], action: [-0.21815445 -0.167     ]\n",
      "Episode: 437/3000, Reward: -22365.035261770332, done: False\n",
      "state: [-0.5609239  84.99007207], action: [-0.16503371 -0.167     ]\n",
      "Episode: 438/3000, Reward: -22911.43464877319, done: False\n",
      "state: [-0.56036731 84.40634342], action: [-0.22913471 -0.167     ]\n",
      "Episode: 439/3000, Reward: -22666.724853836262, done: False\n",
      "state: [-0.56094199 85.19334425], action: [-0.264764 -0.167   ]\n",
      "Episode: 440/3000, Reward: -24059.8983228546, done: False\n",
      "state: [-0.56178663 85.99178634], action: [-0.18871228 -0.167     ]\n",
      "Episode: 441/3000, Reward: -22939.380857238615, done: False\n",
      "state: [-0.55996391 85.45020308], action: [-0.10159951 -0.167     ]\n",
      "Episode: 442/3000, Reward: -23692.11720602602, done: False\n",
      "state: [-0.56118594 86.19808647], action: [-0.1942172 -0.167    ]\n",
      "Episode: 443/3000, Reward: -22879.38023330685, done: False\n",
      "state: [-0.56016962 85.37312812], action: [-0.08656682 -0.167     ]\n",
      "Episode: 444/3000, Reward: -23004.13531478372, done: False\n",
      "state: [-0.56005241 85.5784333 ], action: [ 0.04482724 -0.46033645]\n",
      "Episode: 445/3000, Reward: -23083.91768912653, done: False\n",
      "state: [-0.56197665 86.23478219], action: [-0.15651649 -0.167     ]\n",
      "Episode: 446/3000, Reward: -22979.10286320185, done: False\n",
      "state: [-0.56140122 86.31997463], action: [-0.18643776 -0.167     ]\n",
      "Episode: 447/3000, Reward: -22974.359654061365, done: False\n",
      "state: [-0.56196107 86.1919581 ], action: [-0.2428446 -0.167    ]\n",
      "Episode: 448/3000, Reward: -23694.50627100722, done: False\n",
      "state: [-0.55998353 85.74204776], action: [ 0.05809372 -0.167     ]\n",
      "Episode: 449/3000, Reward: -23081.91669786572, done: False\n",
      "state: [-0.56090676 85.48229395], action: [ 0.07198862 -0.167     ]\n",
      "Episode: 450/3000, Reward: -23377.838142344564, done: False\n",
      "state: [-0.56098724 85.6261658 ], action: [-0.0742831  -0.28742945]\n",
      "Episode: 451/3000, Reward: -22846.704199473283, done: False\n",
      "state: [-0.56134938 85.42979917], action: [-0.236394 -0.167   ]\n",
      "Episode: 452/3000, Reward: -23098.92312339852, done: False\n",
      "state: [-0.55853397 84.97152401], action: [ 0.16365188 -0.20382081]\n",
      "Episode: 453/3000, Reward: -22625.32911561499, done: False\n",
      "state: [-0.56006193 84.92069968], action: [-0.1072893 -0.167    ]\n",
      "Episode: 454/3000, Reward: -22973.611747510397, done: False\n",
      "state: [-0.56418086 84.91927288], action: [-0.9610278   0.12296616]\n",
      "Episode: 455/3000, Reward: -22836.032611728606, done: False\n",
      "state: [-0.56118446 85.56117222], action: [-0.25850263 -0.167     ]\n",
      "Episode: 456/3000, Reward: -22626.640076670534, done: False\n",
      "state: [-0.56057301 84.39435011], action: [-0.17697251 -0.167     ]\n",
      "Episode: 457/3000, Reward: -22768.021462719647, done: False\n",
      "state: [-0.56059143 84.68352799], action: [-0.15447658 -0.167     ]\n",
      "Episode: 458/3000, Reward: -22445.60195928378, done: False\n",
      "state: [-0.56021148 84.3238008 ], action: [-0.11545693 -0.167     ]\n",
      "Episode: 459/3000, Reward: -22286.416304765775, done: False\n",
      "state: [-0.55939921 84.0340185 ], action: [-0.08343865 -0.167     ]\n",
      "Episode: 460/3000, Reward: -22349.01934920332, done: False\n",
      "state: [-0.55999892 83.9748795 ], action: [-0.19935095 -0.167     ]\n",
      "Episode: 461/3000, Reward: -22245.928956155425, done: False\n",
      "state: [-0.55487118 84.08390398], action: [0.37967864 0.8400401 ]\n",
      "Episode: 462/3000, Reward: -22552.671914402992, done: False\n",
      "state: [-0.55935616 83.41798129], action: [-0.00218168 -0.167     ]\n",
      "Episode: 463/3000, Reward: -22755.891146249865, done: False\n",
      "state: [-0.56342758 83.70327732], action: [-0.87875515 -0.30519763]\n",
      "Episode: 464/3000, Reward: -22203.182856904667, done: False\n",
      "state: [-0.55941002 83.16706771], action: [-0.11205307 -0.167     ]\n",
      "Episode: 465/3000, Reward: -22226.61072279826, done: False\n",
      "state: [-0.5539741  82.55766081], action: [0.9391742 0.6814265]\n",
      "Episode: 466/3000, Reward: -22148.411505348166, done: False\n",
      "state: [-0.55971172 82.84813602], action: [-0.23037048 -0.167     ]\n",
      "Episode: 467/3000, Reward: -21831.3961013467, done: False\n",
      "state: [-0.55894204 82.72124386], action: [-0.14860271 -0.167     ]\n",
      "Episode: 468/3000, Reward: -21520.679162309614, done: False\n",
      "state: [-0.56007021 82.65646113], action: [-0.15807159 -0.167     ]\n",
      "Episode: 469/3000, Reward: -22452.396044593457, done: False\n",
      "state: [-0.55799051 82.05544523], action: [-0.06347471 -0.167     ]\n",
      "Episode: 470/3000, Reward: -21704.88766814487, done: False\n",
      "state: [-0.5590939  82.00165726], action: [-0.09284823 -0.167     ]\n",
      "Episode: 471/3000, Reward: -21226.629082503612, done: False\n",
      "state: [-0.55853315 81.8654048 ], action: [-0.06987008 -0.167     ]\n",
      "Episode: 472/3000, Reward: -21221.097185857547, done: False\n",
      "state: [-0.55694411 81.32632586], action: [ 0.08924929 -0.40097582]\n",
      "Episode: 473/3000, Reward: -21185.37474468239, done: False\n",
      "state: [-0.55817608 81.49277833], action: [-0.13370058 -0.167     ]\n",
      "Episode: 474/3000, Reward: -21391.866255688372, done: False\n",
      "state: [-0.55896505 81.3920971 ], action: [-0.11344656 -0.167     ]\n",
      "Episode: 475/3000, Reward: -20947.237342597564, done: False\n",
      "state: [-0.55794466 80.54311524], action: [-0.18509711 -0.167     ]\n",
      "Episode: 476/3000, Reward: -21447.141241669924, done: False\n",
      "state: [-0.55912522 80.78013545], action: [-0.14357024 -0.167     ]\n",
      "Episode: 477/3000, Reward: -21192.03850452325, done: False\n",
      "state: [-0.55823477 80.5046082 ], action: [-0.27083346 -0.167     ]\n",
      "Episode: 478/3000, Reward: -20662.906633628783, done: False\n",
      "state: [-0.55746114 80.15786195], action: [-0.18433073 -0.167     ]\n",
      "Episode: 479/3000, Reward: -20671.490837181387, done: False\n",
      "state: [-0.55721837 80.26872172], action: [-0.04575171 -0.167     ]\n",
      "Episode: 480/3000, Reward: -20725.891414071466, done: False\n",
      "state: [-0.55790794 80.15598338], action: [-0.05760642 -0.167     ]\n",
      "Episode: 481/3000, Reward: -20513.188192376467, done: False\n",
      "state: [-0.55835865 79.87584423], action: [ 0.17328283 -0.167     ]\n",
      "Episode: 482/3000, Reward: -21266.881608610864, done: False\n",
      "state: [-0.55777751 79.41283306], action: [-0.20885591 -0.167     ]\n",
      "Episode: 483/3000, Reward: -20383.371078979457, done: False\n",
      "state: [-0.55759232 79.2390698 ], action: [-0.14440702 -0.167     ]\n",
      "Episode: 484/3000, Reward: -19895.680337901144, done: False\n",
      "state: [-0.55740505 79.17270636], action: [-0.14795354 -0.167     ]\n",
      "Episode: 485/3000, Reward: -20043.47910717707, done: False\n",
      "state: [-0.55704766 78.83298269], action: [-0.03841003 -0.167     ]\n",
      "Episode: 486/3000, Reward: -20021.268937895205, done: False\n",
      "state: [-0.55646053 78.62344915], action: [-0.16159552 -0.167     ]\n",
      "Episode: 487/3000, Reward: -19776.169845638327, done: False\n",
      "state: [-0.55582201 78.38953122], action: [-0.0627832 -0.167    ]\n",
      "Episode: 488/3000, Reward: -19824.737148122033, done: False\n",
      "state: [-0.55728753 78.74469086], action: [-0.22268388 -0.167     ]\n",
      "Episode: 489/3000, Reward: -19831.28793737906, done: False\n",
      "state: [-0.55682677 78.0344629 ], action: [-0.20146729 -0.167     ]\n",
      "Episode: 490/3000, Reward: -19758.634079234263, done: False\n",
      "state: [-0.55648132 78.02661978], action: [-0.24469602 -0.167     ]\n",
      "Episode: 491/3000, Reward: -19725.84595208976, done: False\n",
      "state: [-0.5558765  77.79001452], action: [-0.10918938 -0.167     ]\n",
      "Episode: 492/3000, Reward: -19795.299646476014, done: False\n",
      "state: [-0.55654693 77.69785056], action: [-0.11825631 -0.167     ]\n",
      "Episode: 493/3000, Reward: -19262.669747611584, done: False\n",
      "state: [-0.55579344 77.26034008], action: [-0.20594272 -0.167     ]\n",
      "Episode: 494/3000, Reward: -19512.103663879097, done: False\n",
      "state: [-0.5560646  77.34162982], action: [-0.14798339 -0.167     ]\n",
      "Episode: 495/3000, Reward: -19639.08661815494, done: False\n",
      "state: [-0.55694455 77.08343712], action: [-0.41749632  0.59085965]\n",
      "Episode: 496/3000, Reward: -19088.383700466627, done: False\n",
      "state: [-0.55525195 76.48572145], action: [-0.20545319 -0.167     ]\n",
      "Episode: 497/3000, Reward: -19211.75305317104, done: False\n",
      "state: [-0.55528801 76.64447489], action: [-0.18513396 -0.167     ]\n",
      "Episode: 498/3000, Reward: -18898.067319056925, done: False\n",
      "state: [-0.5554429  76.38086984], action: [-0.22026065 -0.167     ]\n",
      "Episode: 499/3000, Reward: -19015.537637345966, done: False\n",
      "state: [-0.55498132 76.63397729], action: [-0.3887281 -0.167    ]\n",
      "Episode: 500/3000, Reward: -19067.726790157794, done: False\n",
      "state: [-0.55619063 76.24286239], action: [-0.17565669 -0.167     ]\n",
      "Episode: 501/3000, Reward: -18712.19894833888, done: False\n",
      "state: [-0.55622579 75.95958918], action: [-0.258524 -0.167   ]\n",
      "Episode: 502/3000, Reward: -18455.6202539325, done: False\n",
      "state: [-0.55523808 75.59616387], action: [-0.20535818 -0.167     ]\n",
      "Episode: 503/3000, Reward: -18713.517347985096, done: False\n",
      "state: [-0.55469871 75.44643056], action: [-0.19478244 -0.167     ]\n",
      "Episode: 504/3000, Reward: -18442.026130210375, done: False\n",
      "state: [-0.55445109 75.26801427], action: [-0.15055688 -0.167     ]\n",
      "Episode: 505/3000, Reward: -18441.457128578088, done: False\n",
      "state: [-0.55418954 75.04435619], action: [-0.12043732 -0.167     ]\n",
      "Episode: 506/3000, Reward: -19510.679586114657, done: False\n",
      "state: [-0.55439221 74.49392289], action: [-0.25400463 -0.167     ]\n",
      "Episode: 507/3000, Reward: -18109.82862041852, done: False\n",
      "state: [-0.554144   74.30301363], action: [-0.19393086 -0.167     ]\n",
      "Episode: 508/3000, Reward: -17974.86659357639, done: False\n",
      "state: [-0.55359477 74.19089513], action: [-0.23457801 -0.167     ]\n",
      "Episode: 509/3000, Reward: -18293.39293702272, done: False\n",
      "state: [-0.55343111 74.14584558], action: [-0.17519082 -0.167     ]\n",
      "Episode: 510/3000, Reward: -18069.369071485853, done: False\n",
      "state: [-0.55448529 74.15241062], action: [-0.212035 -0.167   ]\n",
      "Episode: 511/3000, Reward: -17957.35054230213, done: False\n",
      "state: [-0.55334949 73.70200235], action: [-0.09857832 -0.167     ]\n",
      "Episode: 512/3000, Reward: -18196.526391291758, done: False\n",
      "state: [-0.55283131 73.5035381 ], action: [-0.18685012 -0.167     ]\n",
      "Episode: 513/3000, Reward: -17481.772498476825, done: False\n",
      "state: [-0.55274225 73.13088719], action: [-0.23596178 -0.167     ]\n",
      "Episode: 514/3000, Reward: -17484.50105901526, done: False\n",
      "state: [-0.55315029 73.16493384], action: [-0.2285057 -0.167    ]\n",
      "Episode: 515/3000, Reward: -17425.575862855567, done: False\n",
      "state: [-0.55336917 73.10865586], action: [-0.25389042 -0.167     ]\n",
      "Episode: 516/3000, Reward: -17335.016994747544, done: False\n",
      "state: [-0.55271803 72.80437071], action: [-0.19095539 -0.167     ]\n",
      "Episode: 517/3000, Reward: -17334.074873559533, done: False\n",
      "state: [-0.55249568 72.74771781], action: [-0.35351992 -0.167     ]\n",
      "Episode: 518/3000, Reward: -17392.93815820065, done: False\n",
      "state: [-0.55692545 72.78333264], action: [-0.83841205 -0.5967751 ]\n",
      "Episode: 519/3000, Reward: -16923.714529424953, done: False\n",
      "state: [-0.55155352 71.45709667], action: [-0.20928636 -0.167     ]\n",
      "Episode: 520/3000, Reward: -16631.609189018935, done: False\n",
      "state: [-0.5510699  71.23136173], action: [-0.16056256 -0.167     ]\n",
      "Episode: 521/3000, Reward: -16493.11461690488, done: False\n",
      "state: [-0.55021145 70.88880328], action: [-0.12840675 -0.167     ]\n",
      "Episode: 522/3000, Reward: -16493.79906031213, done: False\n",
      "state: [-0.55094812 70.58983226], action: [-0.29226437 -0.167     ]\n",
      "Episode: 523/3000, Reward: -16294.80235257827, done: False\n",
      "state: [-0.55147443 70.71144672], action: [-0.17842804 -0.167     ]\n",
      "Episode: 524/3000, Reward: -16058.201915419188, done: False\n",
      "state: [-0.55027326 70.1296887 ], action: [-0.18258342 -0.167     ]\n",
      "Episode: 525/3000, Reward: -16343.378342205182, done: False\n",
      "state: [-0.55064152 70.06446324], action: [-0.25929984 -0.167     ]\n",
      "Episode: 526/3000, Reward: -16150.404438966936, done: False\n",
      "state: [-0.54974402 69.56194957], action: [-0.21086888 -0.167     ]\n",
      "Episode: 527/3000, Reward: -16017.317970598731, done: False\n",
      "state: [-0.54963203 69.13404049], action: [-0.25361916 -0.167     ]\n",
      "Episode: 528/3000, Reward: -15564.894742946699, done: False\n",
      "state: [-0.54907698 68.95679551], action: [-0.1766473 -0.167    ]\n",
      "Episode: 529/3000, Reward: -15483.105643803357, done: False\n",
      "state: [-0.54813116 68.62887556], action: [-0.13245653 -0.167     ]\n",
      "Episode: 530/3000, Reward: -15407.639025766395, done: False\n",
      "state: [-0.54863294 68.30567517], action: [-0.223793 -0.167   ]\n",
      "Episode: 531/3000, Reward: -15175.115261248615, done: False\n",
      "state: [-0.54931357 67.69484533], action: [-0.09224311 -0.167     ]\n",
      "Episode: 532/3000, Reward: -15514.492955504144, done: False\n",
      "state: [-0.54739997 67.29349259], action: [-0.17661035 -0.167     ]\n",
      "Episode: 533/3000, Reward: -14811.295015287304, done: False\n",
      "state: [-0.54675946 66.82759707], action: [-0.2086297 -0.167    ]\n",
      "Episode: 534/3000, Reward: -14830.500415292181, done: False\n",
      "state: [-0.54867645 66.72635482], action: [-0.3080017 -0.167    ]\n",
      "Episode: 535/3000, Reward: -14546.675099610018, done: False\n",
      "state: [-0.54679458 66.25485768], action: [-0.27628258 -0.167     ]\n",
      "Episode: 536/3000, Reward: -14996.133289410165, done: False\n",
      "state: [-0.54573665 65.77748657], action: [-0.32852235 -0.167     ]\n",
      "Episode: 537/3000, Reward: -14109.37301957779, done: False\n",
      "state: [-0.54583912 65.37714202], action: [-0.2093666 -0.167    ]\n",
      "Episode: 538/3000, Reward: -14120.24593996833, done: False\n",
      "state: [-0.54507932 65.06773401], action: [-0.22498122 -0.167     ]\n",
      "Episode: 539/3000, Reward: -14043.28206448673, done: False\n",
      "state: [-0.54430552 64.72971633], action: [-0.12047491 -0.167     ]\n",
      "Episode: 540/3000, Reward: -13816.743050311745, done: False\n",
      "state: [-0.54413131 64.19554846], action: [-0.15192857 -0.167     ]\n",
      "Episode: 541/3000, Reward: -13703.026885835832, done: False\n",
      "state: [-0.54406845 64.14649364], action: [-0.20870997 -0.167     ]\n",
      "Episode: 542/3000, Reward: -13818.424783629149, done: False\n",
      "state: [-0.54370691 63.84792648], action: [-0.255082 -0.167   ]\n",
      "Episode: 543/3000, Reward: -13624.100059851848, done: False\n",
      "state: [-0.54343224 63.48561702], action: [-0.25187653 -0.167     ]\n",
      "Episode: 544/3000, Reward: -13801.069526556717, done: False\n",
      "state: [-0.54289007 63.25440711], action: [-0.19616196 -0.167     ]\n",
      "Episode: 545/3000, Reward: -13080.258902719977, done: False\n",
      "state: [-0.54241204 62.88912865], action: [-0.2251623 -0.167    ]\n",
      "Episode: 546/3000, Reward: -12987.164691397684, done: False\n",
      "state: [-0.54225795 62.63473442], action: [-0.2965219 -0.167    ]\n",
      "Episode: 547/3000, Reward: -13124.594845043388, done: False\n",
      "state: [-0.54246055 62.43838096], action: [-0.2537334 -0.167    ]\n",
      "Episode: 548/3000, Reward: -12872.014079398456, done: False\n",
      "state: [-0.53751359 62.04120472], action: [0.52063733 0.2647067 ]\n",
      "Episode: 549/3000, Reward: -12678.369343330936, done: False\n",
      "state: [-0.54139688 61.93150669], action: [-0.23640841 -0.167     ]\n",
      "Episode: 550/3000, Reward: -12756.594556663294, done: False\n",
      "state: [-0.54007427 61.58655748], action: [-0.48070642 -0.167     ]\n",
      "Episode: 551/3000, Reward: -12690.903186492005, done: False\n",
      "state: [-0.5403826  61.36935129], action: [-0.19234438 -0.167     ]\n",
      "Episode: 552/3000, Reward: -12628.856187364408, done: False\n",
      "state: [-0.53991186 60.88112723], action: [-0.22148712 -0.167     ]\n",
      "Episode: 553/3000, Reward: -13126.714592290675, done: False\n",
      "state: [-0.53992833 60.87823947], action: [-0.25754836 -0.167     ]\n",
      "Episode: 554/3000, Reward: -12366.789406238795, done: False\n",
      "state: [-0.53914987 60.42076181], action: [-0.1650931 -0.167    ]\n",
      "Episode: 555/3000, Reward: -12188.164959163843, done: False\n",
      "state: [-0.538264   60.18671103], action: [-0.18080544 -0.167     ]\n",
      "Episode: 556/3000, Reward: -12671.896142576175, done: False\n",
      "state: [-0.5387773  60.00470131], action: [-0.18394008 -0.167     ]\n",
      "Episode: 557/3000, Reward: -12044.991393689772, done: False\n",
      "state: [-0.53830031 59.84828858], action: [-0.18486133 -0.167     ]\n",
      "Episode: 558/3000, Reward: -11949.957346895571, done: False\n",
      "state: [-0.53818353 59.57210093], action: [-0.23436172 -0.167     ]\n",
      "Episode: 559/3000, Reward: -11932.276945443731, done: False\n",
      "state: [-0.537574   59.26361454], action: [-0.21552974 -0.167     ]\n",
      "Episode: 560/3000, Reward: -11769.669062955307, done: False\n",
      "state: [-0.53673123 59.03823556], action: [-0.21769662 -0.167     ]\n",
      "Episode: 561/3000, Reward: -12089.836849164525, done: False\n",
      "state: [-0.5354153  58.92218513], action: [0.05047935 0.3692629 ]\n",
      "Episode: 562/3000, Reward: -11589.713508820483, done: False\n",
      "state: [-0.53646466 58.66871831], action: [-0.23053662 -0.167     ]\n",
      "Episode: 563/3000, Reward: -11679.60650679217, done: False\n",
      "state: [-0.53674076 58.64820752], action: [-0.22484359 -0.167     ]\n",
      "Episode: 564/3000, Reward: -11969.869217832154, done: False\n",
      "state: [-0.53622361 58.25761863], action: [-0.2184814 -0.167    ]\n",
      "Episode: 565/3000, Reward: -11840.053977577456, done: False\n",
      "state: [-0.53573431 58.13561758], action: [-0.34530836 -0.167     ]\n",
      "Episode: 566/3000, Reward: -11842.156839323487, done: False\n",
      "state: [-0.53520763 57.86980476], action: [-0.2880162 -0.167    ]\n",
      "Episode: 567/3000, Reward: -11927.393873548806, done: False\n",
      "state: [-0.53559998 57.88249159], action: [-0.43881628 -0.167     ]\n",
      "Episode: 568/3000, Reward: -11500.599679118694, done: False\n",
      "state: [-0.53483566 57.51130046], action: [-0.2642886 -0.167    ]\n",
      "Episode: 569/3000, Reward: -11663.140383320519, done: False\n",
      "state: [-0.53433071 57.33930493], action: [-0.2937778 -0.167    ]\n",
      "Episode: 570/3000, Reward: -11491.36966227499, done: False\n",
      "state: [-0.53372264 57.01714044], action: [-0.24875854 -0.167     ]\n",
      "Episode: 571/3000, Reward: -11992.74913521982, done: False\n",
      "state: [-0.53485742 56.95583609], action: [-0.26227915 -0.167     ]\n",
      "Episode: 572/3000, Reward: -11204.762106760214, done: False\n",
      "state: [-0.53451994 56.89030442], action: [-0.18527395 -0.167     ]\n",
      "Episode: 573/3000, Reward: -10937.693101488689, done: False\n",
      "state: [-0.53322814 56.66667462], action: [-0.32698333 -0.167     ]\n",
      "Episode: 574/3000, Reward: -11029.73652458569, done: False\n",
      "state: [-0.53351374 56.41812222], action: [-0.31764436 -0.167     ]\n",
      "Episode: 575/3000, Reward: -11223.73434102959, done: False\n",
      "state: [-0.52410437 56.42348454], action: [ 0.84502375 -0.8722769 ]\n",
      "Episode: 576/3000, Reward: -10954.830985116598, done: False\n",
      "state: [-0.53282695 56.19940003], action: [-0.22872986 -0.167     ]\n",
      "Episode: 577/3000, Reward: -11351.673996885007, done: False\n",
      "state: [-0.53226486 56.0242342 ], action: [-0.2537334 -0.167    ]\n",
      "Episode: 578/3000, Reward: -10634.396272584407, done: False\n",
      "state: [-0.53221298 55.82955808], action: [-0.26443762 -0.167     ]\n",
      "Episode: 579/3000, Reward: -10778.311159753917, done: False\n",
      "state: [-0.53235801 55.82695246], action: [-0.31384593 -0.167     ]\n",
      "Episode: 580/3000, Reward: -10684.729835421875, done: False\n",
      "state: [-0.53226873 55.77411657], action: [-0.3418161 -0.167    ]\n",
      "Episode: 581/3000, Reward: -10991.981195777951, done: False\n",
      "state: [-0.53563088 55.62366163], action: [-0.9411214  -0.02388762]\n",
      "Episode: 582/3000, Reward: -10550.019730299886, done: False\n",
      "state: [-0.53199161 55.57929083], action: [-0.28751937 -0.167     ]\n",
      "Episode: 583/3000, Reward: -10746.735589962655, done: False\n",
      "state: [-0.53142377 55.36201558], action: [-0.2477849 -0.167    ]\n",
      "Episode: 584/3000, Reward: -10542.966163637528, done: False\n",
      "state: [-0.53079271 55.23827569], action: [-0.1606183 -0.167    ]\n",
      "Episode: 585/3000, Reward: -10446.488816271625, done: False\n",
      "state: [-0.53049575 55.06201642], action: [-0.27649397 -0.167     ]\n",
      "Episode: 586/3000, Reward: -10625.797342849437, done: False\n",
      "state: [-0.53054821 55.09965211], action: [-0.35560772 -0.167     ]\n",
      "Episode: 587/3000, Reward: -10306.755918815907, done: False\n",
      "state: [-0.53067636 54.92657483], action: [-0.25789025 -0.167     ]\n",
      "Episode: 588/3000, Reward: -10699.816143013251, done: False\n",
      "state: [-0.53008962 54.7677371 ], action: [-0.2609572 -0.167    ]\n",
      "Episode: 589/3000, Reward: -10254.708906545227, done: False\n",
      "state: [-0.53018981 54.75968498], action: [-0.2631386 -0.167    ]\n",
      "Episode: 590/3000, Reward: -10718.140765142529, done: False\n",
      "state: [-0.52981634 54.65621   ], action: [-0.26653674 -0.167     ]\n",
      "Episode: 591/3000, Reward: -10497.485052542666, done: False\n",
      "state: [-0.53010384 54.55443968], action: [-0.27213028 -0.167     ]\n",
      "Episode: 592/3000, Reward: -10614.370534624033, done: False\n",
      "state: [-0.52960348 54.46922469], action: [-0.28783426 -0.167     ]\n",
      "Episode: 593/3000, Reward: -10543.148967880454, done: False\n",
      "state: [-0.52995815 54.46807041], action: [-0.3266256 -0.167    ]\n",
      "Episode: 594/3000, Reward: -10700.623605737333, done: False\n",
      "state: [-0.52896543 54.46789081], action: [-0.32247892 -0.167     ]\n",
      "Episode: 595/3000, Reward: -10973.79008787956, done: False\n",
      "state: [-0.52934158 54.36088602], action: [-0.28901988 -0.167     ]\n",
      "Episode: 596/3000, Reward: -10537.882863262244, done: False\n",
      "state: [-0.52905514 54.27118089], action: [-0.2598833 -0.167    ]\n",
      "Episode: 597/3000, Reward: -10513.696337909916, done: False\n",
      "state: [-0.52882125 54.27473733], action: [-0.1733229 -0.167    ]\n",
      "Episode: 598/3000, Reward: -10196.929188044332, done: False\n",
      "state: [-0.52911422 54.21493434], action: [-0.23799963 -0.167     ]\n",
      "Episode: 599/3000, Reward: -10040.836796220361, done: False\n",
      "state: [-0.52891443 54.25201243], action: [-0.23321134 -0.167     ]\n",
      "Episode: 600/3000, Reward: -10468.73213661365, done: False\n",
      "state: [-0.52885773 54.14625797], action: [-0.18803896 -0.167     ]\n",
      "Episode: 601/3000, Reward: -10348.260604430296, done: False\n",
      "state: [-0.52784397 54.21424553], action: [-0.49007225 -0.167     ]\n",
      "Episode: 602/3000, Reward: -10221.565086434402, done: False\n",
      "state: [-0.52913509 54.13728067], action: [-0.2695852 -0.167    ]\n",
      "Episode: 603/3000, Reward: -10471.984256808793, done: False\n",
      "state: [-0.52904731 54.10040609], action: [-0.26504067 -0.167     ]\n",
      "Episode: 604/3000, Reward: -10192.215292819854, done: False\n",
      "state: [-0.52874003 53.97371774], action: [-0.2553174 -0.167    ]\n",
      "Episode: 605/3000, Reward: -10444.512002412106, done: False\n",
      "state: [-0.52843471 54.04887095], action: [-0.2986984 -0.167    ]\n",
      "Episode: 606/3000, Reward: -10374.699513728072, done: False\n",
      "state: [-0.52889553 54.08768679], action: [-0.2829041 -0.167    ]\n",
      "Episode: 607/3000, Reward: -10231.010158552852, done: False\n",
      "state: [-0.52827362 53.98249038], action: [-0.22533973 -0.167     ]\n",
      "Episode: 608/3000, Reward: -10164.536479521897, done: False\n",
      "state: [-0.52861191 54.14063056], action: [-0.2234451 -0.167    ]\n",
      "Episode: 609/3000, Reward: -10189.29836346174, done: False\n",
      "state: [-0.52899839 54.26708632], action: [-0.37982595 -0.167     ]\n",
      "Episode: 610/3000, Reward: -10306.808301605055, done: False\n",
      "state: [-0.52926728 54.17049981], action: [-0.2344915 -0.167    ]\n",
      "Episode: 611/3000, Reward: -10202.189206085022, done: False\n",
      "state: [-0.52999757 54.29871959], action: [-0.2938928 -0.167    ]\n",
      "Episode: 612/3000, Reward: -10704.496142545946, done: False\n",
      "state: [-0.5287057 54.1726495], action: [-0.23420309 -0.167     ]\n",
      "Episode: 613/3000, Reward: -10433.159409260046, done: False\n",
      "state: [-0.53011918 54.36458084], action: [-0.20567238 -0.167     ]\n",
      "Episode: 614/3000, Reward: -10527.247251498047, done: False\n",
      "state: [-0.5280941  54.43343697], action: [-0.63614905 -0.167     ]\n",
      "Episode: 615/3000, Reward: -10272.940523973008, done: False\n",
      "state: [-0.52930491 54.28957802], action: [-0.25601265 -0.167     ]\n",
      "Episode: 616/3000, Reward: -10358.906360734902, done: False\n",
      "state: [-0.52899481 54.22102632], action: [-0.20619476 -0.167     ]\n",
      "Episode: 617/3000, Reward: -10829.014052278006, done: False\n",
      "state: [-0.52866298 54.40617206], action: [-0.48133975 -0.167     ]\n",
      "Episode: 618/3000, Reward: -10521.224971882148, done: False\n",
      "state: [-0.53030581 54.42494391], action: [-0.30959603 -0.167     ]\n",
      "Episode: 619/3000, Reward: -10533.947393919681, done: False\n",
      "state: [-0.53019589 54.39960014], action: [-0.26957104 -0.167     ]\n",
      "Episode: 620/3000, Reward: -10710.529751349279, done: False\n",
      "state: [-0.5296256 54.3692664], action: [-0.3098133 -0.167    ]\n",
      "Episode: 621/3000, Reward: -10478.362667413106, done: False\n",
      "state: [-0.52974117 54.46272981], action: [-0.32144633 -0.167     ]\n",
      "Episode: 622/3000, Reward: -10626.051106681989, done: False\n",
      "state: [-0.52987103 54.51468971], action: [-0.28540435 -0.167     ]\n",
      "Episode: 623/3000, Reward: -10658.425205910966, done: False\n",
      "state: [-0.52958841 54.51394706], action: [-0.28195277 -0.167     ]\n",
      "Episode: 624/3000, Reward: -11000.897454444741, done: False\n",
      "state: [-0.5292159  54.67280019], action: [0.00120792 0.37571633]\n",
      "Episode: 625/3000, Reward: -10685.773606577408, done: False\n",
      "state: [-0.53010489 54.71571805], action: [-0.22629546 -0.167     ]\n",
      "Episode: 626/3000, Reward: -10714.325337780305, done: False\n",
      "state: [-0.53003431 54.81995616], action: [-0.19764335 -0.167     ]\n",
      "Episode: 627/3000, Reward: -10720.971815793155, done: False\n",
      "state: [-0.5282059 55.143936 ], action: [-0.7083484 -0.167    ]\n",
      "Episode: 628/3000, Reward: -10922.653627836517, done: False\n",
      "state: [-0.53031021 54.97187254], action: [-0.1791112 -0.167    ]\n",
      "Episode: 629/3000, Reward: -10886.785396755695, done: False\n",
      "state: [-0.53085089 55.10581376], action: [-0.22042398 -0.167     ]\n",
      "Episode: 630/3000, Reward: -10934.964881641457, done: False\n",
      "state: [-0.53054529 55.09170874], action: [-0.16147664 -0.167     ]\n",
      "Episode: 631/3000, Reward: -10829.14708188577, done: False\n",
      "state: [-0.53097098 55.19437378], action: [-0.23700617 -0.167     ]\n",
      "Episode: 632/3000, Reward: -11558.60217966724, done: False\n",
      "state: [-0.53070488 55.25475954], action: [-0.2422163 -0.167    ]\n",
      "Episode: 633/3000, Reward: -11310.007119018714, done: False\n",
      "state: [-0.53113484 55.29089758], action: [-0.20452496 -0.167     ]\n",
      "Episode: 634/3000, Reward: -10988.791501863905, done: False\n",
      "state: [-0.53162657 55.42191733], action: [-0.27030668 -0.167     ]\n",
      "Episode: 635/3000, Reward: -10826.112922419159, done: False\n",
      "state: [-0.53129805 55.3356613 ], action: [-0.23156217 -0.167     ]\n",
      "Episode: 636/3000, Reward: -11345.607313414106, done: False\n",
      "state: [-0.53144133 55.45498456], action: [-0.22310077 -0.167     ]\n",
      "Episode: 637/3000, Reward: -11330.622237467662, done: False\n",
      "state: [-0.53148323 55.56909856], action: [-0.2263027 -0.167    ]\n",
      "Episode: 638/3000, Reward: -11173.441472945004, done: False\n",
      "state: [-0.53138399 55.61451727], action: [-0.27965468 -0.167     ]\n",
      "Episode: 639/3000, Reward: -11180.308668528749, done: False\n",
      "state: [-0.5317384  55.72389315], action: [-0.18215564 -0.167     ]\n",
      "Episode: 640/3000, Reward: -10866.949278968987, done: False\n",
      "state: [-0.53166673 55.77384653], action: [-0.23716098 -0.167     ]\n",
      "Episode: 641/3000, Reward: -10874.950087889963, done: False\n",
      "state: [-0.53185966 55.86330528], action: [-0.2656648 -0.167    ]\n",
      "Episode: 642/3000, Reward: -11096.70980416136, done: False\n",
      "state: [-0.53202556 55.95033427], action: [-0.21910612 -0.167     ]\n",
      "Episode: 643/3000, Reward: -11327.738604324268, done: False\n",
      "state: [-0.53196314 56.04326066], action: [-0.29899716 -0.167     ]\n",
      "Episode: 644/3000, Reward: -11229.499801400645, done: False\n",
      "state: [-0.53226072 56.08264966], action: [-0.21362287 -0.167     ]\n",
      "Episode: 645/3000, Reward: -11264.809286269927, done: False\n",
      "state: [-0.53239955 56.18796467], action: [-0.16607998 -0.167     ]\n",
      "Episode: 646/3000, Reward: -11286.930156916758, done: False\n",
      "state: [-0.53305057 56.33266205], action: [-0.24285178 -0.167     ]\n",
      "Episode: 647/3000, Reward: -11206.797976281277, done: False\n",
      "state: [-0.53295833 56.29290099], action: [-0.2779871 -0.167    ]\n",
      "Episode: 648/3000, Reward: -11228.724816926271, done: False\n",
      "state: [-0.53253103 56.30919237], action: [-0.2101835 -0.167    ]\n",
      "Episode: 649/3000, Reward: -11354.571723178105, done: False\n",
      "state: [-0.53299332 56.49877527], action: [-0.21241386 -0.167     ]\n",
      "Episode: 650/3000, Reward: -11304.058428923649, done: False\n",
      "state: [-0.53268975 56.44572671], action: [-0.15558232 -0.167     ]\n",
      "Episode: 651/3000, Reward: -11633.033928205694, done: False\n",
      "state: [-0.53384664 56.59587512], action: [-0.28873315 -0.167     ]\n",
      "Episode: 652/3000, Reward: -11519.397577700569, done: False\n",
      "state: [-0.5336077  56.61480403], action: [-0.32525498 -0.167     ]\n",
      "Episode: 653/3000, Reward: -11115.423418169028, done: False\n",
      "state: [-0.53375531 56.66071377], action: [-0.32902932 -0.167     ]\n",
      "Episode: 654/3000, Reward: -12232.939743923442, done: False\n",
      "state: [-0.53334311 56.70455154], action: [-0.23357564 -0.167     ]\n",
      "Episode: 655/3000, Reward: -11609.362384120363, done: False\n",
      "state: [-0.5334373  56.70717538], action: [-0.3103615 -0.167    ]\n",
      "Episode: 656/3000, Reward: -11502.58685178873, done: False\n",
      "state: [-0.53373012 56.80908936], action: [-0.24788515 -0.167     ]\n",
      "Episode: 657/3000, Reward: -11350.594856649544, done: False\n",
      "state: [-0.53399208 56.86865928], action: [-0.24929169 -0.167     ]\n",
      "Episode: 658/3000, Reward: -11358.814620265684, done: False\n",
      "state: [-0.53211638 56.78431879], action: [-0.4493933 -0.167    ]\n",
      "Episode: 659/3000, Reward: -11160.489198121773, done: False\n",
      "state: [-0.53347934 56.8019004 ], action: [-0.31153312 -0.167     ]\n",
      "Episode: 660/3000, Reward: -11370.218703145008, done: False\n",
      "state: [-0.53399982 56.84845675], action: [-0.2979686 -0.167    ]\n",
      "Episode: 661/3000, Reward: -11582.982455739064, done: False\n",
      "state: [-0.53394621 56.87232644], action: [-0.19295046 -0.167     ]\n",
      "Episode: 662/3000, Reward: -11974.77687259042, done: False\n",
      "state: [-0.53380559 56.89922458], action: [-0.2501072 -0.167    ]\n",
      "Episode: 663/3000, Reward: -11270.404059587112, done: False\n",
      "state: [-0.53395571 56.87725668], action: [-0.23391823 -0.167     ]\n",
      "Episode: 664/3000, Reward: -11841.53692822235, done: False\n",
      "state: [-0.53411181 56.89064523], action: [-0.27533448 -0.167     ]\n",
      "Episode: 665/3000, Reward: -11607.260120750028, done: False\n",
      "state: [-0.53359909 56.94400497], action: [-0.25874114 -0.167     ]\n",
      "Episode: 666/3000, Reward: -11405.634682944199, done: False\n",
      "state: [-0.53382075 56.91346266], action: [-0.1970861 -0.167    ]\n",
      "Episode: 667/3000, Reward: -11530.474874018359, done: False\n",
      "state: [-0.53398546 56.95684471], action: [-0.3126246 -0.167    ]\n",
      "Episode: 668/3000, Reward: -11608.264889783539, done: False\n",
      "state: [-0.53396095 57.02674527], action: [-0.2457286 -0.167    ]\n",
      "Episode: 669/3000, Reward: -11451.679106003796, done: False\n",
      "state: [-0.53395613 56.95484057], action: [-0.21654436 -0.167     ]\n",
      "Episode: 670/3000, Reward: -11599.675047509887, done: False\n",
      "state: [-0.53353395 57.18671789], action: [-0.5636717 -0.167    ]\n",
      "Episode: 671/3000, Reward: -11344.492339506454, done: False\n",
      "state: [-0.53386547 56.85514326], action: [-0.12114402 -0.167     ]\n",
      "Episode: 672/3000, Reward: -11346.863076911193, done: False\n",
      "state: [-0.53346482 57.04995341], action: [-0.17997876 -0.167     ]\n",
      "Episode: 673/3000, Reward: -11358.726577907737, done: False\n",
      "state: [-0.53414789 57.07437885], action: [-0.2892261 -0.167    ]\n",
      "Episode: 674/3000, Reward: -11503.486585324383, done: False\n",
      "state: [-0.53383954 57.0400931 ], action: [-0.2408908 -0.167    ]\n",
      "Episode: 675/3000, Reward: -11898.07827178211, done: False\n",
      "state: [-0.53402123 57.07307353], action: [-0.23400837 -0.167     ]\n",
      "Episode: 676/3000, Reward: -11685.361895867149, done: False\n",
      "state: [-0.53431131 57.12511001], action: [-0.25610176 -0.167     ]\n",
      "Episode: 677/3000, Reward: -11401.46027123593, done: False\n",
      "state: [-0.53447869 57.07826244], action: [-0.28021017 -0.167     ]\n",
      "Episode: 678/3000, Reward: -11584.995087570293, done: False\n",
      "state: [-0.53421366 57.1231728 ], action: [-0.29017663 -0.167     ]\n",
      "Episode: 679/3000, Reward: -11346.481064180294, done: False\n",
      "state: [-0.53371844 57.06013058], action: [-0.24249278 -0.167     ]\n",
      "Episode: 680/3000, Reward: -11698.78173317952, done: False\n",
      "state: [-0.53445737 57.1746957 ], action: [-0.30202317 -0.167     ]\n",
      "Episode: 681/3000, Reward: -11667.1972912543, done: False\n",
      "state: [-0.53368223 57.1211249 ], action: [-0.20505854 -0.167     ]\n",
      "Episode: 682/3000, Reward: -11771.28845473556, done: False\n",
      "state: [-0.5338675  57.10357372], action: [-0.19083777 -0.167     ]\n",
      "Episode: 683/3000, Reward: -11362.889529847369, done: False\n",
      "state: [-0.53428222 57.18827852], action: [-0.2660689 -0.167    ]\n",
      "Episode: 684/3000, Reward: -11617.238072281238, done: False\n",
      "state: [-0.53455895 57.25417918], action: [-0.26828647 -0.167     ]\n",
      "Episode: 685/3000, Reward: -11821.650270448612, done: False\n",
      "state: [-0.53407768 57.27630554], action: [-0.13276383 -0.167     ]\n",
      "Episode: 686/3000, Reward: -11511.358630466093, done: False\n",
      "state: [-0.53474541 57.32002794], action: [-0.31730822 -0.167     ]\n",
      "Episode: 687/3000, Reward: -11610.535356086473, done: False\n",
      "state: [-0.5349776 57.3622601], action: [-0.30802932 -0.167     ]\n",
      "Episode: 688/3000, Reward: -11416.571042928275, done: False\n",
      "state: [-0.53519255 57.46452475], action: [-0.23656687 -0.167     ]\n",
      "Episode: 689/3000, Reward: -12024.541625121621, done: False\n",
      "state: [-0.53445411 57.385343  ], action: [-0.1792995 -0.167    ]\n",
      "Episode: 690/3000, Reward: -12215.928385282417, done: False\n",
      "state: [-0.53464693 57.47862527], action: [-0.26494846 -0.167     ]\n",
      "Episode: 691/3000, Reward: -11682.932812924182, done: False\n",
      "state: [-0.53450165 57.45869606], action: [-0.24653849 -0.167     ]\n",
      "Episode: 692/3000, Reward: -11690.227454050817, done: False\n",
      "state: [-0.53506566 57.68823636], action: [-0.19077896 -0.167     ]\n",
      "Episode: 693/3000, Reward: -12060.606403794955, done: False\n",
      "state: [-0.5353181  57.70671741], action: [-0.33313572 -0.167     ]\n",
      "Episode: 694/3000, Reward: -12321.160297297214, done: False\n",
      "state: [-0.53523674 57.74520384], action: [-0.26715323 -0.167     ]\n",
      "Episode: 695/3000, Reward: -11636.056678989467, done: False\n",
      "state: [-0.53512775 57.76480733], action: [-0.27405423 -0.167     ]\n",
      "Episode: 696/3000, Reward: -11620.907105263275, done: False\n",
      "state: [-0.53533366 57.87985448], action: [-0.2121443 -0.167    ]\n",
      "Episode: 697/3000, Reward: -11640.912073778187, done: False\n",
      "state: [-0.53573763 57.9180397 ], action: [-0.09609203 -0.167     ]\n",
      "Episode: 698/3000, Reward: -11792.92501532477, done: False\n",
      "state: [-0.53542923 58.06098186], action: [-0.24978891 -0.167     ]\n",
      "Episode: 699/3000, Reward: -11720.073124621462, done: False\n",
      "state: [-0.53542579 58.09898076], action: [-0.2035525 -0.167    ]\n",
      "Episode: 700/3000, Reward: -11771.21577785801, done: False\n",
      "state: [-0.53669123 58.28907861], action: [-0.26296106 -0.167     ]\n",
      "Episode: 701/3000, Reward: -12001.011348348304, done: False\n",
      "state: [-0.53592349 58.24935881], action: [-0.24475339 -0.167     ]\n",
      "Episode: 702/3000, Reward: -11766.934065549316, done: False\n",
      "state: [-0.5359069  58.29596279], action: [-0.23404443 -0.167     ]\n",
      "Episode: 703/3000, Reward: -11776.581754872132, done: False\n",
      "state: [-0.53596898 58.36377164], action: [-0.21034393 -0.167     ]\n",
      "Episode: 704/3000, Reward: -11787.18780293499, done: False\n",
      "state: [-0.53579544 58.28944701], action: [-0.18919049 -0.167     ]\n",
      "Episode: 705/3000, Reward: -12104.128196713575, done: False\n",
      "state: [-0.53635999 58.38720941], action: [-0.22585022 -0.167     ]\n",
      "Episode: 706/3000, Reward: -12138.142082407581, done: False\n",
      "state: [-0.53604039 58.33829847], action: [-0.25533167 -0.167     ]\n",
      "Episode: 707/3000, Reward: -11967.588818684073, done: False\n",
      "state: [-0.53599225 58.3299955 ], action: [-0.2172169 -0.167    ]\n",
      "Episode: 708/3000, Reward: -11874.660102948492, done: False\n",
      "state: [-0.53638208 58.51145494], action: [-0.25833887 -0.167     ]\n",
      "Episode: 709/3000, Reward: -11934.839571469758, done: False\n",
      "state: [-0.53653477 58.48430454], action: [-0.2672241 -0.167    ]\n",
      "Episode: 710/3000, Reward: -12207.378091845838, done: False\n",
      "state: [-0.53738804 58.58367143], action: [-0.43044657 -0.79968673]\n",
      "Episode: 711/3000, Reward: -11889.03153082908, done: False\n",
      "state: [-0.5368367  58.67541925], action: [-0.27995002 -0.167     ]\n",
      "Episode: 712/3000, Reward: -11982.214678776047, done: False\n",
      "state: [-0.5362997  58.49334514], action: [-0.28692436 -0.167     ]\n",
      "Episode: 713/3000, Reward: -12649.656449597725, done: False\n",
      "state: [-0.53651364 58.6784301 ], action: [-0.24378489 -0.167     ]\n",
      "Episode: 714/3000, Reward: -11891.25478143943, done: False\n",
      "state: [-0.5366815  58.74199194], action: [-0.23538533 -0.167     ]\n",
      "Episode: 715/3000, Reward: -11938.289373621708, done: False\n",
      "state: [-0.53676359 58.78911489], action: [-0.23850338 -0.167     ]\n",
      "Episode: 716/3000, Reward: -12211.24568910863, done: False\n",
      "state: [-0.53700085 58.86674386], action: [-0.2873304 -0.167    ]\n",
      "Episode: 717/3000, Reward: -12315.7334021492, done: False\n",
      "state: [-0.53686688 58.90328135], action: [-0.23185095 -0.167     ]\n",
      "Episode: 718/3000, Reward: -12121.251177981752, done: False\n",
      "state: [-0.53692869 59.04239855], action: [-0.21019809 -0.167     ]\n",
      "Episode: 719/3000, Reward: -12117.121833239375, done: False\n",
      "state: [-0.53744781 59.19181515], action: [-0.18847683 -0.167     ]\n",
      "Episode: 720/3000, Reward: -12067.428485996208, done: False\n",
      "state: [-0.53741708 59.28847675], action: [-0.20625685 -0.167     ]\n",
      "Episode: 721/3000, Reward: -12216.350207341291, done: False\n",
      "state: [-0.53739687 59.42331904], action: [-0.27949995 -0.167     ]\n",
      "Episode: 722/3000, Reward: -12174.703659069117, done: False\n",
      "state: [-0.5375907  59.42105772], action: [-0.17567886 -0.167     ]\n",
      "Episode: 723/3000, Reward: -12261.699264680348, done: False\n",
      "state: [-0.53828687 59.51748839], action: [-0.30149615 -0.167     ]\n",
      "Episode: 724/3000, Reward: -12243.520276557208, done: False\n",
      "state: [-0.53790931 59.58224184], action: [-0.2813557 -0.167    ]\n",
      "Episode: 725/3000, Reward: -12538.00706703998, done: False\n",
      "state: [-0.53804584 59.67131756], action: [-0.20858592 -0.167     ]\n",
      "Episode: 726/3000, Reward: -12169.972861411079, done: False\n",
      "state: [-0.53883431 59.80561386], action: [-0.2854394 -0.167    ]\n",
      "Episode: 727/3000, Reward: -12808.684540175518, done: False\n",
      "state: [-0.53839364 59.76119775], action: [-0.29166415 -0.167     ]\n",
      "Episode: 728/3000, Reward: -12272.213113999931, done: False\n",
      "state: [-0.53873433 59.99277483], action: [-0.21025643 -0.167     ]\n",
      "Episode: 729/3000, Reward: -12687.739986424765, done: False\n",
      "state: [-0.53861984 59.97336646], action: [-0.24338299 -0.167     ]\n",
      "Episode: 730/3000, Reward: -12609.723564447584, done: False\n",
      "state: [-0.53883942 60.2313343 ], action: [-0.26946846 -0.167     ]\n",
      "Episode: 731/3000, Reward: -12586.636999439868, done: False\n",
      "state: [-0.53927023 60.40299337], action: [-0.22875156 -0.167     ]\n",
      "Episode: 732/3000, Reward: -12552.651145423017, done: False\n",
      "state: [-0.53931105 60.56033949], action: [-0.27789557 -0.167     ]\n",
      "Episode: 733/3000, Reward: -12752.652146702927, done: False\n",
      "state: [-0.5396234  60.73536201], action: [-0.23746698 -0.167     ]\n",
      "Episode: 734/3000, Reward: -12821.269749395227, done: False\n",
      "state: [-0.53950666 60.77553893], action: [-0.25617304 -0.167     ]\n",
      "Episode: 735/3000, Reward: -12725.053336764264, done: False\n",
      "state: [-0.53995851 61.04930688], action: [-0.26638082 -0.167     ]\n",
      "Episode: 736/3000, Reward: -12840.746679759332, done: False\n",
      "state: [-0.54002373 61.17286777], action: [-0.23362613 -0.167     ]\n",
      "Episode: 737/3000, Reward: -13097.428087534787, done: False\n",
      "state: [-0.54023346 61.15080213], action: [-0.2642815 -0.167    ]\n",
      "Episode: 738/3000, Reward: -13381.930322658753, done: False\n",
      "state: [-0.54134765 61.40400688], action: [-0.29939312 -0.167     ]\n",
      "Episode: 739/3000, Reward: -13067.35716039582, done: False\n",
      "state: [-0.54010547 61.32800818], action: [-0.14534068 -0.167     ]\n",
      "Episode: 740/3000, Reward: -12947.987009553179, done: False\n",
      "state: [-0.54041677 61.43786056], action: [-0.17776316 -0.167     ]\n",
      "Episode: 741/3000, Reward: -12960.650487461106, done: False\n",
      "state: [-0.54027184 61.50935157], action: [-0.20979697 -0.167     ]\n",
      "Episode: 742/3000, Reward: -13072.237761874512, done: False\n",
      "state: [-0.540841   61.57266095], action: [-0.2740754 -0.167    ]\n",
      "Episode: 743/3000, Reward: -13002.824818550724, done: False\n",
      "state: [-0.53986364 61.57000299], action: [-0.07824668 -0.167     ]\n",
      "Episode: 744/3000, Reward: -13228.03575747972, done: False\n",
      "state: [-0.5409155  61.48855011], action: [-0.25223377 -0.167     ]\n",
      "Episode: 745/3000, Reward: -12933.152193720303, done: False\n",
      "state: [-0.54055614 61.40179725], action: [-0.25449702 -0.167     ]\n",
      "Episode: 746/3000, Reward: -12958.524144041747, done: False\n",
      "state: [-0.54060813 61.42955193], action: [-0.24561389 -0.167     ]\n",
      "Episode: 747/3000, Reward: -12947.912323540824, done: False\n",
      "state: [-0.54083263 61.49940081], action: [-0.30445483 -0.167     ]\n",
      "Episode: 748/3000, Reward: -12970.260216609426, done: False\n",
      "state: [-0.54072937 61.57006192], action: [-0.26163253 -0.167     ]\n",
      "Episode: 749/3000, Reward: -13094.525181121291, done: False\n",
      "state: [-0.54155263 61.85876529], action: [-0.22404663 -0.167     ]\n",
      "Episode: 750/3000, Reward: -12950.542511528924, done: False\n",
      "state: [-0.54093686 61.59865093], action: [-0.2640473 -0.167    ]\n",
      "Episode: 751/3000, Reward: -13031.407570782987, done: False\n",
      "state: [-0.54079533 61.5898206 ], action: [-0.23936664 -0.167     ]\n",
      "Episode: 752/3000, Reward: -13169.693048507295, done: False\n",
      "state: [-0.54099827 61.75249482], action: [-0.20105003 -0.167     ]\n",
      "Episode: 753/3000, Reward: -13215.441009246366, done: False\n",
      "state: [-0.54107062 61.80854032], action: [-0.2726 -0.167 ]\n",
      "Episode: 754/3000, Reward: -13154.137241547194, done: False\n",
      "state: [-0.54084258 62.05224675], action: [-0.12744616 -0.167     ]\n",
      "Episode: 755/3000, Reward: -13128.794973138229, done: False\n",
      "state: [-0.54120667 61.96834066], action: [-0.28161564 -0.167     ]\n",
      "Episode: 756/3000, Reward: -13091.536977176826, done: False\n",
      "state: [-0.54070092 61.83774127], action: [-0.09058624 -0.167     ]\n",
      "Episode: 757/3000, Reward: -13151.653115324983, done: False\n",
      "state: [-0.54127684 62.01493226], action: [-0.18921992 -0.167     ]\n",
      "Episode: 758/3000, Reward: -13270.658999156904, done: False\n",
      "state: [-0.54143602 62.26041367], action: [-0.21360102 -0.167     ]\n",
      "Episode: 759/3000, Reward: -13295.969373478385, done: False\n",
      "state: [-0.54176914 62.3466443 ], action: [-0.20355982 -0.167     ]\n",
      "Episode: 760/3000, Reward: -13476.111944697557, done: False\n",
      "state: [-0.54268663 62.60060253], action: [-0.22213997 -0.167     ]\n",
      "Episode: 761/3000, Reward: -13424.590456274896, done: False\n",
      "state: [-0.54184659 62.58850001], action: [-0.23378481 -0.167     ]\n",
      "Episode: 762/3000, Reward: -13466.115201880053, done: False\n",
      "state: [-0.542389  62.8216864], action: [-0.2186049 -0.167    ]\n",
      "Episode: 763/3000, Reward: -13558.296953993418, done: False\n",
      "state: [-0.54277161 62.96023532], action: [-0.28599292 -0.167     ]\n",
      "Episode: 764/3000, Reward: -13499.242641490922, done: False\n",
      "state: [-0.54209336 62.85314632], action: [-0.2563441 -0.167    ]\n",
      "Episode: 765/3000, Reward: -13412.550573506836, done: False\n",
      "state: [-0.54211635 62.68602063], action: [-0.22832492 -0.167     ]\n",
      "Episode: 766/3000, Reward: -13582.988209289957, done: False\n",
      "state: [-0.54226892 62.88349984], action: [-0.22954671 -0.167     ]\n",
      "Episode: 767/3000, Reward: -13470.207070210497, done: False\n",
      "state: [-0.54256217 62.88157775], action: [-0.27288952 -0.167     ]\n",
      "Episode: 768/3000, Reward: -13435.999778001531, done: False\n",
      "state: [-0.54210429 62.77954006], action: [-0.1991971 -0.167    ]\n",
      "Episode: 769/3000, Reward: -13446.381851266982, done: False\n",
      "state: [-0.54199175 62.87038032], action: [-0.1565016 -0.167    ]\n",
      "Episode: 770/3000, Reward: -13544.162859314205, done: False\n",
      "state: [-0.5414928  62.91204752], action: [-0.47751462 -0.167     ]\n",
      "Episode: 771/3000, Reward: -13674.774272894338, done: False\n",
      "state: [-0.54247836 62.88833608], action: [-0.21059184 -0.167     ]\n",
      "Episode: 772/3000, Reward: -13540.315170658729, done: False\n",
      "state: [-0.54220714 62.6716046 ], action: [-0.20695801 -0.167     ]\n",
      "Episode: 773/3000, Reward: -13412.990040416722, done: False\n",
      "state: [-0.54197022 62.55529259], action: [-0.21805997 -0.167     ]\n",
      "Episode: 774/3000, Reward: -13392.26641363862, done: False\n",
      "state: [-0.54301527 62.90378818], action: [-0.2633587 -0.167    ]\n",
      "Episode: 775/3000, Reward: -13421.750796563072, done: False\n",
      "state: [-0.54179138 62.67070171], action: [-0.16814172 -0.167     ]\n",
      "Episode: 776/3000, Reward: -13429.535362239532, done: False\n",
      "state: [-0.5420158  62.67290931], action: [-0.23805721 -0.167     ]\n",
      "Episode: 777/3000, Reward: -13361.030931502966, done: False\n",
      "state: [-0.54232331 62.62191207], action: [-0.24719761 -0.167     ]\n",
      "Episode: 778/3000, Reward: -13365.03424897746, done: False\n",
      "state: [-0.54194694 62.43011212], action: [-0.26055902 -0.167     ]\n",
      "Episode: 779/3000, Reward: -13375.150612142932, done: False\n",
      "state: [-0.54215811 62.61174002], action: [-0.23476546 -0.167     ]\n",
      "Episode: 780/3000, Reward: -13419.261543307504, done: False\n",
      "state: [-0.54232479 62.5947794 ], action: [-0.27837422 -0.167     ]\n",
      "Episode: 781/3000, Reward: -13290.222143283165, done: False\n",
      "state: [-0.54227826 62.52127916], action: [-0.28935197 -0.167     ]\n",
      "Episode: 782/3000, Reward: -13387.785211494367, done: False\n",
      "state: [-0.54170933 62.48737033], action: [-0.152875 -0.167   ]\n",
      "Episode: 783/3000, Reward: -13308.074730635062, done: False\n",
      "state: [-0.54199671 62.44699648], action: [-0.24053863 -0.167     ]\n",
      "Episode: 784/3000, Reward: -13317.826076337635, done: False\n",
      "state: [-0.54184011 62.47041398], action: [-0.2093885 -0.167    ]\n",
      "Episode: 785/3000, Reward: -13314.843936907959, done: False\n",
      "state: [-0.54199959 62.42846058], action: [-0.3017389 -0.167    ]\n",
      "Episode: 786/3000, Reward: -13277.667207522216, done: False\n",
      "state: [-0.5412347 62.3903556], action: [-0.10653508 -0.167     ]\n",
      "Episode: 787/3000, Reward: -13355.868728828704, done: False\n",
      "state: [-0.54189278 62.19442187], action: [-0.25211945 -0.167     ]\n",
      "Episode: 788/3000, Reward: -13201.75056081437, done: False\n",
      "state: [-0.54157653 62.10811644], action: [-0.2484078 -0.167    ]\n",
      "Episode: 789/3000, Reward: -13166.005574952576, done: False\n",
      "state: [-0.54115877 62.04928261], action: [-0.18787336 -0.167     ]\n",
      "Episode: 790/3000, Reward: -13179.543482657496, done: False\n",
      "state: [-0.54166535 62.19474378], action: [-0.19307165 -0.167     ]\n",
      "Episode: 791/3000, Reward: -13141.86677773055, done: False\n",
      "state: [-0.541313   62.16120253], action: [-0.25779766 -0.167     ]\n",
      "Episode: 792/3000, Reward: -13134.353495790843, done: False\n",
      "state: [-0.5413516  62.03006125], action: [-0.23284698 -0.167     ]\n",
      "Episode: 793/3000, Reward: -13189.781597543368, done: False\n",
      "state: [-0.54110853 62.04096239], action: [-0.21405242 -0.167     ]\n",
      "Episode: 794/3000, Reward: -13138.247262633859, done: False\n",
      "state: [-0.54193973 62.09803624], action: [-0.2768533 -0.167    ]\n",
      "Episode: 795/3000, Reward: -13113.664701429387, done: False\n",
      "state: [-0.54090811 61.94522253], action: [-0.14980368 -0.167     ]\n",
      "Episode: 796/3000, Reward: -13121.055309797524, done: False\n",
      "state: [-0.54080734 61.78783121], action: [-0.21852499 -0.167     ]\n",
      "Episode: 797/3000, Reward: -13075.6984756182, done: False\n",
      "state: [-0.54156387 61.96518215], action: [-0.25194085 -0.167     ]\n",
      "Episode: 798/3000, Reward: -13141.237715076059, done: False\n",
      "state: [-0.54121552 61.87404091], action: [-0.25821784 -0.167     ]\n",
      "Episode: 799/3000, Reward: -13112.018938361092, done: False\n",
      "state: [-0.54102519 61.88368731], action: [-0.218416 -0.167   ]\n",
      "Episode: 800/3000, Reward: -13029.40535999147, done: False\n",
      "state: [-0.54131972 61.86943026], action: [-0.21064287 -0.167     ]\n",
      "Episode: 801/3000, Reward: -13023.960377499468, done: False\n",
      "state: [-0.5412263  61.78979716], action: [-0.22893229 -0.167     ]\n",
      "Episode: 802/3000, Reward: -13022.845943000642, done: False\n",
      "state: [-0.54092845 61.78050307], action: [-0.20714787 -0.167     ]\n",
      "Episode: 803/3000, Reward: -12945.974552104928, done: False\n",
      "state: [-0.54051827 61.66179566], action: [-0.16586483 -0.167     ]\n",
      "Episode: 804/3000, Reward: -13004.271190724974, done: False\n",
      "state: [-0.541054   61.73873797], action: [-0.23373432 -0.167     ]\n",
      "Episode: 805/3000, Reward: -12948.484766123822, done: False\n",
      "state: [-0.54060052 61.66245722], action: [-0.2547539 -0.167    ]\n",
      "Episode: 806/3000, Reward: -13061.697936217262, done: False\n",
      "state: [-0.54170808 61.78191797], action: [-0.27877536 -0.167     ]\n",
      "Episode: 807/3000, Reward: -12978.342592072113, done: False\n",
      "state: [-0.540935   61.68418636], action: [-0.249653 -0.167   ]\n",
      "Episode: 808/3000, Reward: -13008.573532348144, done: False\n",
      "state: [-0.54067098 61.61008656], action: [-0.2052778 -0.167    ]\n",
      "Episode: 809/3000, Reward: -12928.194424751473, done: False\n",
      "state: [-0.54089327 61.58999106], action: [-0.2516693 -0.167    ]\n",
      "Episode: 810/3000, Reward: -12877.557545493071, done: False\n",
      "state: [-0.5407044 61.6252423], action: [-0.22064535 -0.167     ]\n",
      "Episode: 811/3000, Reward: -12936.912280587414, done: False\n",
      "state: [-0.54031869 61.59681041], action: [-0.09212964 -0.167     ]\n",
      "Episode: 812/3000, Reward: -12892.853393945237, done: False\n",
      "state: [-0.54091594 61.55917544], action: [-0.25032532 -0.167     ]\n",
      "Episode: 813/3000, Reward: -12914.731594619278, done: False\n",
      "state: [-0.54081475 61.48028169], action: [-0.2793874 -0.167    ]\n",
      "Episode: 814/3000, Reward: -12844.285003949311, done: False\n",
      "state: [-0.54084813 61.47185439], action: [-0.3101202 -0.167    ]\n",
      "Episode: 815/3000, Reward: -12843.6333950712, done: False\n",
      "state: [-0.54079802 61.39064897], action: [-0.26284742 -0.167     ]\n",
      "Episode: 816/3000, Reward: -12831.387002092848, done: False\n",
      "state: [-0.54009664 61.25602872], action: [-0.20035443 -0.167     ]\n",
      "Episode: 817/3000, Reward: -12902.64494673453, done: False\n",
      "state: [-0.54023913 61.23056888], action: [-0.24757005 -0.167     ]\n",
      "Episode: 818/3000, Reward: -12797.43502799835, done: False\n",
      "state: [-0.54015175 61.17444759], action: [-0.23328708 -0.167     ]\n",
      "Episode: 819/3000, Reward: -12806.814190885725, done: False\n",
      "state: [-0.54032913 61.29947768], action: [-0.2658775 -0.167    ]\n",
      "Episode: 820/3000, Reward: -12799.682113770677, done: False\n",
      "state: [-0.54073128 61.39407046], action: [-0.24772045 -0.167     ]\n",
      "Episode: 821/3000, Reward: -12824.583402202852, done: False\n",
      "state: [-0.54039289 61.39077223], action: [-0.23182209 -0.167     ]\n",
      "Episode: 822/3000, Reward: -12816.533518111897, done: False\n",
      "state: [-0.54052733 61.22497676], action: [-0.28277424 -0.167     ]\n",
      "Episode: 823/3000, Reward: -12818.423333179146, done: False\n",
      "state: [-0.54050869 61.29686394], action: [-0.31540638 -0.167     ]\n",
      "Episode: 824/3000, Reward: -12756.243097408367, done: False\n",
      "state: [-0.54064593 61.21591486], action: [-0.23191594 -0.167     ]\n",
      "Episode: 825/3000, Reward: -12734.765407495095, done: False\n",
      "state: [-0.54073593 61.28654469], action: [-0.21440183 -0.167     ]\n",
      "Episode: 826/3000, Reward: -12731.375804413812, done: False\n",
      "state: [-0.54005962 61.09283153], action: [-0.23438334 -0.167     ]\n",
      "Episode: 827/3000, Reward: -12758.623520677686, done: False\n",
      "state: [-0.54015203 61.19401925], action: [-0.2116998 -0.167    ]\n",
      "Episode: 828/3000, Reward: -12745.033455433793, done: False\n",
      "state: [-0.53477664 61.02607283], action: [0.83754045 0.56416965]\n",
      "Episode: 829/3000, Reward: -12627.415350714979, done: False\n",
      "state: [-0.5406076  61.04149719], action: [-0.2643028 -0.167    ]\n",
      "Episode: 830/3000, Reward: -12690.16142581915, done: False\n",
      "state: [-0.54075988 61.08450209], action: [-0.28693137 -0.167     ]\n",
      "Episode: 831/3000, Reward: -12721.632423910436, done: False\n",
      "state: [-0.54011028 61.17691803], action: [-0.25194085 -0.167     ]\n",
      "Episode: 832/3000, Reward: -12731.647978335217, done: False\n",
      "state: [-0.54026536 60.9517403 ], action: [-0.3149185 -0.167    ]\n",
      "Episode: 833/3000, Reward: -12736.43973495841, done: False\n",
      "state: [-0.54078366 61.25572044], action: [-0.25498214 -0.167     ]\n",
      "Episode: 834/3000, Reward: -12752.850451590106, done: False\n",
      "state: [-0.54018324 61.12389074], action: [-0.16823068 -0.167     ]\n",
      "Episode: 835/3000, Reward: -12730.93716747496, done: False\n",
      "state: [-0.54027276 61.1342202 ], action: [-0.29837874 -0.167     ]\n",
      "Episode: 836/3000, Reward: -12715.576516998235, done: False\n",
      "state: [-0.54087934 61.24710406], action: [-0.29420993 -0.167     ]\n",
      "Episode: 837/3000, Reward: -12681.631064932311, done: False\n",
      "state: [-0.53985917 61.08981989], action: [-0.20160636 -0.167     ]\n",
      "Episode: 838/3000, Reward: -12708.40308416043, done: False\n",
      "state: [-0.53982784 61.01922943], action: [-0.21145931 -0.167     ]\n",
      "Episode: 839/3000, Reward: -12690.423151775087, done: False\n",
      "state: [-0.54017831 61.11669996], action: [-0.2640757 -0.167    ]\n",
      "Episode: 840/3000, Reward: -12738.691298093245, done: False\n",
      "state: [-0.54028818 61.04988933], action: [-0.25695702 -0.167     ]\n",
      "Episode: 841/3000, Reward: -12708.088130930528, done: False\n",
      "state: [-0.53995193 61.02075382], action: [-0.21370296 -0.167     ]\n",
      "Episode: 842/3000, Reward: -12733.899097571359, done: False\n",
      "state: [-0.54020145 61.1151516 ], action: [-0.24815008 -0.167     ]\n",
      "Episode: 843/3000, Reward: -12799.647704755256, done: False\n",
      "state: [-0.54010213 61.08093531], action: [-0.2741248 -0.167    ]\n",
      "Episode: 844/3000, Reward: -12726.687214359534, done: False\n",
      "state: [-0.53996165 61.04637314], action: [-0.20601578 -0.167     ]\n",
      "Episode: 845/3000, Reward: -12704.97850462509, done: False\n",
      "state: [-0.54027593 61.1014455 ], action: [-0.2806249 -0.167    ]\n",
      "Episode: 846/3000, Reward: -12742.680513121053, done: False\n",
      "state: [-0.54000497 61.04788085], action: [-0.22290139 -0.167     ]\n",
      "Episode: 847/3000, Reward: -12668.0245816379, done: False\n",
      "state: [-0.53961379 60.96731869], action: [-0.15502019 -0.167     ]\n",
      "Episode: 848/3000, Reward: -12648.362706902704, done: False\n",
      "state: [-0.539516   60.96473041], action: [-0.17427367 -0.167     ]\n",
      "Episode: 849/3000, Reward: -12712.718756305623, done: False\n",
      "state: [-0.54006318 61.00118954], action: [-0.22878046 -0.167     ]\n",
      "Episode: 850/3000, Reward: -12697.406595706541, done: False\n",
      "state: [-0.54014651 61.08810581], action: [-0.21718054 -0.167     ]\n",
      "Episode: 851/3000, Reward: -12708.008574788959, done: False\n",
      "state: [-0.53998007 61.01259872], action: [-0.2596414 -0.167    ]\n",
      "Episode: 852/3000, Reward: -12713.886809953628, done: False\n",
      "state: [-0.54024336 61.17054341], action: [-0.2610781 -0.167    ]\n",
      "Episode: 853/3000, Reward: -12723.494673220128, done: False\n",
      "state: [-0.53978953 61.00946763], action: [-0.21743496 -0.167     ]\n",
      "Episode: 854/3000, Reward: -12833.686814726392, done: False\n",
      "state: [-0.54003766 60.9300897 ], action: [-0.2634865 -0.167    ]\n",
      "Episode: 855/3000, Reward: -12706.522407089495, done: False\n",
      "state: [-0.54015859 61.15486122], action: [-0.18779977 -0.167     ]\n",
      "Episode: 856/3000, Reward: -12714.535710045808, done: False\n",
      "state: [-0.53999825 61.12345034], action: [-0.2339002 -0.167    ]\n",
      "Episode: 857/3000, Reward: -12696.818179487183, done: False\n",
      "state: [-0.54006304 61.14154752], action: [-0.24564974 -0.167     ]\n",
      "Episode: 858/3000, Reward: -12642.293874795427, done: False\n",
      "state: [-0.54010794 61.04217148], action: [-0.19769467 -0.167     ]\n",
      "Episode: 859/3000, Reward: -12656.542578638278, done: False\n",
      "state: [-0.54098014 61.16331461], action: [-0.25559554 -0.167     ]\n",
      "Episode: 860/3000, Reward: -12646.300364730192, done: False\n",
      "state: [-0.5399606  60.82577989], action: [-0.29278064 -0.167     ]\n",
      "Episode: 861/3000, Reward: -12588.67639799646, done: False\n",
      "state: [-0.53992912 60.92116022], action: [-0.23776932 -0.167     ]\n",
      "Episode: 862/3000, Reward: -12570.114467722478, done: False\n",
      "state: [-0.53961008 60.74457067], action: [-0.2511261 -0.167    ]\n",
      "Episode: 863/3000, Reward: -12516.021363878168, done: False\n",
      "state: [-0.54045542 60.72040992], action: [-0.41161734  0.11115004]\n",
      "Episode: 864/3000, Reward: -12584.271488405628, done: False\n",
      "state: [-0.53958611 60.76346072], action: [-0.23071721 -0.167     ]\n",
      "Episode: 865/3000, Reward: -12568.268528275581, done: False\n",
      "state: [-0.53944748 60.73698396], action: [-0.15388075 -0.167     ]\n",
      "Episode: 866/3000, Reward: -12594.968132809112, done: False\n",
      "state: [-0.54040415 60.84641075], action: [-0.24961722 -0.167     ]\n",
      "Episode: 867/3000, Reward: -12440.354336212555, done: False\n",
      "state: [-0.53955324 60.62998197], action: [-0.24443062 -0.167     ]\n",
      "Episode: 868/3000, Reward: -12504.11489761789, done: False\n",
      "state: [-0.53960363 60.7388271 ], action: [-0.24921656 -0.167     ]\n",
      "Episode: 869/3000, Reward: -12480.240440669499, done: False\n",
      "state: [-0.53941997 60.68658433], action: [-0.16113482 -0.167     ]\n",
      "Episode: 870/3000, Reward: -12447.607715133036, done: False\n",
      "state: [-0.53942398 60.62212785], action: [-0.18755686 -0.167     ]\n",
      "Episode: 871/3000, Reward: -12372.523200147782, done: False\n",
      "state: [-0.53912878 60.41579049], action: [-0.20380844 -0.167     ]\n",
      "Episode: 872/3000, Reward: -12394.617415216117, done: False\n",
      "state: [-0.53925093 60.37661937], action: [-0.3173631 -0.167    ]\n",
      "Episode: 873/3000, Reward: -12340.613257504141, done: False\n",
      "state: [-0.53886838 60.29044972], action: [-0.23470058 -0.167     ]\n",
      "Episode: 874/3000, Reward: -12356.174515322125, done: False\n",
      "state: [-0.53881714 60.27554001], action: [-0.1695574 -0.167    ]\n",
      "Episode: 875/3000, Reward: -12380.196276877432, done: False\n",
      "state: [-0.53939187 60.41670475], action: [-0.24616583 -0.167     ]\n",
      "Episode: 876/3000, Reward: -12342.187987090792, done: False\n",
      "state: [-0.53923583 60.31766662], action: [-0.26917833 -0.167     ]\n",
      "Episode: 877/3000, Reward: -12525.851373344618, done: False\n",
      "state: [-0.53875263 60.37124031], action: [-0.19066867 -0.167     ]\n",
      "Episode: 878/3000, Reward: -12310.021905872305, done: False\n",
      "state: [-0.53912785 60.38664558], action: [-0.22729054 -0.167     ]\n",
      "Episode: 879/3000, Reward: -12316.546705087698, done: False\n",
      "state: [-0.53878527 60.20367737], action: [-0.22251709 -0.167     ]\n",
      "Episode: 880/3000, Reward: -12336.064590603857, done: False\n",
      "state: [-0.53893609 60.33464887], action: [-0.22702281 -0.167     ]\n",
      "Episode: 881/3000, Reward: -12265.105248708773, done: False\n",
      "state: [-0.53950954 60.43381123], action: [-0.21795824 -0.167     ]\n",
      "Episode: 882/3000, Reward: -12201.334014729568, done: False\n",
      "state: [-0.53892125 60.12803222], action: [-0.30942357 -0.167     ]\n",
      "Episode: 883/3000, Reward: -12258.200144208597, done: False\n",
      "state: [-0.53882397 60.23798457], action: [-0.18232529 -0.167     ]\n",
      "Episode: 884/3000, Reward: -12328.96712912942, done: False\n",
      "state: [-0.53862978 60.25872037], action: [-0.18163188 -0.167     ]\n",
      "Episode: 885/3000, Reward: -12374.653290345821, done: False\n",
      "state: [-0.5387073  60.18631297], action: [-0.17424408 -0.167     ]\n",
      "Episode: 886/3000, Reward: -12191.011787940619, done: False\n",
      "state: [-0.5387634  60.16705301], action: [-0.23486638 -0.167     ]\n",
      "Episode: 887/3000, Reward: -12155.481278965473, done: False\n",
      "state: [-0.53917207 60.10260913], action: [-0.32973328 -0.167     ]\n",
      "Episode: 888/3000, Reward: -12148.36302583405, done: False\n",
      "state: [-0.53880467 60.16077651], action: [-0.27708575 -0.167     ]\n",
      "Episode: 889/3000, Reward: -12164.444805928963, done: False\n",
      "state: [-0.53904694 60.21107728], action: [-0.28903037 -0.167     ]\n",
      "Episode: 890/3000, Reward: -12132.571255994806, done: False\n",
      "state: [-0.53890584 60.11800369], action: [-0.2785783 -0.167    ]\n",
      "Episode: 891/3000, Reward: -12205.419858249248, done: False\n",
      "state: [-0.53856358 60.14344985], action: [-0.20457613 -0.167     ]\n",
      "Episode: 892/3000, Reward: -12044.421942455876, done: False\n",
      "state: [-0.53855949 59.94099516], action: [-0.22432199 -0.167     ]\n",
      "Episode: 893/3000, Reward: -12143.476977671662, done: False\n",
      "state: [-0.53872023 60.1259686 ], action: [-0.18816775 -0.167     ]\n",
      "Episode: 894/3000, Reward: -12080.097809123205, done: False\n",
      "state: [-0.53854366 60.03033083], action: [-0.21465656 -0.167     ]\n",
      "Episode: 895/3000, Reward: -12063.622478318091, done: False\n",
      "state: [-0.53845049 59.85430535], action: [-0.26303917 -0.167     ]\n",
      "Episode: 896/3000, Reward: -12066.042917729099, done: False\n",
      "state: [-0.53860867 59.92204808], action: [-0.24521238 -0.167     ]\n",
      "Episode: 897/3000, Reward: -12013.009228640614, done: False\n",
      "state: [-0.53824743 59.85671647], action: [-0.23320052 -0.167     ]\n",
      "Episode: 898/3000, Reward: -12004.420856943445, done: False\n",
      "state: [-0.53815909 59.87188842], action: [-0.21143743 -0.167     ]\n",
      "Episode: 899/3000, Reward: -11973.83443759443, done: False\n",
      "state: [-0.53821105 59.76564623], action: [-0.2384746 -0.167    ]\n",
      "Episode: 900/3000, Reward: -11966.648972512912, done: False\n",
      "state: [-0.53820982 59.73249973], action: [-0.249145 -0.167   ]\n",
      "Episode: 901/3000, Reward: -11921.33112061562, done: False\n",
      "state: [-0.53803814 59.65791662], action: [-0.27657852 -0.167     ]\n",
      "Episode: 902/3000, Reward: -11910.763189938756, done: False\n",
      "state: [-0.53811933 59.6625283 ], action: [-0.25376907 -0.167     ]\n",
      "Episode: 903/3000, Reward: -11934.291082254887, done: False\n",
      "state: [-0.5381316  59.68830317], action: [-0.23057275 -0.167     ]\n",
      "Episode: 904/3000, Reward: -11865.040092200432, done: False\n",
      "state: [-0.53778205 59.60580246], action: [-0.24121419 -0.167     ]\n",
      "Episode: 905/3000, Reward: -11900.286644275497, done: False\n",
      "state: [-0.53800164 59.65610721], action: [-0.21984683 -0.167     ]\n",
      "Episode: 906/3000, Reward: -11909.401988697475, done: False\n",
      "state: [-0.53761045 59.58323267], action: [-0.2026089 -0.167    ]\n",
      "Episode: 907/3000, Reward: -11814.594072527201, done: False\n",
      "state: [-0.53809982 59.65152414], action: [-0.22424228 -0.167     ]\n",
      "Episode: 908/3000, Reward: -12273.851300229626, done: False\n",
      "state: [-0.53804641 59.63835138], action: [-0.2518408 -0.167    ]\n",
      "Episode: 909/3000, Reward: -11819.240827128704, done: False\n",
      "state: [-0.53802932 59.55952317], action: [-0.2647711 -0.167    ]\n",
      "Episode: 910/3000, Reward: -11808.335289376475, done: False\n",
      "state: [-0.5377905 59.5411618], action: [-0.2086005 -0.167    ]\n",
      "Episode: 911/3000, Reward: -11837.447681901638, done: False\n",
      "state: [-0.53781751 59.50659388], action: [-0.26960996 -0.167     ]\n",
      "Episode: 912/3000, Reward: -12033.111055208607, done: False\n",
      "state: [-0.53802431 59.44742953], action: [-0.3052092 -0.167    ]\n",
      "Episode: 913/3000, Reward: -11790.442987978995, done: False\n",
      "state: [-0.53793416 59.50674537], action: [-0.2914687 -0.167    ]\n",
      "Episode: 914/3000, Reward: -11752.981909562139, done: False\n",
      "state: [-0.53760025 59.30164792], action: [-0.2297057 -0.167    ]\n",
      "Episode: 915/3000, Reward: -11691.933630238611, done: False\n",
      "state: [-0.53725625 59.2432168 ], action: [-0.13799153 -0.167     ]\n",
      "Episode: 916/3000, Reward: -11674.804086762535, done: False\n",
      "state: [-0.53840116 59.38712017], action: [-0.27699417 -0.167     ]\n",
      "Episode: 917/3000, Reward: -11807.477723898086, done: False\n",
      "state: [-0.53862074 59.50475881], action: [-0.3415735 -0.167    ]\n",
      "Episode: 918/3000, Reward: -11669.472455445128, done: False\n",
      "state: [-0.53766316 59.26045287], action: [-0.25325507 -0.167     ]\n",
      "Episode: 919/3000, Reward: -11677.223504643205, done: False\n",
      "state: [-0.53762088 59.21774045], action: [-0.26641625 -0.167     ]\n",
      "Episode: 920/3000, Reward: -11663.473718864288, done: False\n",
      "state: [-0.53730405 59.20589775], action: [-0.23758215 -0.167     ]\n",
      "Episode: 921/3000, Reward: -11540.601921813892, done: False\n",
      "state: [-0.53728414 59.05753975], action: [-0.2584955 -0.167    ]\n",
      "Episode: 922/3000, Reward: -11516.176737127458, done: False\n",
      "state: [-0.53748728 59.05095387], action: [-0.2728754 -0.167    ]\n",
      "Episode: 923/3000, Reward: -11594.425521046756, done: False\n",
      "state: [-0.53693445 58.98149032], action: [-0.24859391 -0.167     ]\n",
      "Episode: 924/3000, Reward: -11549.762712798542, done: False\n",
      "state: [-0.53715034 59.08200321], action: [-0.261931 -0.167   ]\n",
      "Episode: 925/3000, Reward: -11503.27569108652, done: False\n",
      "state: [-0.53726354 59.01079108], action: [-0.3057764 -0.167    ]\n",
      "Episode: 926/3000, Reward: -11501.045300360618, done: False\n",
      "state: [-0.53698116 58.934739  ], action: [-0.2576196 -0.167    ]\n",
      "Episode: 927/3000, Reward: -11424.529570144841, done: False\n",
      "state: [-0.53695719 58.89190481], action: [-0.23606263 -0.167     ]\n",
      "Episode: 928/3000, Reward: -11392.986928843866, done: False\n",
      "state: [-0.5368664  58.78398173], action: [-0.25703186 -0.167     ]\n",
      "Episode: 929/3000, Reward: -11375.476471962766, done: False\n",
      "state: [-0.53668442 58.65442055], action: [-0.2725011 -0.167    ]\n",
      "Episode: 930/3000, Reward: -11400.305097571389, done: False\n",
      "state: [-0.53648893 58.70641787], action: [-0.2353637 -0.167    ]\n",
      "Episode: 931/3000, Reward: -11370.713293090728, done: False\n",
      "state: [-0.53665815 58.648921  ], action: [-0.24422257 -0.167     ]\n",
      "Episode: 932/3000, Reward: -11290.81577897297, done: False\n",
      "state: [-0.53136679 58.67641101], action: [0.45193607 0.51589787]\n",
      "Episode: 933/3000, Reward: -11249.984491393428, done: False\n",
      "state: [-0.53652864 58.66160077], action: [-0.22071794 -0.167     ]\n",
      "Episode: 934/3000, Reward: -11257.169805717172, done: False\n",
      "state: [-0.53632205 58.5958266 ], action: [-0.2141143 -0.167    ]\n",
      "Episode: 935/3000, Reward: -11258.0784103408, done: False\n",
      "state: [-0.53637772 58.55852983], action: [-0.2531694 -0.167    ]\n",
      "Episode: 936/3000, Reward: -11183.387631092322, done: False\n",
      "state: [-0.5362436  58.36732829], action: [-0.2821459 -0.167    ]\n",
      "Episode: 937/3000, Reward: -11154.92809696236, done: False\n",
      "state: [-0.53622206 58.37731504], action: [-0.24843286 -0.167     ]\n",
      "Episode: 938/3000, Reward: -11222.000071554188, done: False\n",
      "state: [-0.53614641 58.37464133], action: [-0.25827837 -0.167     ]\n",
      "Episode: 939/3000, Reward: -11096.726146631714, done: False\n",
      "state: [-0.5362096  58.26715503], action: [-0.3149769 -0.167    ]\n",
      "Episode: 940/3000, Reward: -11096.232455283625, done: False\n",
      "state: [-0.53598285 58.29348229], action: [-0.27919748 -0.167     ]\n",
      "Episode: 941/3000, Reward: -11007.171005092592, done: False\n",
      "state: [-0.5358195  58.18760084], action: [-0.28148568 -0.167     ]\n",
      "Episode: 942/3000, Reward: -10985.701164886888, done: False\n",
      "state: [-0.53559718 58.03152073], action: [-0.22982857 -0.167     ]\n",
      "Episode: 943/3000, Reward: -10944.628862132211, done: False\n",
      "state: [-0.53558744 57.98371712], action: [-0.25875893 -0.167     ]\n",
      "Episode: 944/3000, Reward: -10952.372493336992, done: False\n",
      "state: [-0.53625302 58.19598375], action: [-0.22068527 -0.167     ]\n",
      "Episode: 945/3000, Reward: -10911.83904984251, done: False\n",
      "state: [-0.53545476 57.99443402], action: [-0.2321758 -0.167    ]\n",
      "Episode: 946/3000, Reward: -10926.57244188949, done: False\n",
      "state: [-0.53590521 58.09748273], action: [-0.27173108 -0.167     ]\n",
      "Episode: 947/3000, Reward: -10882.278551029367, done: False\n",
      "state: [-0.53537878 57.86565024], action: [-0.26259172 -0.167     ]\n",
      "Episode: 948/3000, Reward: -10898.039799004657, done: False\n",
      "state: [-0.53553002 58.03397147], action: [-0.22811158 -0.167     ]\n",
      "Episode: 949/3000, Reward: -10841.081907215419, done: False\n",
      "state: [-0.53523838 57.87582948], action: [-0.2604879 -0.167    ]\n",
      "Episode: 950/3000, Reward: -10820.048505483419, done: False\n",
      "state: [-0.53548686 57.91586859], action: [-0.24407908 -0.167     ]\n",
      "Episode: 951/3000, Reward: -10917.035301277718, done: False\n",
      "state: [-0.53549035 58.02168325], action: [-0.23378481 -0.167     ]\n",
      "Episode: 952/3000, Reward: -10883.65793770891, done: False\n",
      "state: [-0.53586243 58.1304765 ], action: [-0.23858252 -0.167     ]\n",
      "Episode: 953/3000, Reward: -10923.267161377447, done: False\n",
      "state: [-0.53583931 58.17575043], action: [-0.24701136 -0.167     ]\n",
      "Episode: 954/3000, Reward: -10895.73070264151, done: False\n",
      "state: [-0.53596858 58.15294827], action: [-0.2847104 -0.167    ]\n",
      "Episode: 955/3000, Reward: -10866.655317756075, done: False\n",
      "state: [-0.536453   58.17440341], action: [-0.06946009 -0.167     ]\n",
      "Episode: 956/3000, Reward: -10875.944807745367, done: False\n",
      "state: [-0.53494764 58.28187285], action: [-0.55029255 -0.167     ]\n",
      "Episode: 957/3000, Reward: -10876.877609490086, done: False\n",
      "state: [-0.53585737 58.12323993], action: [-0.27528864 -0.167     ]\n",
      "Episode: 958/3000, Reward: -10877.929305821855, done: False\n",
      "state: [-0.53593588 58.23711763], action: [-0.25809678 -0.167     ]\n",
      "Episode: 959/3000, Reward: -10895.211415100168, done: False\n",
      "state: [-0.53589272 58.12624316], action: [-0.24459918 -0.167     ]\n",
      "Episode: 960/3000, Reward: -10874.372644147857, done: False\n",
      "state: [-0.53599183 58.22636062], action: [-0.22880216 -0.167     ]\n",
      "Episode: 961/3000, Reward: -10898.428637797124, done: False\n",
      "state: [-0.53609495 58.22642402], action: [-0.22475667 -0.167     ]\n",
      "Episode: 962/3000, Reward: -10804.578773337807, done: False\n",
      "state: [-0.535373   58.02945311], action: [-0.12677062 -0.167     ]\n",
      "Episode: 963/3000, Reward: -10764.363009175071, done: False\n",
      "state: [-0.53579035 58.07609652], action: [-0.18496081 -0.167     ]\n",
      "Episode: 964/3000, Reward: -10779.701414743466, done: False\n",
      "state: [-0.53529444 58.0215101 ], action: [-0.17084645 -0.167     ]\n",
      "Episode: 965/3000, Reward: -10705.425809908802, done: False\n",
      "state: [-0.53531486 57.82644303], action: [-0.2294925 -0.167    ]\n",
      "Episode: 966/3000, Reward: -10646.117982096826, done: False\n",
      "state: [-0.53523531 57.70552978], action: [-0.27250817 -0.167     ]\n",
      "Episode: 967/3000, Reward: -10625.58621532983, done: False\n",
      "state: [-0.53521726 57.72932656], action: [-0.2746645 -0.167    ]\n",
      "Episode: 968/3000, Reward: -10614.910297173117, done: False\n",
      "state: [-0.53521337 57.73224834], action: [-0.27665955 -0.167     ]\n",
      "Episode: 969/3000, Reward: -10621.097482906636, done: False\n",
      "state: [-0.53502726 57.76812475], action: [-0.21926953 -0.167     ]\n",
      "Episode: 970/3000, Reward: -10601.00165922498, done: False\n",
      "state: [-0.53534489 57.79240304], action: [-0.23000199 -0.167     ]\n",
      "Episode: 971/3000, Reward: -10613.860533344157, done: False\n",
      "state: [-0.53480505 57.59481697], action: [-0.23582849 -0.167     ]\n",
      "Episode: 972/3000, Reward: -10584.013523092644, done: False\n",
      "state: [-0.5348269  57.63063543], action: [-0.19617297 -0.167     ]\n",
      "Episode: 973/3000, Reward: -10578.510738803772, done: False\n",
      "state: [-0.53500549 57.61480094], action: [-0.2778533 -0.167    ]\n",
      "Episode: 974/3000, Reward: -10574.44342396305, done: False\n",
      "state: [-0.53515041 57.74790635], action: [-0.26216903 -0.167     ]\n",
      "Episode: 975/3000, Reward: -10588.559543799829, done: False\n",
      "state: [-0.53512333 57.66814972], action: [-0.23958959 -0.167     ]\n",
      "Episode: 976/3000, Reward: -10580.770047635731, done: False\n",
      "state: [-0.53534788 57.80987722], action: [-0.21821621 -0.167     ]\n",
      "Episode: 977/3000, Reward: -10528.702034252177, done: False\n",
      "state: [-0.53500911 57.71947094], action: [-0.22034776 -0.167     ]\n",
      "Episode: 978/3000, Reward: -10614.516986980841, done: False\n",
      "state: [-0.53515432 57.7864361 ], action: [-0.27790964 -0.167     ]\n",
      "Episode: 979/3000, Reward: -10640.698072173478, done: False\n",
      "state: [-0.53558384 57.98667776], action: [-0.22929373 -0.167     ]\n",
      "Episode: 980/3000, Reward: -10669.820884153194, done: False\n",
      "state: [-0.53543263 58.03934841], action: [-0.20003219 -0.167     ]\n",
      "Episode: 981/3000, Reward: -10694.770442986464, done: False\n",
      "state: [-0.5358645 58.2084787], action: [-0.2583994 -0.167    ]\n",
      "Episode: 982/3000, Reward: -10786.692900115164, done: False\n",
      "state: [-0.53622706 58.22039359], action: [-0.24928094 -0.167     ]\n",
      "Episode: 983/3000, Reward: -10799.316939452825, done: False\n",
      "state: [-0.53633348 58.45186655], action: [-0.27311546 -0.167     ]\n",
      "Episode: 984/3000, Reward: -10770.691777877948, done: False\n",
      "state: [-0.53596626 58.37485479], action: [-0.25305158 -0.167     ]\n",
      "Episode: 985/3000, Reward: -10781.133173546095, done: False\n",
      "state: [-0.53637614 58.49990706], action: [-0.26589522 -0.167     ]\n",
      "Episode: 986/3000, Reward: -10831.941657816804, done: False\n",
      "state: [-0.53637388 58.60098675], action: [-0.25183722 -0.167     ]\n",
      "Episode: 987/3000, Reward: -10899.707903272229, done: False\n",
      "state: [-0.53681328 58.82867586], action: [-0.22627012 -0.167     ]\n",
      "Episode: 988/3000, Reward: -10963.943527050442, done: False\n",
      "state: [-0.53694628 58.92767021], action: [-0.2474877 -0.167    ]\n",
      "Episode: 989/3000, Reward: -10977.702213782633, done: False\n",
      "state: [-0.53677328 58.96229137], action: [-0.1614432 -0.167    ]\n",
      "Episode: 990/3000, Reward: -11035.7303264537, done: False\n",
      "state: [-0.53718427 59.20137782], action: [-0.16703686 -0.167     ]\n",
      "Episode: 991/3000, Reward: -11054.558125252357, done: False\n",
      "state: [-0.53777848 59.29731025], action: [-0.24383512 -0.167     ]\n",
      "Episode: 992/3000, Reward: -11151.684697829114, done: False\n",
      "state: [-0.53747263 59.25832799], action: [-0.30271983 -0.167     ]\n",
      "Episode: 993/3000, Reward: -11141.238802492668, done: False\n",
      "state: [-0.53798601 59.46985656], action: [-0.2536299 -0.167    ]\n",
      "Episode: 994/3000, Reward: -11171.281867323205, done: False\n",
      "state: [-0.53801095 59.59191354], action: [-0.26779076 -0.167     ]\n",
      "Episode: 995/3000, Reward: -11229.979366680156, done: False\n",
      "state: [-0.53872176 59.77721035], action: [-0.26077947 -0.167     ]\n",
      "Episode: 996/3000, Reward: -11227.003328771254, done: False\n",
      "state: [-0.53808759 59.69528822], action: [-0.21476936 -0.167     ]\n",
      "Episode: 997/3000, Reward: -11215.583481946098, done: False\n",
      "state: [-0.53866291 59.85796003], action: [-0.25319082 -0.167     ]\n",
      "Episode: 998/3000, Reward: -11240.049537025261, done: False\n",
      "state: [-0.53848855 59.90464835], action: [-0.26532438 -0.167     ]\n",
      "Episode: 999/3000, Reward: -11242.184418444782, done: False\n",
      "state: [-0.53846789 59.99129322], action: [-0.21377577 -0.167     ]\n",
      "Episode: 1000/3000, Reward: -11240.61439636364, done: False\n",
      "state: [-0.53838361 59.97364667], action: [-0.22430025 -0.167     ]\n",
      "Episode: 1001/3000, Reward: -11251.371474634992, done: False\n",
      "state: [-0.5382628  59.93813632], action: [-0.19932531 -0.167     ]\n",
      "Episode: 1002/3000, Reward: -11287.797133755294, done: False\n",
      "state: [-0.53875428 60.11492429], action: [-0.24203674 -0.167     ]\n",
      "Episode: 1003/3000, Reward: -11235.458017624913, done: False\n",
      "state: [-0.53863405 60.00728162], action: [-0.24071832 -0.167     ]\n",
      "Episode: 1004/3000, Reward: -11286.867753182778, done: False\n",
      "state: [-0.53869687 60.19190567], action: [-0.22797416 -0.167     ]\n",
      "Episode: 1005/3000, Reward: -11290.792702244904, done: False\n",
      "state: [-0.53863585 60.13645642], action: [-0.1931855 -0.167    ]\n",
      "Episode: 1006/3000, Reward: -11286.990359645759, done: False\n",
      "state: [-0.54111869 60.17930343], action: [-0.7234331   0.12026409]\n",
      "Episode: 1007/3000, Reward: -11252.018062475083, done: False\n",
      "state: [-0.53889286 60.14692915], action: [-0.28114495 -0.167     ]\n",
      "Episode: 1008/3000, Reward: -11262.27547466018, done: False\n",
      "state: [-0.53937835 60.30142567], action: [-0.18068735 -0.167     ]\n",
      "Episode: 1009/3000, Reward: -11231.227292224215, done: False\n",
      "state: [-0.53841917 60.10968459], action: [-0.20845456 -0.167     ]\n",
      "Episode: 1010/3000, Reward: -11236.124451201813, done: False\n",
      "state: [-0.53884056 60.24497843], action: [-0.2103658 -0.167    ]\n",
      "Episode: 1011/3000, Reward: -11237.09645038057, done: False\n",
      "state: [-0.53878224 60.25151509], action: [-0.231573 -0.167   ]\n",
      "Episode: 1012/3000, Reward: -11224.705707840702, done: False\n",
      "state: [-0.53914304 60.2352178 ], action: [-0.25101888 -0.167     ]\n",
      "Episode: 1013/3000, Reward: -11246.485686058546, done: False\n",
      "state: [-0.53896135 60.32861028], action: [-0.27742732 -0.167     ]\n",
      "Episode: 1014/3000, Reward: -11234.10289944397, done: False\n",
      "state: [-0.53953564 60.43137368], action: [-0.23282893 -0.167     ]\n",
      "Episode: 1015/3000, Reward: -11224.054094230958, done: False\n",
      "state: [-0.53891296 60.27480158], action: [-0.23169574 -0.167     ]\n",
      "Episode: 1016/3000, Reward: -11209.963772665738, done: False\n",
      "state: [-0.53896518 60.32017447], action: [-0.19017604 -0.167     ]\n",
      "Episode: 1017/3000, Reward: -11283.179230469386, done: False\n",
      "state: [-0.53959458 60.61272292], action: [-0.22992973 -0.167     ]\n",
      "Episode: 1018/3000, Reward: -11272.734831880607, done: False\n",
      "state: [-0.5390878 60.5739355], action: [-0.2232059 -0.167    ]\n",
      "Episode: 1019/3000, Reward: -11331.272681333727, done: False\n",
      "state: [-0.53962166 60.74954464], action: [-0.22888891 -0.167     ]\n",
      "Episode: 1020/3000, Reward: -11376.56047737655, done: False\n",
      "state: [-0.53999193 60.92649266], action: [-0.22535059 -0.167     ]\n",
      "Episode: 1021/3000, Reward: -11422.446559458618, done: False\n",
      "state: [-0.54009905 61.1093516 ], action: [-0.2090529 -0.167    ]\n",
      "Episode: 1022/3000, Reward: -11490.313769199525, done: False\n",
      "state: [-0.54034085 61.2607938 ], action: [-0.25493222 -0.167     ]\n",
      "Episode: 1023/3000, Reward: -11547.522909183157, done: False\n",
      "state: [-0.54054977 61.49521663], action: [-0.22138554 -0.167     ]\n",
      "Episode: 1024/3000, Reward: -11645.58914388086, done: False\n",
      "state: [-0.540897   61.74557684], action: [-0.20126966 -0.167     ]\n",
      "Episode: 1025/3000, Reward: -11748.017133903373, done: False\n",
      "state: [-0.54149064 62.0985506 ], action: [-0.20833778 -0.167     ]\n",
      "Episode: 1026/3000, Reward: -11747.08021497546, done: False\n",
      "state: [-0.541424   62.14449739], action: [-0.20916964 -0.167     ]\n",
      "Episode: 1027/3000, Reward: -11787.384624658373, done: False\n",
      "state: [-0.54190431 62.39116081], action: [-0.25896534 -0.167     ]\n",
      "Episode: 1028/3000, Reward: -11897.551461777004, done: False\n",
      "state: [-0.54214867 62.57292258], action: [-0.22916363 -0.167     ]\n",
      "Episode: 1029/3000, Reward: -11912.333138098524, done: False\n",
      "state: [-0.54201878 62.58405704], action: [-0.22350308 -0.167     ]\n",
      "Episode: 1030/3000, Reward: -11964.84322696834, done: False\n",
      "state: [-0.54229737 62.76585154], action: [-0.21803817 -0.167     ]\n",
      "Episode: 1031/3000, Reward: -11967.6507032007, done: False\n",
      "state: [-0.54255387 62.89314681], action: [-0.23470779 -0.167     ]\n",
      "Episode: 1032/3000, Reward: -12022.39870523059, done: False\n",
      "state: [-0.54262269 63.01981285], action: [-0.20843996 -0.167     ]\n",
      "Episode: 1033/3000, Reward: -12059.585082376245, done: False\n",
      "state: [-0.54344769 63.3604183 ], action: [-0.2866933 -0.167    ]\n",
      "Episode: 1034/3000, Reward: -12140.47080761974, done: False\n",
      "state: [-0.54315776 63.39037852], action: [-0.23971184 -0.167     ]\n",
      "Episode: 1035/3000, Reward: -12101.798082742062, done: False\n",
      "state: [-0.54299977 63.32013201], action: [-0.25431862 -0.167     ]\n",
      "Episode: 1036/3000, Reward: -12130.36179411381, done: False\n",
      "state: [-0.54298905 63.41777338], action: [-0.20965838 -0.167     ]\n",
      "Episode: 1037/3000, Reward: -12209.633110145505, done: False\n",
      "state: [-0.54364253 63.72158415], action: [-0.25605896 -0.167     ]\n",
      "Episode: 1038/3000, Reward: -12228.737164071921, done: False\n",
      "state: [-0.53902385 63.79847258], action: [0.6803579 0.3753622]\n",
      "Episode: 1039/3000, Reward: -12238.441908349874, done: False\n",
      "state: [-0.54389072 63.99161852], action: [-0.24552785 -0.167     ]\n",
      "Episode: 1040/3000, Reward: -12344.404346259487, done: False\n",
      "state: [-0.5439324  64.08866331], action: [-0.23285419 -0.167     ]\n",
      "Episode: 1041/3000, Reward: -12332.085019111859, done: False\n",
      "state: [-0.54414611 64.30880207], action: [-0.21206415 -0.167     ]\n",
      "Episode: 1042/3000, Reward: -12409.71720362335, done: False\n",
      "state: [-0.54441403 64.46304628], action: [-0.23873362 -0.167     ]\n",
      "Episode: 1043/3000, Reward: -12423.91656426926, done: False\n",
      "state: [-0.54474802 64.51534886], action: [-0.23564474 -0.167     ]\n",
      "Episode: 1044/3000, Reward: -12435.65719515152, done: False\n",
      "state: [-0.54478588 64.65782733], action: [-0.23174267 -0.167     ]\n",
      "Episode: 1045/3000, Reward: -12462.901705128832, done: False\n",
      "state: [-0.54461434 64.66257559], action: [-0.22260411 -0.167     ]\n",
      "Episode: 1046/3000, Reward: -12426.159189778708, done: False\n",
      "state: [-0.54473784 64.53960135], action: [-0.28885555 -0.167     ]\n",
      "Episode: 1047/3000, Reward: -12454.87685877694, done: False\n",
      "state: [-0.54468892 64.71411731], action: [-0.22399591 -0.167     ]\n",
      "Episode: 1048/3000, Reward: -12430.903660048747, done: False\n",
      "state: [-0.5453485  64.87591877], action: [-0.22839001 -0.167     ]\n",
      "Episode: 1049/3000, Reward: -12341.46255775095, done: False\n",
      "state: [-0.54588664 64.57900952], action: [ 0.12600549 -0.167     ]\n",
      "Episode: 1050/3000, Reward: -12390.06039298223, done: False\n",
      "state: [-0.54452619 64.60319562], action: [-0.2252999 -0.167    ]\n",
      "Episode: 1051/3000, Reward: -12397.506699158714, done: False\n",
      "state: [-0.54446945 64.72893983], action: [-0.20058145 -0.167     ]\n",
      "Episode: 1052/3000, Reward: -12422.52874699073, done: False\n",
      "state: [-0.54485159 64.74375609], action: [-0.26340133 -0.167     ]\n",
      "Episode: 1053/3000, Reward: -12347.313232962935, done: False\n",
      "state: [-0.54784271 64.76406082], action: [-0.809159    0.71502185]\n",
      "Episode: 1054/3000, Reward: -12343.621808140733, done: False\n",
      "state: [-0.54481827 64.83633736], action: [-0.2271603 -0.167    ]\n",
      "Episode: 1055/3000, Reward: -12397.917617826071, done: False\n",
      "state: [-0.54490973 64.93323934], action: [-0.2678191 -0.167    ]\n",
      "Episode: 1056/3000, Reward: -12375.494300190025, done: False\n",
      "state: [-0.54491292 64.98999582], action: [-0.25065428 -0.167     ]\n",
      "Episode: 1057/3000, Reward: -12388.026953439292, done: False\n",
      "state: [-0.54490899 65.02961459], action: [-0.19831774 -0.167     ]\n",
      "Episode: 1058/3000, Reward: -12388.182797194002, done: False\n",
      "state: [-0.54764978 65.01735398], action: [-0.75604415 -0.5197344 ]\n",
      "Episode: 1059/3000, Reward: -12413.463350417112, done: False\n",
      "state: [-0.54515482 65.20411681], action: [-0.21085429 -0.167     ]\n",
      "Episode: 1060/3000, Reward: -12358.123329662665, done: False\n",
      "state: [-0.54494565 65.06478512], action: [-0.16998714 -0.167     ]\n",
      "Episode: 1061/3000, Reward: -12331.258524138262, done: False\n",
      "state: [-0.54540005 65.25177342], action: [-0.20597924 -0.167     ]\n",
      "Episode: 1062/3000, Reward: -12408.129504394663, done: False\n",
      "state: [-0.54527135 65.22572885], action: [-0.21556611 -0.167     ]\n",
      "Episode: 1063/3000, Reward: -12391.427904983053, done: False\n",
      "state: [-0.54524873 65.30703602], action: [-0.214511 -0.167   ]\n",
      "Episode: 1064/3000, Reward: -12364.78388017865, done: False\n",
      "state: [-0.54582643 65.3578606 ], action: [-0.28225473 -0.167     ]\n",
      "Episode: 1065/3000, Reward: -12324.398074618766, done: False\n",
      "state: [-0.54609727 65.39363804], action: [-0.2073012 -0.167    ]\n",
      "Episode: 1066/3000, Reward: -12214.404686005175, done: False\n",
      "state: [-0.54509098 64.90847484], action: [-0.24436605 -0.167     ]\n",
      "Episode: 1067/3000, Reward: -12130.11933492774, done: False\n",
      "state: [-0.54414594 65.02711732], action: [-0.5349276 -0.167    ]\n",
      "Episode: 1068/3000, Reward: -12095.865198338337, done: False\n",
      "state: [-0.54464325 64.71328038], action: [-0.21714419 -0.167     ]\n",
      "Episode: 1069/3000, Reward: -12034.992467715314, done: False\n",
      "state: [-0.54447829 64.51242245], action: [-0.24599381 -0.167     ]\n",
      "Episode: 1070/3000, Reward: -11985.69966767435, done: False\n",
      "state: [-0.54447178 64.45826477], action: [-0.20110127 -0.167     ]\n",
      "Episode: 1071/3000, Reward: -11950.87020027512, done: False\n",
      "state: [-0.54436518 64.40928852], action: [-0.22035502 -0.167     ]\n",
      "Episode: 1072/3000, Reward: -11888.773916593396, done: False\n",
      "state: [-0.54418643 64.27791577], action: [-0.24790664 -0.167     ]\n",
      "Episode: 1073/3000, Reward: -11836.889524761085, done: False\n",
      "state: [-0.54420481 64.17875412], action: [-0.2593141 -0.167    ]\n",
      "Episode: 1074/3000, Reward: -11775.332345199264, done: False\n",
      "state: [-0.54408694 64.04416102], action: [-0.23508263 -0.167     ]\n",
      "Episode: 1075/3000, Reward: -11704.639542944427, done: False\n",
      "state: [-0.54361997 63.87391717], action: [-0.23425356 -0.167     ]\n",
      "Episode: 1076/3000, Reward: -11642.894838858623, done: False\n",
      "state: [-0.54341506 63.72201152], action: [-0.16333368 -0.167     ]\n",
      "Episode: 1077/3000, Reward: -11548.256474067159, done: False\n",
      "state: [-0.54324562 63.62297245], action: [-0.21701273 -0.3393061 ]\n",
      "Episode: 1078/3000, Reward: -11452.434804081317, done: False\n",
      "state: [-0.54322797 63.49128476], action: [-0.23794925 -0.167     ]\n",
      "Episode: 1079/3000, Reward: -11489.787890644742, done: False\n",
      "state: [-0.5430782  63.40904312], action: [-0.1761003 -0.167    ]\n",
      "Episode: 1080/3000, Reward: -11396.548314650103, done: False\n",
      "state: [-0.54277272 63.22538369], action: [-0.1796613 -0.167    ]\n",
      "Episode: 1081/3000, Reward: -11388.658814198128, done: False\n",
      "state: [-0.54287819 63.18965803], action: [-0.22627012 -0.167     ]\n",
      "Episode: 1082/3000, Reward: -11325.625799812691, done: False\n",
      "state: [-0.5427804 63.1195013], action: [-0.23111446 -0.167     ]\n",
      "Episode: 1083/3000, Reward: -11286.81197828284, done: False\n",
      "state: [-0.54261547 63.03481795], action: [-0.21174352 -0.167     ]\n",
      "Episode: 1084/3000, Reward: -11255.30962494808, done: False\n",
      "state: [-0.54251918 62.95620099], action: [-0.18483922 -0.167     ]\n",
      "Episode: 1085/3000, Reward: -11180.875822853795, done: False\n",
      "state: [-0.5425654  62.94015183], action: [-0.22452486 -0.167     ]\n",
      "Episode: 1086/3000, Reward: -11180.873135604095, done: False\n",
      "state: [-0.54230833 62.75925908], action: [-0.24501875 -0.167     ]\n",
      "Episode: 1087/3000, Reward: -11132.73065244322, done: False\n",
      "state: [-0.54231229 62.6577495 ], action: [-0.23022598 -0.167     ]\n",
      "Episode: 1088/3000, Reward: -11056.344628100422, done: False\n",
      "state: [-0.54269232 62.80448517], action: [-0.20543125 -0.167     ]\n",
      "Episode: 1089/3000, Reward: -11035.01487577027, done: False\n",
      "state: [-0.54205906 62.54958899], action: [-0.27435058 -0.167     ]\n",
      "Episode: 1090/3000, Reward: -10997.98765742598, done: False\n",
      "state: [-0.54160452 62.43027356], action: [-0.18288578 -0.167     ]\n",
      "Episode: 1091/3000, Reward: -10976.407897465142, done: False\n",
      "state: [-0.54230948 62.42334733], action: [-0.29710633 -0.167     ]\n",
      "Episode: 1092/3000, Reward: -10912.68989638979, done: False\n",
      "state: [-0.54171637 62.42670957], action: [-0.17434025 -0.167     ]\n",
      "Episode: 1093/3000, Reward: -10869.166264417852, done: False\n",
      "state: [-0.54146774 62.19599783], action: [-0.20656364 -0.167     ]\n",
      "Episode: 1094/3000, Reward: -10812.362630040134, done: False\n",
      "state: [-0.5416136  62.20587887], action: [-0.24352653 -0.167     ]\n",
      "Episode: 1095/3000, Reward: -10741.249400373654, done: False\n",
      "state: [-0.54142684 62.02914928], action: [-0.24290922 -0.167     ]\n",
      "Episode: 1096/3000, Reward: -10748.388665800136, done: False\n",
      "state: [-0.54120238 61.95934934], action: [-0.25864503 -0.167     ]\n",
      "Episode: 1097/3000, Reward: -10711.189597874212, done: False\n",
      "state: [-0.54125003 62.04980877], action: [-0.21061371 -0.167     ]\n",
      "Episode: 1098/3000, Reward: -10646.499811703497, done: False\n",
      "state: [-0.54099991 61.77389168], action: [-0.23360449 -0.167     ]\n",
      "Episode: 1099/3000, Reward: -10597.982390247738, done: False\n",
      "state: [-0.54068702 61.68911686], action: [-0.24228452 -0.167     ]\n",
      "Episode: 1100/3000, Reward: -10516.125503553483, done: False\n",
      "state: [-0.5408178  61.60769201], action: [-0.21537696 -0.167     ]\n",
      "Episode: 1101/3000, Reward: -10462.272703984132, done: False\n",
      "state: [-0.54047116 61.37012499], action: [-0.28255662 -0.167     ]\n",
      "Episode: 1102/3000, Reward: -10439.992561563353, done: False\n",
      "state: [-0.54025937 61.28034167], action: [-0.20323801 -0.167     ]\n",
      "Episode: 1103/3000, Reward: -10346.643574108279, done: False\n",
      "state: [-0.5401992  61.13495471], action: [-0.22205657 -0.167     ]\n",
      "Episode: 1104/3000, Reward: -10325.174456274633, done: False\n",
      "state: [-0.54011575 61.24372712], action: [-0.20602308 -0.167     ]\n",
      "Episode: 1105/3000, Reward: -10251.246057440198, done: False\n",
      "state: [-0.54012797 61.06470514], action: [-0.25282663 -0.167     ]\n",
      "Episode: 1106/3000, Reward: -10199.630773737517, done: False\n",
      "state: [-0.53968046 60.82650656], action: [-0.20316121 -0.167     ]\n",
      "Episode: 1107/3000, Reward: -10147.259942926392, done: False\n",
      "state: [-0.54008535 60.83121128], action: [-0.28737587 -0.167     ]\n",
      "Episode: 1108/3000, Reward: -10122.029517693512, done: False\n",
      "state: [-0.53972586 60.7231719 ], action: [-0.22996587 -0.167     ]\n",
      "Episode: 1109/3000, Reward: -10043.904482031103, done: False\n",
      "state: [-0.53944109 60.46836862], action: [-0.28829253 -0.167     ]\n",
      "Episode: 1110/3000, Reward: -9932.126634044373, done: False\n",
      "state: [-0.53920862 60.31198174], action: [-0.2959999 -0.167    ]\n",
      "Episode: 1111/3000, Reward: -9939.826831502924, done: False\n",
      "state: [-0.53918018 60.31884929], action: [-0.23886672 -0.167     ]\n",
      "Episode: 1112/3000, Reward: -9848.756225484432, done: False\n",
      "state: [-0.53920105 60.10067647], action: [-0.10383398 -0.167     ]\n",
      "Episode: 1113/3000, Reward: -9779.771697452217, done: False\n",
      "state: [-0.53872962 60.02324122], action: [-0.24397145 -0.167     ]\n",
      "Episode: 1114/3000, Reward: -9739.88222253207, done: False\n",
      "state: [-0.53676378 60.11050815], action: [-0.57432526 -0.167     ]\n",
      "Episode: 1115/3000, Reward: -9721.378115585716, done: False\n",
      "state: [-0.5383985 59.8579366], action: [-0.19903958 -0.167     ]\n",
      "Episode: 1116/3000, Reward: -9634.38648150038, done: False\n",
      "state: [-0.53819811 59.74537546], action: [-0.25048265 -0.167     ]\n",
      "Episode: 1117/3000, Reward: -9606.505094168062, done: False\n",
      "state: [-0.53802554 59.61615405], action: [-0.30011526 -0.167     ]\n",
      "Episode: 1118/3000, Reward: -9556.970987073226, done: False\n",
      "state: [-0.53827685 59.50978726], action: [-0.24814649 -0.167     ]\n",
      "Episode: 1119/3000, Reward: -9485.355399337339, done: False\n",
      "state: [-0.53775242 59.42375513], action: [-0.26223296 -0.167     ]\n",
      "Episode: 1120/3000, Reward: -9458.863190620588, done: False\n",
      "state: [-0.53773203 59.34160356], action: [-0.25125477 -0.167     ]\n",
      "Episode: 1121/3000, Reward: -9368.50835892599, done: False\n",
      "state: [-0.53752858 59.21511687], action: [-0.29381263 -0.167     ]\n",
      "Episode: 1122/3000, Reward: -9308.732628805556, done: False\n",
      "state: [-0.53757649 59.1211447 ], action: [-0.26808465 -0.167     ]\n",
      "Episode: 1123/3000, Reward: -9265.554541051892, done: False\n",
      "state: [-0.53694998 58.90674662], action: [-0.22409736 -0.167     ]\n",
      "Episode: 1124/3000, Reward: -9234.647742785663, done: False\n",
      "state: [-0.53696387 58.916536  ], action: [-0.22321314 -0.167     ]\n",
      "Episode: 1125/3000, Reward: -9133.269060210534, done: False\n",
      "state: [-0.53662345 58.66897321], action: [-0.23827311 -0.167     ]\n",
      "Episode: 1126/3000, Reward: -9111.132014616098, done: False\n",
      "state: [-0.53658485 58.61760965], action: [-0.26778015 -0.167     ]\n",
      "Episode: 1127/3000, Reward: -9061.544453837256, done: False\n",
      "state: [-0.53629572 58.4593368 ], action: [-0.24414365 -0.167     ]\n",
      "Episode: 1128/3000, Reward: -9015.944493034744, done: False\n",
      "state: [-0.5362279  58.41929242], action: [-0.25201586 -0.167     ]\n",
      "Episode: 1129/3000, Reward: -8953.90856558669, done: False\n",
      "state: [-0.5358131  58.18965173], action: [-0.24643816 -0.167     ]\n",
      "Episode: 1130/3000, Reward: -8904.175254198444, done: False\n",
      "state: [-0.5358529  58.10285032], action: [-0.2881701 -0.167    ]\n",
      "Episode: 1131/3000, Reward: -8843.550945134286, done: False\n",
      "state: [-0.53545096 58.00626382], action: [-0.2440432 -0.167    ]\n",
      "Episode: 1132/3000, Reward: -8798.30250655456, done: False\n",
      "state: [-0.5354905  57.87570123], action: [-0.27483377 -0.167     ]\n",
      "Episode: 1133/3000, Reward: -8742.753713045851, done: False\n",
      "state: [-0.53519416 57.76980973], action: [-0.2514835 -0.167    ]\n",
      "Episode: 1134/3000, Reward: -8684.891587320573, done: False\n",
      "state: [-0.53495716 57.64261812], action: [-0.2755883 -0.167    ]\n",
      "Episode: 1135/3000, Reward: -8638.803265168386, done: False\n",
      "state: [-0.53517047 57.58883505], action: [-0.30372092 -0.167     ]\n",
      "Episode: 1136/3000, Reward: -8590.089589075353, done: False\n",
      "state: [-0.53475581 57.52689796], action: [-0.24711882 -0.167     ]\n",
      "Episode: 1137/3000, Reward: -8510.098290349462, done: False\n",
      "state: [-0.534465   57.28379227], action: [-0.2690368 -0.167    ]\n",
      "Episode: 1138/3000, Reward: -8491.235442376126, done: False\n",
      "state: [-0.53402572 57.20047727], action: [-0.18224783 -0.167     ]\n",
      "Episode: 1139/3000, Reward: -8430.087835780248, done: False\n",
      "state: [-0.53426881 57.15296396], action: [-0.21180183 -0.167     ]\n",
      "Episode: 1140/3000, Reward: -8398.932533428591, done: False\n",
      "state: [-0.53431555 57.12625612], action: [-0.29976812 -0.167     ]\n",
      "Episode: 1141/3000, Reward: -8329.240500295742, done: False\n",
      "state: [-0.53399328 56.93259707], action: [-0.29483005 -0.167     ]\n",
      "Episode: 1142/3000, Reward: -8297.300311926952, done: False\n",
      "state: [-0.53373439 56.82134099], action: [-0.28459123 -0.167     ]\n",
      "Episode: 1143/3000, Reward: -8257.862223627484, done: False\n",
      "state: [-0.53391462 56.79491958], action: [-0.2833778 -0.167    ]\n",
      "Episode: 1144/3000, Reward: -8190.385371706204, done: False\n",
      "state: [-0.53311483 56.55136879], action: [-0.22205293 -0.167     ]\n",
      "Episode: 1145/3000, Reward: -8097.982203046143, done: False\n",
      "state: [-0.53364674 56.52110089], action: [-0.28678432 -0.167     ]\n",
      "Episode: 1146/3000, Reward: -8061.154040092323, done: False\n",
      "state: [-0.53286195 56.33050543], action: [-0.2575163 -0.167    ]\n",
      "Episode: 1147/3000, Reward: -8020.293759445841, done: False\n",
      "state: [-0.532726   56.25431617], action: [-0.26301077 -0.167     ]\n",
      "Episode: 1148/3000, Reward: -7958.893850792824, done: False\n",
      "state: [-0.53279867 56.19281142], action: [-0.30672014 -0.167     ]\n",
      "Episode: 1149/3000, Reward: -7907.466896892797, done: False\n",
      "state: [-0.53233654 55.97485141], action: [-0.25631917 -0.167     ]\n",
      "Episode: 1150/3000, Reward: -7871.51448058334, done: False\n",
      "state: [-0.53250016 56.02446766], action: [-0.31303412 -0.167     ]\n",
      "Episode: 1151/3000, Reward: -7838.918456319361, done: False\n",
      "state: [-0.53239261 56.01254876], action: [-0.256116 -0.167   ]\n",
      "Episode: 1152/3000, Reward: -7778.809148767533, done: False\n",
      "state: [-0.53196012 55.85828258], action: [-0.24303485 -0.167     ]\n",
      "Episode: 1153/3000, Reward: -7761.040151599583, done: False\n",
      "state: [-0.53176565 55.69923013], action: [-0.251001 -0.167   ]\n",
      "Episode: 1154/3000, Reward: -7709.832210435426, done: False\n",
      "state: [-0.53158771 55.60682792], action: [-0.23910052 -0.167     ]\n",
      "Episode: 1155/3000, Reward: -7645.740387706308, done: False\n",
      "state: [-0.53158799 55.58819407], action: [-0.25793654 -0.167     ]\n",
      "Episode: 1156/3000, Reward: -7586.281525900314, done: False\n",
      "state: [-0.53108669 55.35059841], action: [-0.244488 -0.167   ]\n",
      "Episode: 1157/3000, Reward: -7550.78879809033, done: False\n",
      "state: [-0.53126341 55.34296653], action: [-0.3167901 -0.167    ]\n",
      "Episode: 1158/3000, Reward: -7513.773786227616, done: False\n",
      "state: [-0.53075014 55.22107542], action: [-0.22488706 -0.167     ]\n",
      "Episode: 1159/3000, Reward: -7455.500757756981, done: False\n",
      "state: [-0.53090964 55.1628119 ], action: [-0.24118185 -0.167     ]\n",
      "Episode: 1160/3000, Reward: -7421.994258702172, done: False\n",
      "state: [-0.53057911 55.08860851], action: [-0.23123 -0.167  ]\n",
      "Episode: 1161/3000, Reward: -7359.6017690762965, done: False\n",
      "state: [-0.53036108 54.92977165], action: [-0.18101576 -0.167     ]\n",
      "Episode: 1162/3000, Reward: -7267.6907774425035, done: False\n",
      "state: [-0.5301818  54.76827406], action: [-0.26639855 -0.167     ]\n",
      "Episode: 1163/3000, Reward: -7192.442444047853, done: False\n",
      "state: [-0.52930085 54.52281462], action: [-0.22905158 -0.167     ]\n",
      "Episode: 1164/3000, Reward: -7159.326171005614, done: False\n",
      "state: [-0.52929981 54.43361303], action: [-0.23489161 -0.167     ]\n",
      "Episode: 1165/3000, Reward: -7095.438055187449, done: False\n",
      "state: [-0.5292426  54.36643635], action: [-0.25870198 -0.167     ]\n",
      "Episode: 1166/3000, Reward: -7004.721212464113, done: False\n",
      "state: [-0.52968038 54.32359157], action: [-0.31899506 -0.167     ]\n",
      "Episode: 1167/3000, Reward: -6974.86325570049, done: False\n",
      "state: [-0.5289413  54.12155098], action: [-0.20316486 -0.167     ]\n",
      "Episode: 1168/3000, Reward: -6913.252549880329, done: False\n",
      "state: [-0.52860082 53.9300007 ], action: [-0.27592313 -0.167     ]\n",
      "Episode: 1169/3000, Reward: -6841.255171053255, done: False\n",
      "state: [-0.52811011 53.71498504], action: [-0.26858735 -0.167     ]\n",
      "Episode: 1170/3000, Reward: -6798.525628836901, done: False\n",
      "state: [-0.52808842 53.68769659], action: [-0.2614655 -0.167    ]\n",
      "Episode: 1171/3000, Reward: -6725.039868609814, done: False\n",
      "state: [-0.52739414 53.42410069], action: [-0.18397695 -0.167     ]\n",
      "Episode: 1172/3000, Reward: -6674.4912614555, done: False\n",
      "state: [-0.52746794 53.32623144], action: [-0.25980505 -0.167     ]\n",
      "Episode: 1173/3000, Reward: -6596.152866106076, done: False\n",
      "state: [-0.52705508 53.19825089], action: [-0.23124084 -0.167     ]\n",
      "Episode: 1174/3000, Reward: -6559.317857840545, done: False\n",
      "state: [-0.52662951 52.9940415 ], action: [-0.2553709 -0.167    ]\n",
      "Episode: 1175/3000, Reward: -6489.778340729408, done: False\n",
      "state: [-0.52649445 52.90423679], action: [-0.23822273 -0.167     ]\n",
      "Episode: 1176/3000, Reward: -6441.122172469476, done: False\n",
      "state: [-0.52635602 52.76846973], action: [-0.2795527 -0.167    ]\n",
      "Episode: 1177/3000, Reward: -6365.457694422101, done: False\n",
      "state: [-0.52578912 52.57744559], action: [-0.25262663 -0.167     ]\n",
      "Episode: 1178/3000, Reward: -6307.62563265216, done: False\n",
      "state: [-0.52537824 52.39159599], action: [-0.30922347 -0.167     ]\n",
      "Episode: 1179/3000, Reward: -6209.339843021774, done: False\n",
      "state: [-0.52506867 52.20414465], action: [-0.26019984 -0.167     ]\n",
      "Episode: 1180/3000, Reward: -6207.361678293772, done: False\n",
      "state: [-0.52497301 52.21544173], action: [-0.2526909 -0.167    ]\n",
      "Episode: 1181/3000, Reward: -6127.37691889844, done: False\n",
      "state: [-0.52446281 51.9833433 ], action: [-0.25655082 -0.167     ]\n",
      "Episode: 1182/3000, Reward: -6052.034346798882, done: False\n",
      "state: [-0.5238237  51.69194251], action: [-0.2310639 -0.167    ]\n",
      "Episode: 1183/3000, Reward: -5999.204082902923, done: False\n",
      "state: [-0.52378321 51.61462157], action: [-0.22921784 -0.167     ]\n",
      "Episode: 1184/3000, Reward: -5945.759829767058, done: False\n",
      "state: [-0.52376839 51.49541954], action: [-0.2870294 -0.167    ]\n",
      "Episode: 1185/3000, Reward: -5904.429930401541, done: False\n",
      "state: [-0.52341691 51.36045457], action: [-0.26527828 -0.167     ]\n",
      "Episode: 1186/3000, Reward: -5852.765793864739, done: False\n",
      "state: [-0.52296184 51.25351246], action: [-0.25431862 -0.167     ]\n",
      "Episode: 1187/3000, Reward: -5808.358134262123, done: False\n",
      "state: [-0.52263786 51.11519213], action: [-0.22904797 -0.167     ]\n",
      "Episode: 1188/3000, Reward: -5760.723657631859, done: False\n",
      "state: [-0.52244383 51.01752176], action: [-0.27090415 -0.167     ]\n",
      "Episode: 1189/3000, Reward: -5730.978208720673, done: False\n",
      "state: [-0.52212708 50.87194465], action: [-0.23754255 -0.167     ]\n",
      "Episode: 1190/3000, Reward: -5697.205516240801, done: False\n",
      "state: [-0.52234645 50.8317043 ], action: [-0.30034086 -0.167     ]\n",
      "Episode: 1191/3000, Reward: -5638.684226308598, done: False\n",
      "state: [-0.52224326 50.59407018], action: [-0.08834601 -0.167     ]\n",
      "Episode: 1192/3000, Reward: -5569.864957895477, done: False\n",
      "state: [-0.5213713  50.45805533], action: [-0.3084056 -0.167    ]\n",
      "Episode: 1193/3000, Reward: -5482.410076103447, done: False\n",
      "state: [-0.52122494 50.2731874 ], action: [-0.27341902 -0.167     ]\n",
      "Episode: 1194/3000, Reward: -5411.8141920551825, done: False\n",
      "state: [-0.52032288 50.029064  ], action: [-0.23843503 -0.167     ]\n",
      "Episode: 1195/3000, Reward: -5347.993754645734, done: False\n",
      "state: [-0.51984846 49.89304741], action: [-0.25061136 -0.167     ]\n",
      "Episode: 1196/3000, Reward: -5290.302540442504, done: False\n",
      "state: [-0.51975493 49.69258185], action: [-0.28815612 -0.167     ]\n",
      "Episode: 1197/3000, Reward: -5235.029389366912, done: False\n",
      "state: [-0.51937059 49.54423392], action: [-0.2816859 -0.167    ]\n",
      "Episode: 1198/3000, Reward: -5178.309495440626, done: False\n",
      "state: [-0.51899484 49.40315404], action: [-0.2700167 -0.167    ]\n",
      "Episode: 1199/3000, Reward: -5107.112058695158, done: False\n",
      "state: [-0.51848535 49.2972262 ], action: [-0.26322734 -0.167     ]\n",
      "Episode: 1200/3000, Reward: -5076.583142384751, done: False\n",
      "state: [-0.51820783 49.16062379], action: [-0.24235994 -0.167     ]\n",
      "Episode: 1201/3000, Reward: -5018.544657675521, done: False\n",
      "state: [-0.51798713 49.01345442], action: [-0.2919852 -0.167    ]\n",
      "Episode: 1202/3000, Reward: -4989.596679209533, done: False\n",
      "state: [-0.51751967 48.8789478 ], action: [-0.2928957 -0.167    ]\n",
      "Episode: 1203/3000, Reward: -4934.730635648123, done: False\n",
      "state: [-0.5173327  48.72102553], action: [-0.26562577 -0.167     ]\n",
      "Episode: 1204/3000, Reward: -4897.250341438261, done: False\n",
      "state: [-0.51713513 48.63710914], action: [-0.25656506 -0.167     ]\n",
      "Episode: 1205/3000, Reward: -4850.840571446934, done: False\n",
      "state: [-0.51654952 48.48752157], action: [-0.22018805 -0.167     ]\n",
      "Episode: 1206/3000, Reward: -4792.931204803086, done: False\n",
      "state: [-0.51644197 48.34977017], action: [-0.31599712 -0.167     ]\n",
      "Episode: 1207/3000, Reward: -4758.978592673942, done: False\n",
      "state: [-0.51584323 48.21974137], action: [-0.22641851 -0.167     ]\n",
      "Episode: 1208/3000, Reward: -4694.644630504512, done: False\n",
      "state: [-0.51574357 48.06818381], action: [-0.29415765 -0.167     ]\n",
      "Episode: 1209/3000, Reward: -4646.899987551768, done: False\n",
      "state: [-0.51522225 47.92079882], action: [-0.26188836 -0.167     ]\n",
      "Episode: 1210/3000, Reward: -4606.502689611769, done: False\n",
      "state: [-0.51525091 47.83628651], action: [-0.2943075 -0.167    ]\n",
      "Episode: 1211/3000, Reward: -4572.55359034767, done: False\n",
      "state: [-0.51470877 47.64210098], action: [-0.3144717 -0.167    ]\n",
      "Episode: 1212/3000, Reward: -4517.078656102248, done: False\n",
      "state: [-0.5141481  47.49497344], action: [-0.24322149 -0.167     ]\n",
      "Episode: 1213/3000, Reward: -4472.901157282052, done: False\n",
      "state: [-0.51438597 47.46395525], action: [-0.27591607 -0.167     ]\n",
      "Episode: 1214/3000, Reward: -4444.46351195413, done: False\n",
      "state: [-0.51400037 47.3616295 ], action: [-0.25929272 -0.167     ]\n",
      "Episode: 1215/3000, Reward: -4404.919201022813, done: False\n",
      "state: [-0.51361425 47.30969605], action: [-0.24399297 -0.167     ]\n",
      "Episode: 1216/3000, Reward: -4387.084403887804, done: False\n",
      "state: [-0.51360889 47.24192656], action: [-0.2953768 -0.167    ]\n",
      "Episode: 1217/3000, Reward: -4361.351201556038, done: False\n",
      "state: [-0.51320503 47.12785303], action: [-0.269426 -0.167   ]\n",
      "Episode: 1218/3000, Reward: -4334.964287653864, done: False\n",
      "state: [-0.51314384 47.10379819], action: [-0.28388643 -0.167     ]\n",
      "Episode: 1219/3000, Reward: -4273.932307479879, done: False\n",
      "state: [-0.51264763 46.89796311], action: [-0.2867073 -0.167    ]\n",
      "Episode: 1220/3000, Reward: -4231.8909863883955, done: False\n",
      "state: [-0.51227534 46.71175264], action: [-0.33037913 -0.167     ]\n",
      "Episode: 1221/3000, Reward: -4201.616865616614, done: False\n",
      "state: [-0.51183731 46.58358543], action: [-0.2932514 -0.167    ]\n",
      "Episode: 1222/3000, Reward: -4137.101093064432, done: False\n",
      "state: [-0.51134991 46.39421477], action: [-0.2888136 -0.167    ]\n",
      "Episode: 1223/3000, Reward: -4098.058071011398, done: False\n",
      "state: [-0.51101907 46.27396887], action: [-0.31432045 -0.167     ]\n",
      "Episode: 1224/3000, Reward: -4067.999931596695, done: False\n",
      "state: [-0.51017855 46.0639351 ], action: [-0.23726179 -0.167     ]\n",
      "Episode: 1225/3000, Reward: -4029.752168098444, done: False\n",
      "state: [-0.51007831 45.98924151], action: [-0.2965393 -0.167    ]\n",
      "Episode: 1226/3000, Reward: -4000.9867539848824, done: False\n",
      "state: [-0.50980526 45.90965182], action: [-0.24893747 -0.167     ]\n",
      "Episode: 1227/3000, Reward: -3997.0388794461105, done: False\n",
      "state: [-0.51000074 45.89780558], action: [-0.27062488 -0.167     ]\n",
      "Episode: 1228/3000, Reward: -3953.14168678059, done: False\n",
      "state: [-0.50957102 45.83460941], action: [-0.27244815 -0.167     ]\n",
      "Episode: 1229/3000, Reward: -3926.487411155454, done: False\n",
      "state: [-0.50931425 45.75803855], action: [-0.25956315 -0.167     ]\n",
      "Episode: 1230/3000, Reward: -3903.4986798364066, done: False\n",
      "state: [-0.50930318 45.70393221], action: [-0.26631704 -0.167     ]\n",
      "Episode: 1231/3000, Reward: -3904.499663508489, done: False\n",
      "state: [-0.50950981 45.78102495], action: [-0.25493935 -0.167     ]\n",
      "Episode: 1232/3000, Reward: -3899.450449287051, done: False\n",
      "state: [-0.50951651 45.73733686], action: [-0.27988324 -0.167     ]\n",
      "Episode: 1233/3000, Reward: -3884.4071679264493, done: False\n",
      "state: [-0.50955409 45.75959492], action: [-0.29468375 -0.167     ]\n",
      "Episode: 1234/3000, Reward: -3838.996250361976, done: False\n",
      "state: [-0.50928343 45.66543287], action: [-0.2670647 -0.167    ]\n",
      "Episode: 1235/3000, Reward: -3805.893169172345, done: False\n",
      "state: [-0.50885131 45.4613506 ], action: [-0.30132273 -0.167     ]\n",
      "Episode: 1236/3000, Reward: -3746.941933423325, done: False\n",
      "state: [-0.50797399 45.21993557], action: [-0.30439946 -0.167     ]\n",
      "Episode: 1237/3000, Reward: -3674.4825396078645, done: False\n",
      "state: [-0.50735651 44.96186709], action: [-0.28685084 -0.167     ]\n",
      "Episode: 1238/3000, Reward: -3638.2348561111544, done: False\n",
      "state: [-0.50700475 44.81677284], action: [-0.298198 -0.167   ]\n",
      "Episode: 1239/3000, Reward: -3590.9823707656747, done: False\n",
      "state: [-0.50610568 44.53589902], action: [-0.3001222 -0.167    ]\n",
      "Episode: 1240/3000, Reward: -3540.213296454895, done: False\n",
      "state: [-0.5052593  44.27880318], action: [-0.30549282 -0.167     ]\n",
      "Episode: 1241/3000, Reward: -3483.419252070028, done: False\n",
      "state: [-0.50446355 44.02680868], action: [-0.2779378 -0.167    ]\n",
      "Episode: 1242/3000, Reward: -3446.516236801217, done: False\n",
      "state: [-0.50339778 43.81737093], action: [-0.2647392 -0.167    ]\n",
      "Episode: 1243/3000, Reward: -3426.1790026914223, done: False\n",
      "state: [-0.50371801 43.77577249], action: [-0.31323025 -0.167     ]\n",
      "Episode: 1244/3000, Reward: -3397.49269955203, done: False\n",
      "state: [-0.50321678 43.64110564], action: [-0.3043891 -0.167    ]\n",
      "Episode: 1245/3000, Reward: -3364.0041444018552, done: False\n",
      "state: [-0.5030997  43.61989114], action: [-0.29889295 -0.167     ]\n",
      "Episode: 1246/3000, Reward: -3350.6851956107143, done: False\n",
      "state: [-0.50287303 43.51177364], action: [-0.2785537 -0.167    ]\n",
      "Episode: 1247/3000, Reward: -3328.812246462615, done: False\n",
      "state: [-0.50237539 43.43559768], action: [-0.2511547 -0.167    ]\n",
      "Episode: 1248/3000, Reward: -3313.122595238312, done: False\n",
      "state: [-0.50235563 43.37680061], action: [-0.2287407 -0.167    ]\n",
      "Episode: 1249/3000, Reward: -3304.087950478181, done: False\n",
      "state: [-0.50237153 43.3912364 ], action: [-0.29750624 -0.167     ]\n",
      "Episode: 1250/3000, Reward: -3290.330398679183, done: False\n",
      "state: [-0.50181645 43.23495665], action: [-0.28763482 -0.167     ]\n",
      "Episode: 1251/3000, Reward: -3231.0710674259276, done: False\n",
      "state: [-0.50173265 43.15069836], action: [-0.27607113 -0.167     ]\n",
      "Episode: 1252/3000, Reward: -3247.9160755792605, done: False\n",
      "state: [-0.50183882 43.15156569], action: [-0.28167886 -0.167     ]\n",
      "Episode: 1253/3000, Reward: -3247.5056411949963, done: False\n",
      "state: [-0.50184815 43.17086707], action: [-0.2925504 -0.167    ]\n",
      "Episode: 1254/3000, Reward: -3215.1065894406265, done: False\n",
      "state: [-0.50142087 43.02953019], action: [-0.2821494 -0.167    ]\n",
      "Episode: 1255/3000, Reward: -3204.595398633657, done: False\n",
      "state: [-0.49824365 42.95471046], action: [0.25726092 0.3195837 ]\n",
      "Episode: 1256/3000, Reward: -3186.592123938062, done: False\n",
      "state: [-0.50084437 42.89591547], action: [-0.30661646 -0.167     ]\n",
      "Episode: 1257/3000, Reward: -3176.664230362488, done: False\n",
      "state: [-0.50080836 42.90058576], action: [-0.31876203 -0.167     ]\n",
      "Episode: 1258/3000, Reward: -3160.4405246801643, done: False\n",
      "state: [-0.50029472 42.73664408], action: [-0.2988825 -0.167    ]\n",
      "Episode: 1259/3000, Reward: -3157.4261582328772, done: False\n",
      "state: [-0.50028816 42.71806415], action: [-0.28519762 -0.167     ]\n",
      "Episode: 1260/3000, Reward: -3129.8096741649274, done: False\n",
      "state: [-0.49986217 42.69866944], action: [-0.2600896 -0.167    ]\n",
      "Episode: 1261/3000, Reward: -3135.9564176177973, done: False\n",
      "state: [-0.50030615 42.72683303], action: [-0.2699389 -0.167    ]\n",
      "Episode: 1262/3000, Reward: -3127.077555727959, done: False\n",
      "state: [-0.50019852 42.68941953], action: [-0.257527 -0.167   ]\n",
      "Episode: 1263/3000, Reward: -3093.1188094607855, done: False\n",
      "state: [-0.49969131 42.53143588], action: [-0.28779927 -0.167     ]\n",
      "Episode: 1264/3000, Reward: -3071.73304015619, done: False\n",
      "state: [-0.49927998 42.43594334], action: [-0.27005562 -0.167     ]\n",
      "Episode: 1265/3000, Reward: -3081.908431369962, done: False\n",
      "state: [-0.49921575 42.47156776], action: [-0.29378128 -0.167     ]\n",
      "Episode: 1266/3000, Reward: -3047.5717297779693, done: False\n",
      "state: [-0.49923189 42.46251761], action: [-0.31913212 -0.167     ]\n",
      "Episode: 1267/3000, Reward: -3040.9081280979417, done: False\n",
      "state: [-0.49929843 42.39910256], action: [-0.32013223 -0.167     ]\n",
      "Episode: 1268/3000, Reward: -3026.166570723295, done: False\n",
      "state: [-0.49816346 42.35297648], action: [-0.4741919 -0.167    ]\n",
      "Episode: 1269/3000, Reward: -3011.703147691533, done: False\n",
      "state: [-0.49871926 42.2932471 ], action: [-0.29418555 -0.167     ]\n",
      "Episode: 1270/3000, Reward: -3010.3421873167463, done: False\n",
      "state: [-0.4985645  42.23883356], action: [-0.30219305 -0.167     ]\n",
      "Episode: 1271/3000, Reward: -3002.0938181070674, done: False\n",
      "state: [-0.49876108 42.28874215], action: [-0.25845635 -0.167     ]\n",
      "Episode: 1272/3000, Reward: -3002.0528126830613, done: False\n",
      "state: [-0.49855753 42.23288881], action: [-0.27261764 -0.167     ]\n",
      "Episode: 1273/3000, Reward: -2995.1841159533815, done: False\n",
      "state: [-0.49879651 42.22925843], action: [-0.31016845 -0.167     ]\n",
      "Episode: 1274/3000, Reward: -2983.6987074570707, done: False\n",
      "state: [-0.49889185 42.277347  ], action: [-0.29844126 -0.167     ]\n",
      "Episode: 1275/3000, Reward: -2973.006355735634, done: False\n",
      "state: [-0.49817478 42.20979071], action: [-0.26809528 -0.167     ]\n",
      "Episode: 1276/3000, Reward: -2975.0373197258914, done: False\n",
      "state: [-0.49832702 42.1369607 ], action: [-0.3015447 -0.167    ]\n",
      "Episode: 1277/3000, Reward: -2955.7538222255685, done: False\n",
      "state: [-0.4982167  42.12500124], action: [-0.30842286 -0.167     ]\n",
      "Episode: 1278/3000, Reward: -2982.3012380687906, done: False\n",
      "state: [-0.49931488 42.3740464 ], action: [-0.30891296 -0.167     ]\n",
      "Episode: 1279/3000, Reward: -2963.6446283571654, done: False\n",
      "state: [-0.49817833 42.13553326], action: [-0.29366624 -0.167     ]\n",
      "Episode: 1280/3000, Reward: -2957.2472268126903, done: False\n",
      "state: [-0.49821645 42.12779063], action: [-0.2576552 -0.167    ]\n",
      "Episode: 1281/3000, Reward: -2941.46343961051, done: False\n",
      "state: [-0.49806336 42.14690273], action: [-0.34484798 -0.167     ]\n",
      "Episode: 1282/3000, Reward: -2945.4168335483414, done: False\n",
      "state: [-0.4983663  42.15354079], action: [-0.28136274 -0.167     ]\n",
      "Episode: 1283/3000, Reward: -2941.896999209928, done: False\n",
      "state: [-0.49799456 42.11169267], action: [-0.30193305 -0.167     ]\n",
      "Episode: 1284/3000, Reward: -2936.561787356646, done: False\n",
      "state: [-0.49815875 42.06505119], action: [-0.3297605 -0.167    ]\n",
      "Episode: 1285/3000, Reward: -2953.1349621204095, done: False\n",
      "state: [-0.49843696 42.12722015], action: [-0.2920201 -0.167    ]\n",
      "Episode: 1286/3000, Reward: -2916.048850906534, done: False\n",
      "state: [-0.49849613 42.10314152], action: [-0.28967 -0.167  ]\n",
      "Episode: 1287/3000, Reward: -2947.9683252723385, done: False\n",
      "state: [-0.49808561 42.09450388], action: [-0.28922263 -0.167     ]\n",
      "Episode: 1288/3000, Reward: -2942.3517920936392, done: False\n",
      "state: [-0.4977798  42.02327904], action: [-0.25439712 -0.167     ]\n",
      "Episode: 1289/3000, Reward: -2951.498281837704, done: False\n",
      "state: [-0.49817644 42.02488082], action: [-0.26472852 -0.167     ]\n",
      "Episode: 1290/3000, Reward: -2932.6429374424133, done: False\n",
      "state: [-0.49761051 41.92910859], action: [-0.2778005 -0.167    ]\n",
      "Episode: 1291/3000, Reward: -2935.9925881400736, done: False\n",
      "state: [-0.49775009 41.99767305], action: [-0.2909171 -0.167    ]\n",
      "Episode: 1292/3000, Reward: -2938.5063372030645, done: False\n",
      "state: [-0.49856286 42.12960297], action: [-0.32638702 -0.167     ]\n",
      "Episode: 1293/3000, Reward: -2936.871914345696, done: False\n",
      "state: [-0.4978178  41.99337875], action: [-0.33550417 -0.167     ]\n",
      "Episode: 1294/3000, Reward: -2913.9124607949634, done: False\n",
      "state: [-0.49788116 41.98409427], action: [-0.31775755 -0.167     ]\n",
      "Episode: 1295/3000, Reward: -2920.569062271958, done: False\n",
      "state: [-0.49757327 41.88227059], action: [-0.30279258 -0.167     ]\n",
      "Episode: 1296/3000, Reward: -2910.1038295974167, done: False\n",
      "state: [-0.49755983 41.85424557], action: [-0.30932352 -0.167     ]\n",
      "Episode: 1297/3000, Reward: -2911.7666791046104, done: False\n",
      "state: [-0.49723107 41.84000957], action: [-0.27959138 -0.167     ]\n",
      "Episode: 1298/3000, Reward: -2913.1759335969564, done: False\n",
      "state: [-0.49751481 41.82503869], action: [-0.33807448 -0.167     ]\n",
      "Episode: 1299/3000, Reward: -2922.7320986623986, done: False\n",
      "state: [-0.49750643 41.83378328], action: [-0.2908228 -0.167    ]\n",
      "Episode: 1300/3000, Reward: -2894.2148841600874, done: False\n",
      "state: [-0.49670207 41.71488419], action: [-0.27812788 -0.167     ]\n",
      "Episode: 1301/3000, Reward: -2890.4031207404846, done: False\n",
      "state: [-0.49714403 41.73629821], action: [-0.28560057 -0.167     ]\n",
      "Episode: 1302/3000, Reward: -2886.8945956723574, done: False\n",
      "state: [-0.49672809 41.64136815], action: [-0.3051988 -0.167    ]\n",
      "Episode: 1303/3000, Reward: -2877.974534906011, done: False\n",
      "state: [-0.49636334 41.55039791], action: [-0.26736578 -0.167     ]\n",
      "Episode: 1304/3000, Reward: -2857.9723398432457, done: False\n",
      "state: [-0.49628716 41.51674382], action: [-0.2644447 -0.167    ]\n",
      "Episode: 1305/3000, Reward: -2856.541127787444, done: False\n",
      "state: [-0.49577388 41.44780137], action: [-0.24940974 -0.167     ]\n",
      "Episode: 1306/3000, Reward: -2842.8577118834037, done: False\n",
      "state: [-0.49606527 41.4599238 ], action: [-0.28128546 -0.167     ]\n",
      "Episode: 1307/3000, Reward: -2833.841672102965, done: False\n",
      "state: [-0.49563294 41.33459917], action: [-0.31646746 -0.167     ]\n",
      "Episode: 1308/3000, Reward: -2831.6220435440246, done: False\n",
      "state: [-0.49577493 41.33328867], action: [-0.26935878 -0.167     ]\n",
      "Episode: 1309/3000, Reward: -2822.9411854571317, done: False\n",
      "state: [-0.49517512 41.20732944], action: [-0.3111886 -0.167    ]\n",
      "Episode: 1310/3000, Reward: -2811.1509298204965, done: False\n",
      "state: [-0.49479769 41.14512158], action: [-0.29553348 -0.167     ]\n",
      "Episode: 1311/3000, Reward: -2808.267369632397, done: False\n",
      "state: [-0.49457397 41.11216815], action: [-0.31490132 -0.167     ]\n",
      "Episode: 1312/3000, Reward: -2801.960426962217, done: False\n",
      "state: [-0.49482793 41.10406989], action: [-0.30392522 -0.167     ]\n",
      "Episode: 1313/3000, Reward: -2800.3741340519673, done: False\n",
      "state: [-0.49469151 41.03114933], action: [-0.3002194 -0.167    ]\n",
      "Episode: 1314/3000, Reward: -2763.248284418556, done: False\n",
      "state: [-0.49465588 40.996391  ], action: [-0.21900806 -0.167     ]\n",
      "Episode: 1315/3000, Reward: -2782.085808830664, done: False\n",
      "state: [-0.49405038 40.88903507], action: [-0.2672843 -0.167    ]\n",
      "Episode: 1316/3000, Reward: -2767.6205155638536, done: False\n",
      "state: [-0.49372375 40.8345495 ], action: [-0.31252134 -0.167     ]\n",
      "Episode: 1317/3000, Reward: -2768.6179104045996, done: False\n",
      "state: [-0.493437   40.76125772], action: [-0.2835883 -0.167    ]\n",
      "Episode: 1318/3000, Reward: -2750.869172015724, done: False\n",
      "state: [-0.4933737  40.65370584], action: [-0.27447757 -0.167     ]\n",
      "Episode: 1319/3000, Reward: -2750.820943828395, done: False\n",
      "state: [-0.49329337 40.64395703], action: [-0.32600865 -0.167     ]\n",
      "Episode: 1320/3000, Reward: -2736.8261664528263, done: False\n",
      "state: [-0.49276635 40.61341555], action: [-0.28812814 -0.167     ]\n",
      "Episode: 1321/3000, Reward: -2728.7388264611664, done: False\n",
      "state: [-0.49305274 40.57420232], action: [-0.2925888 -0.167    ]\n",
      "Episode: 1322/3000, Reward: -2732.6764670454245, done: False\n",
      "state: [-0.49256595 40.48766311], action: [-0.27455515 -0.167     ]\n",
      "Episode: 1323/3000, Reward: -2719.3893352600803, done: False\n",
      "state: [-0.49274564 40.46044869], action: [-0.29471162 -0.167     ]\n",
      "Episode: 1324/3000, Reward: -2705.5150587825497, done: False\n",
      "state: [-0.49204765 40.32559451], action: [-0.30528873 -0.167     ]\n",
      "Episode: 1325/3000, Reward: -2698.020921317855, done: False\n",
      "state: [-0.49160461 40.2177253 ], action: [-0.2783707 -0.167    ]\n",
      "Episode: 1326/3000, Reward: -2688.5037079738813, done: False\n",
      "state: [-0.49151275 40.21778348], action: [-0.28988665 -0.167     ]\n",
      "Episode: 1327/3000, Reward: -2688.108331609174, done: False\n",
      "state: [-0.49133001 40.16354903], action: [-0.31682783 -0.167     ]\n",
      "Episode: 1328/3000, Reward: -2679.3277146646224, done: False\n",
      "state: [-0.49114863 40.07252854], action: [-0.3008371 -0.167    ]\n",
      "Episode: 1329/3000, Reward: -2667.6343563580094, done: False\n",
      "state: [-0.49075916 39.94559635], action: [-0.2973428 -0.167    ]\n",
      "Episode: 1330/3000, Reward: -2665.864495545822, done: False\n",
      "state: [-0.49056838 39.91670114], action: [-0.31941304 -0.167     ]\n",
      "Episode: 1331/3000, Reward: -2654.303302609767, done: False\n",
      "state: [-0.48995709 39.82206534], action: [-0.24656714 -0.167     ]\n",
      "Episode: 1332/3000, Reward: -2651.3909041926227, done: False\n",
      "state: [-0.48989972 39.78471351], action: [-0.29940352 -0.167     ]\n",
      "Episode: 1333/3000, Reward: -2645.675759517357, done: False\n",
      "state: [-0.48980361 39.73671952], action: [-0.26508677 -0.167     ]\n",
      "Episode: 1334/3000, Reward: -2633.734198396874, done: False\n",
      "state: [-0.4894877  39.61549925], action: [-0.263664 -0.167   ]\n",
      "Episode: 1335/3000, Reward: -2628.1964764154513, done: False\n",
      "state: [-0.48979329 39.5400989 ], action: [-0.13111457 -0.167     ]\n",
      "Episode: 1336/3000, Reward: -2627.5642613963983, done: False\n",
      "state: [-0.48941375 39.57415261], action: [-0.26713908 -0.167     ]\n",
      "Episode: 1337/3000, Reward: -2616.4952601621303, done: False\n",
      "state: [-0.48896641 39.46498444], action: [-0.2648633 -0.167    ]\n",
      "Episode: 1338/3000, Reward: -2611.5449880228007, done: False\n",
      "state: [-0.48910673 39.48780738], action: [-0.26459372 -0.167     ]\n",
      "Episode: 1339/3000, Reward: -2604.937978638795, done: False\n",
      "state: [-0.48860869 39.3627195 ], action: [-0.30557582 -0.167     ]\n",
      "Episode: 1340/3000, Reward: -2604.1212740056967, done: False\n",
      "state: [-0.48870444 39.35335294], action: [-0.32041293 -0.167     ]\n",
      "Episode: 1341/3000, Reward: -2592.8477274302763, done: False\n",
      "state: [-0.48795829 39.27198988], action: [-0.29451305 -0.167     ]\n",
      "Episode: 1342/3000, Reward: -2592.827652587126, done: False\n",
      "state: [-0.4877701  39.18074058], action: [-0.24460636 -0.167     ]\n",
      "Episode: 1343/3000, Reward: -2588.405924687285, done: False\n",
      "state: [-0.48801614 39.19340854], action: [-0.29076344 -0.167     ]\n",
      "Episode: 1344/3000, Reward: -2574.41780033892, done: False\n",
      "state: [-0.48761921 39.06601987], action: [-0.32631543 -0.167     ]\n",
      "Episode: 1345/3000, Reward: -2583.0408892515197, done: False\n",
      "state: [-0.48740058 39.08606391], action: [-0.31847072 -0.167     ]\n",
      "Episode: 1346/3000, Reward: -2568.474238562374, done: False\n",
      "state: [-0.48719204 39.00884122], action: [-0.32656765 -0.167     ]\n",
      "Episode: 1347/3000, Reward: -2562.5154650178456, done: False\n",
      "state: [-0.48695006 38.90990513], action: [-0.2735602 -0.167    ]\n",
      "Episode: 1348/3000, Reward: -2570.3691950445864, done: False\n",
      "state: [-0.48717368 38.9124211 ], action: [-0.30544093 -0.167     ]\n",
      "Episode: 1349/3000, Reward: -2535.539648067326, done: False\n",
      "state: [-0.48630555 38.7635704 ], action: [-0.27986917 -0.167     ]\n",
      "Episode: 1350/3000, Reward: -2553.896469818775, done: False\n",
      "state: [-0.48606679 38.73773105], action: [-0.25185508 -0.167     ]\n",
      "Episode: 1351/3000, Reward: -2549.9239468173373, done: False\n",
      "state: [-0.48614275 38.68980971], action: [-0.3374628 -0.167    ]\n",
      "Episode: 1352/3000, Reward: -2543.5068845153287, done: False\n",
      "state: [-0.48579613 38.65938851], action: [-0.29217365 -0.167     ]\n",
      "Episode: 1353/3000, Reward: -2544.806970457379, done: False\n",
      "state: [-0.4857256  38.60363685], action: [-0.34013388 -0.167     ]\n",
      "Episode: 1354/3000, Reward: -2537.622752995516, done: False\n",
      "state: [-0.48502093 38.49532878], action: [-0.2901906 -0.167    ]\n",
      "Episode: 1355/3000, Reward: -2532.035961888232, done: False\n",
      "state: [-0.48481833 38.43362407], action: [-0.27181587 -0.167     ]\n",
      "Episode: 1356/3000, Reward: -2518.9536221029925, done: False\n",
      "state: [-0.48475169 38.3955707 ], action: [-0.28263384 -0.167     ]\n",
      "Episode: 1357/3000, Reward: -2530.543028081561, done: False\n",
      "state: [-0.48460027 38.32132665], action: [-0.3011944 -0.167    ]\n",
      "Episode: 1358/3000, Reward: -2514.2211716308907, done: False\n",
      "state: [-0.48417768 38.25589775], action: [-0.2927527 -0.167    ]\n",
      "Episode: 1359/3000, Reward: -2515.2132334683147, done: False\n",
      "state: [-0.48396611 38.17626243], action: [-0.3025015 -0.167    ]\n",
      "Episode: 1360/3000, Reward: -2504.875069262215, done: False\n",
      "state: [-0.48401655 38.18386213], action: [-0.31558156 -0.167     ]\n",
      "Episode: 1361/3000, Reward: -2505.124084054645, done: False\n",
      "state: [-0.48400459 38.14299285], action: [-0.2760183 -0.167    ]\n",
      "Episode: 1362/3000, Reward: -2506.016015022639, done: False\n",
      "state: [-0.48367623 38.03208928], action: [-0.30960983 -0.167     ]\n",
      "Episode: 1363/3000, Reward: -2498.7977924479974, done: False\n",
      "state: [-0.48353164 38.05393902], action: [-0.28561458 -0.167     ]\n",
      "Episode: 1364/3000, Reward: -2498.383887847394, done: False\n",
      "state: [-0.48318599 37.96923843], action: [-0.29676545 -0.167     ]\n",
      "Episode: 1365/3000, Reward: -2499.285001014436, done: False\n",
      "state: [-0.48342593 38.00606519], action: [-0.30725914 -0.167     ]\n",
      "Episode: 1366/3000, Reward: -2498.959492239736, done: False\n",
      "state: [-0.4828519  37.92242577], action: [-0.2580113 -0.167    ]\n",
      "Episode: 1367/3000, Reward: -2482.2748507543324, done: False\n",
      "state: [-0.4825728  37.83372976], action: [-0.29897285 -0.167     ]\n",
      "Episode: 1368/3000, Reward: -2486.962614196816, done: False\n",
      "state: [-0.48032089 37.81256617], action: [ 0.10930076 -0.934263  ]\n",
      "Episode: 1369/3000, Reward: -2481.342705338145, done: False\n",
      "state: [-0.4823811  37.76615316], action: [-0.32085443 -0.167     ]\n",
      "Episode: 1370/3000, Reward: -2474.5016977794135, done: False\n",
      "state: [-0.48195601 37.71135427], action: [-0.29566577 -0.167     ]\n",
      "Episode: 1371/3000, Reward: -2472.804438540474, done: False\n",
      "state: [-0.48192754 37.66232011], action: [-0.30321872 -0.167     ]\n",
      "Episode: 1372/3000, Reward: -2470.6728442878575, done: False\n",
      "state: [-0.48144125 37.59052894], action: [-0.28591236 -0.167     ]\n",
      "Episode: 1373/3000, Reward: -2471.6342283012386, done: False\n",
      "state: [-0.48160697 37.58913064], action: [-0.31266245 -0.167     ]\n",
      "Episode: 1374/3000, Reward: -2458.3289406521117, done: False\n",
      "state: [-0.48129765 37.54584098], action: [-0.30605647 -0.167     ]\n",
      "Episode: 1375/3000, Reward: -2459.778870433864, done: False\n",
      "state: [-0.4812591  37.48482922], action: [-0.30928212 -0.167     ]\n",
      "Episode: 1376/3000, Reward: -2459.5927989574216, done: False\n",
      "state: [-0.48102465 37.45989767], action: [-0.31007883 -0.167     ]\n",
      "Episode: 1377/3000, Reward: -2452.831953687534, done: False\n",
      "state: [-0.48069834 37.39661915], action: [-0.29756534 -0.167     ]\n",
      "Episode: 1378/3000, Reward: -2450.554361717046, done: False\n",
      "state: [-0.48084639 37.38776994], action: [-0.31098878 -0.167     ]\n",
      "Episode: 1379/3000, Reward: -2448.5121682207277, done: False\n",
      "state: [-0.48025144 37.32712681], action: [-0.25116542 -0.167     ]\n",
      "Episode: 1380/3000, Reward: -2448.5833141202424, done: False\n",
      "state: [-0.48039711 37.28148587], action: [-0.2949206 -0.167    ]\n",
      "Episode: 1381/3000, Reward: -2449.613531647194, done: False\n",
      "state: [-0.48034477 37.2496581 ], action: [-0.3375473 -0.167    ]\n",
      "Episode: 1382/3000, Reward: -2435.1397580584635, done: False\n",
      "state: [-0.47943372 37.18017127], action: [-0.28542888 -0.167     ]\n",
      "Episode: 1383/3000, Reward: -2443.953249641346, done: False\n",
      "state: [-0.47959474 37.11640302], action: [-0.28735837 -0.167     ]\n",
      "Episode: 1384/3000, Reward: -2435.6272406964576, done: False\n",
      "state: [-0.4791801  37.06398562], action: [-0.30622587 -0.167     ]\n",
      "Episode: 1385/3000, Reward: -2423.96223726469, done: False\n",
      "state: [-0.47907531 37.01449675], action: [-0.26718867 -0.167     ]\n",
      "Episode: 1386/3000, Reward: -2423.017791327228, done: False\n",
      "state: [-0.47892657 36.93870519], action: [-0.31526208 -0.167     ]\n",
      "Episode: 1387/3000, Reward: -2421.6341944122255, done: False\n",
      "state: [-0.47870414 36.91182124], action: [-0.30177355 -0.167     ]\n",
      "Episode: 1388/3000, Reward: -2427.0427550199233, done: False\n",
      "state: [-0.47897386 36.93214384], action: [-0.36234695 -0.167     ]\n",
      "Episode: 1389/3000, Reward: -2433.00503187905, done: False\n",
      "state: [-0.47890577 36.9101185 ], action: [-0.28507847 -0.167     ]\n",
      "Episode: 1390/3000, Reward: -2421.4038329104287, done: False\n",
      "state: [-0.47851247 36.81463766], action: [-0.29144078 -0.167     ]\n",
      "Episode: 1391/3000, Reward: -2413.90766972193, done: False\n",
      "state: [-0.47799315 36.77384838], action: [-0.2717523 -0.167    ]\n",
      "Episode: 1392/3000, Reward: -2420.11994078087, done: False\n",
      "state: [-0.47815792 36.80826975], action: [-0.37656996 -0.167     ]\n",
      "Episode: 1393/3000, Reward: -2412.898974843925, done: False\n",
      "state: [-0.47779859 36.67147609], action: [-0.29981673 -0.167     ]\n",
      "Episode: 1394/3000, Reward: -2404.3477419549595, done: False\n",
      "state: [-0.47724281 36.61132729], action: [-0.26789346 -0.167     ]\n",
      "Episode: 1395/3000, Reward: -2404.05955981874, done: False\n",
      "state: [-0.47697078 36.52924224], action: [-0.2711021 -0.167    ]\n",
      "Episode: 1396/3000, Reward: -2401.4943129320955, done: False\n",
      "state: [-0.47562551 36.52922618], action: [-0.46145362 -0.167     ]\n",
      "Episode: 1397/3000, Reward: -2401.696252225291, done: False\n",
      "state: [-0.47715875 36.51502703], action: [-0.2723422 -0.167    ]\n",
      "Episode: 1398/3000, Reward: -2401.6492160723715, done: False\n",
      "state: [-0.47649899 36.4083455 ], action: [-0.29002643 -0.167     ]\n",
      "Episode: 1399/3000, Reward: -2390.865497898807, done: False\n",
      "state: [-0.47616884 36.35358622], action: [-0.2862416 -0.167    ]\n",
      "Episode: 1400/3000, Reward: -2390.946504687114, done: False\n",
      "state: [-0.47619213 36.31801441], action: [-0.2881596 -0.167    ]\n",
      "Episode: 1401/3000, Reward: -2395.5517012936953, done: False\n",
      "state: [-0.47607509 36.30750177], action: [-0.31552318 -0.167     ]\n",
      "Episode: 1402/3000, Reward: -2375.5737995509035, done: False\n",
      "state: [-0.47552373 36.22602776], action: [-0.3279437 -0.167    ]\n",
      "Episode: 1403/3000, Reward: -2383.582403021068, done: False\n",
      "state: [-0.47552922 36.19112477], action: [-0.29853508 -0.167     ]\n",
      "Episode: 1404/3000, Reward: -2383.421095232282, done: False\n",
      "state: [-0.47458759 36.18032501], action: [-0.464708 -0.167   ]\n",
      "Episode: 1405/3000, Reward: -2376.8430831402857, done: False\n",
      "state: [-0.47537586 36.09017588], action: [-0.28681582 -0.167     ]\n",
      "Episode: 1406/3000, Reward: -2377.0474516630416, done: False\n",
      "state: [-0.47494155 36.03424863], action: [-0.30245647 -0.167     ]\n",
      "Episode: 1407/3000, Reward: -2371.7926788509517, done: False\n",
      "state: [-0.47446342 35.96778204], action: [-0.2602283 -0.167    ]\n",
      "Episode: 1408/3000, Reward: -2369.629996836439, done: False\n",
      "state: [-0.47448102 35.93852185], action: [-0.2964384 -0.167    ]\n",
      "Episode: 1409/3000, Reward: -2366.773634160454, done: False\n",
      "state: [-0.47422517 35.89050134], action: [-0.2648385 -0.167    ]\n",
      "Episode: 1410/3000, Reward: -2365.504804690782, done: False\n",
      "state: [-0.47401967 35.83179442], action: [-0.30354083 -0.167     ]\n",
      "Episode: 1411/3000, Reward: -2364.6289941645946, done: False\n",
      "state: [-0.47392003 35.82032493], action: [-0.32667327 -0.167     ]\n",
      "Episode: 1412/3000, Reward: -2359.669045921565, done: False\n",
      "state: [-0.473293   35.75200863], action: [-0.30755967 -0.167     ]\n",
      "Episode: 1413/3000, Reward: -2354.623403996897, done: False\n",
      "state: [-0.47343052 35.71347503], action: [-0.3178776 -0.167    ]\n",
      "Episode: 1414/3000, Reward: -2368.883475944381, done: False\n",
      "state: [-0.4734801  35.69332333], action: [-0.28708538 -0.167     ]\n",
      "Episode: 1415/3000, Reward: -2352.160596632884, done: False\n",
      "state: [-0.47318996 35.62639742], action: [-0.3079119 -0.167    ]\n",
      "Episode: 1416/3000, Reward: -2343.62395874399, done: False\n",
      "state: [-0.47319284 35.58095807], action: [-0.30299008 -0.167     ]\n",
      "Episode: 1417/3000, Reward: -2335.6801923649905, done: False\n",
      "state: [-0.47202495 35.45861088], action: [-0.22789821 -0.167     ]\n",
      "Episode: 1418/3000, Reward: -2339.726855896633, done: False\n",
      "state: [-0.47237622 35.46083013], action: [-0.3326032 -0.167    ]\n",
      "Episode: 1419/3000, Reward: -2332.1364528474464, done: False\n",
      "state: [-0.47164123 35.38665153], action: [-0.2981424 -0.167    ]\n",
      "Episode: 1420/3000, Reward: -2334.2263401044843, done: False\n",
      "state: [-0.47184324 35.35002247], action: [-0.2989381 -0.167    ]\n",
      "Episode: 1421/3000, Reward: -2338.107701602094, done: False\n",
      "state: [-0.47152407 35.311734  ], action: [-0.31751746 -0.167     ]\n",
      "Episode: 1422/3000, Reward: -2330.1171359667355, done: False\n",
      "state: [-0.47155611 35.27026066], action: [-0.29620525 -0.167     ]\n",
      "Episode: 1423/3000, Reward: -2331.377847628905, done: False\n",
      "state: [-0.47122635 35.2242385 ], action: [-0.29995558 -0.167     ]\n",
      "Episode: 1424/3000, Reward: -2323.1444581992496, done: False\n",
      "state: [-0.4707085  35.15757774], action: [-0.26907572 -0.167     ]\n",
      "Episode: 1425/3000, Reward: -2320.8996279768835, done: False\n",
      "state: [-0.47088385 35.12052939], action: [-0.2154206 -0.167    ]\n",
      "Episode: 1426/3000, Reward: -2327.8859426326458, done: False\n",
      "state: [-0.47061286 35.10720594], action: [-0.31766495 -0.167     ]\n",
      "Episode: 1427/3000, Reward: -2320.8633778114568, done: False\n",
      "state: [-0.47029656 35.03586205], action: [-0.3048632 -0.167    ]\n",
      "Episode: 1428/3000, Reward: -2317.071048408929, done: False\n",
      "state: [-0.47006875 34.98321469], action: [-0.30297276 -0.167     ]\n",
      "Episode: 1429/3000, Reward: -2298.809849082955, done: False\n",
      "state: [-0.46950485 34.90708395], action: [-0.27716672 -0.167     ]\n",
      "Episode: 1430/3000, Reward: -2304.419178416577, done: False\n",
      "state: [-0.46944512 34.83793698], action: [-0.2997473 -0.167    ]\n",
      "Episode: 1431/3000, Reward: -2300.3408309729534, done: False\n",
      "state: [-0.46883247 34.76155035], action: [-0.3081743 -0.167    ]\n",
      "Episode: 1432/3000, Reward: -2293.0916867479727, done: False\n",
      "state: [-0.46860436 34.67761578], action: [-0.28192818 -0.167     ]\n",
      "Episode: 1433/3000, Reward: -2281.1174853960447, done: False\n",
      "state: [-0.46830683 34.62460634], action: [-0.28166482 -0.167     ]\n",
      "Episode: 1434/3000, Reward: -2271.852626122094, done: False\n",
      "state: [-0.46783976 34.54198826], action: [-0.27579272 -0.167     ]\n",
      "Episode: 1435/3000, Reward: -2270.5626175705447, done: False\n",
      "state: [-0.46820145 34.52405495], action: [-0.30735588 -0.167     ]\n",
      "Episode: 1436/3000, Reward: -2265.6036492335274, done: False\n",
      "state: [-0.46752948 34.4608809 ], action: [-0.29172698 -0.167     ]\n",
      "Episode: 1437/3000, Reward: -2269.8091755200135, done: False\n",
      "state: [-0.46750847 34.47367112], action: [-0.30895436 -0.167     ]\n",
      "Episode: 1438/3000, Reward: -2275.5454775772005, done: False\n",
      "state: [-0.46713946 34.41244518], action: [-0.3032568 -0.167    ]\n",
      "Episode: 1439/3000, Reward: -2278.883980333888, done: False\n",
      "state: [-0.46719876 34.3928977 ], action: [-0.30131578 -0.167     ]\n",
      "Episode: 1440/3000, Reward: -2268.135165275923, done: False\n",
      "state: [-0.46722733 34.38532358], action: [-0.2804035 -0.167    ]\n",
      "Episode: 1441/3000, Reward: -2273.4677303740896, done: False\n",
      "state: [-0.46708991 34.37199638], action: [-0.28255662 -0.167     ]\n",
      "Episode: 1442/3000, Reward: -2282.066108890794, done: False\n",
      "state: [-0.46711417 34.33683986], action: [-0.31185687 -0.167     ]\n",
      "Episode: 1443/3000, Reward: -2265.710576344928, done: False\n",
      "state: [-0.4665096  34.28857348], action: [-0.29603472 -0.167     ]\n",
      "Episode: 1444/3000, Reward: -2269.8129736846004, done: False\n",
      "state: [-0.46638846 34.2318347 ], action: [-0.29869145 -0.167     ]\n",
      "Episode: 1445/3000, Reward: -2262.364060038635, done: False\n",
      "state: [-0.46672364 34.24963141], action: [-0.31788445 -0.167     ]\n",
      "Episode: 1446/3000, Reward: -2269.689773530248, done: False\n",
      "state: [-0.46639251 34.20606708], action: [-0.30939597 -0.167     ]\n",
      "Episode: 1447/3000, Reward: -2265.491046126669, done: False\n",
      "state: [-0.46586545 34.13351754], action: [-0.30999953 -0.167     ]\n",
      "Episode: 1448/3000, Reward: -2260.2820192834442, done: False\n",
      "state: [-0.46548904 34.04135851], action: [-0.3169651 -0.167    ]\n",
      "Episode: 1449/3000, Reward: -2246.084388086248, done: False\n",
      "state: [-0.46496827 33.95915035], action: [-0.30716932 -0.167     ]\n",
      "Episode: 1450/3000, Reward: -2249.1926830278226, done: False\n",
      "state: [-0.4648452  33.91329109], action: [-0.302751 -0.167   ]\n",
      "Episode: 1451/3000, Reward: -2241.75019170979, done: False\n",
      "state: [-0.46461719 33.86798462], action: [-0.30119094 -0.167     ]\n",
      "Episode: 1452/3000, Reward: -2233.6375028098614, done: False\n",
      "state: [-0.4639173  33.76555185], action: [-0.29568318 -0.167     ]\n",
      "Episode: 1453/3000, Reward: -2231.910435124287, done: False\n",
      "state: [-0.4637656  33.71910898], action: [-0.30446178 -0.167     ]\n",
      "Episode: 1454/3000, Reward: -2216.5961895711384, done: False\n",
      "state: [-0.46337909 33.65715224], action: [-0.29159436 -0.167     ]\n",
      "Episode: 1455/3000, Reward: -2226.3281761340977, done: False\n",
      "state: [-0.46347812 33.63805014], action: [-0.2969985 -0.167    ]\n",
      "Episode: 1456/3000, Reward: -2218.381335087022, done: False\n",
      "state: [-0.46314377 33.57145671], action: [-0.2894883 -0.167    ]\n",
      "Episode: 1457/3000, Reward: -2214.7949806520073, done: False\n",
      "state: [-0.46253287 33.48964068], action: [-0.3101064 -0.167    ]\n",
      "Episode: 1458/3000, Reward: -2213.7269322170664, done: False\n",
      "state: [-0.46261591 33.46197364], action: [-0.29779828 -0.167     ]\n",
      "Episode: 1459/3000, Reward: -2217.3573631405347, done: False\n",
      "state: [-0.46254239 33.48550681], action: [-0.2771597 -0.167    ]\n",
      "Episode: 1460/3000, Reward: -2219.6792838320703, done: False\n",
      "state: [-0.46269421 33.45638016], action: [-0.31734595 -0.167     ]\n",
      "Episode: 1461/3000, Reward: -2207.8443012187613, done: False\n",
      "state: [-0.46196164 33.3377936 ], action: [-0.28179124 -0.167     ]\n",
      "Episode: 1462/3000, Reward: -2200.9481069954277, done: False\n",
      "state: [-0.46117424 33.23415314], action: [-0.30510885 -0.167     ]\n",
      "Episode: 1463/3000, Reward: -2201.310217774138, done: False\n",
      "state: [-0.46087615 33.32150265], action: [-0.45770746 -0.167     ]\n",
      "Episode: 1464/3000, Reward: -2199.8709375186886, done: False\n",
      "state: [-0.46094051 33.14150567], action: [-0.28897092 -0.167     ]\n",
      "Episode: 1465/3000, Reward: -2192.755188200041, done: False\n",
      "state: [-0.46047295 33.08377252], action: [-0.26247808 -0.167     ]\n",
      "Episode: 1466/3000, Reward: -2182.766469399017, done: False\n",
      "state: [-0.45981166 32.9594417 ], action: [-0.25782615 -0.167     ]\n",
      "Episode: 1467/3000, Reward: -2163.8376156251447, done: False\n",
      "state: [-0.45972549 32.90966557], action: [-0.27883163 -0.167     ]\n",
      "Episode: 1468/3000, Reward: -2173.4654823368796, done: False\n",
      "state: [-0.45919334 32.84497011], action: [-0.27736747 -0.167     ]\n",
      "Episode: 1469/3000, Reward: -2163.359776225392, done: False\n",
      "state: [-0.45939342 32.83528472], action: [-0.3180216 -0.167    ]\n",
      "Episode: 1470/3000, Reward: -2161.737414400635, done: False\n",
      "state: [-0.45875476 32.72303494], action: [-0.29498678 -0.167     ]\n",
      "Episode: 1471/3000, Reward: -2151.246397933893, done: False\n",
      "state: [-0.45845352 32.66335662], action: [-0.2566898 -0.167    ]\n",
      "Episode: 1472/3000, Reward: -2153.6004484958244, done: False\n",
      "state: [-0.45878206 32.7279495 ], action: [-0.29052594 -0.167     ]\n",
      "Episode: 1473/3000, Reward: -2168.5693125941884, done: False\n",
      "state: [-0.45849068 32.64157664], action: [-0.31781584 -0.167     ]\n",
      "Episode: 1474/3000, Reward: -2152.584512728673, done: False\n",
      "state: [-0.45777736 32.55182299], action: [-0.31165367 -0.167     ]\n",
      "Episode: 1475/3000, Reward: -2145.2324705584347, done: False\n",
      "state: [-0.4574952  32.44979884], action: [-0.34025532 -0.167     ]\n",
      "Episode: 1476/3000, Reward: -2134.7156550085715, done: False\n",
      "state: [-0.45651354 32.33585164], action: [-0.2957493 -0.167    ]\n",
      "Episode: 1477/3000, Reward: -2128.0079175357987, done: False\n",
      "state: [-0.45638464 32.27293897], action: [-0.29223645 -0.167     ]\n",
      "Episode: 1478/3000, Reward: -2110.6053156073267, done: False\n",
      "state: [-0.45620748 32.23367482], action: [-0.28352514 -0.167     ]\n",
      "Episode: 1479/3000, Reward: -2119.2881892370087, done: False\n",
      "state: [-0.45562558 32.16073486], action: [-0.29075295 -0.167     ]\n",
      "Episode: 1480/3000, Reward: -2111.9388291904033, done: False\n",
      "state: [-0.45528406 32.08984831], action: [-0.29272133 -0.167     ]\n",
      "Episode: 1481/3000, Reward: -2103.904541955495, done: False\n",
      "state: [-0.45504439 32.05835398], action: [-0.32779053 -0.167     ]\n",
      "Episode: 1482/3000, Reward: -2096.3080623212345, done: False\n",
      "state: [-0.45475933 31.96535458], action: [-0.26168227 -0.167     ]\n",
      "Episode: 1483/3000, Reward: -2094.456438798173, done: False\n",
      "state: [-0.45436393 31.90563336], action: [-0.2933316 -0.167    ]\n",
      "Episode: 1484/3000, Reward: -2090.2688908193977, done: False\n",
      "state: [-0.45557539 31.94986656], action: [-0.29760358 -0.167     ]\n",
      "Episode: 1485/3000, Reward: -2086.6837601029492, done: False\n",
      "state: [-0.45370956 31.80203947], action: [-0.280059 -0.167   ]\n",
      "Episode: 1486/3000, Reward: -2081.790370160911, done: False\n",
      "state: [-0.45330835 31.7364792 ], action: [-0.26806694 -0.167     ]\n",
      "Episode: 1487/3000, Reward: -2082.089849249093, done: False\n",
      "state: [-0.45324702 31.6785992 ], action: [-0.3063607 -0.167    ]\n",
      "Episode: 1488/3000, Reward: -2074.9308563559575, done: False\n",
      "state: [-0.45285473 31.62347551], action: [-0.29052594 -0.167     ]\n",
      "Episode: 1489/3000, Reward: -2065.8844528236714, done: False\n",
      "state: [-0.45236255 31.54040421], action: [-0.2845071 -0.167    ]\n",
      "Episode: 1490/3000, Reward: -2060.1877010941457, done: False\n",
      "state: [-0.45204444 31.47967023], action: [-0.2893974 -0.167    ]\n",
      "Episode: 1491/3000, Reward: -2056.9416127260733, done: False\n",
      "state: [-0.45191797 31.42059535], action: [-0.29570058 -0.167     ]\n",
      "Episode: 1492/3000, Reward: -2043.980778445994, done: False\n",
      "state: [-0.45158486 31.37534106], action: [-0.31882715 -0.167     ]\n",
      "Episode: 1493/3000, Reward: -2042.762981375141, done: False\n",
      "state: [-0.45082292 31.28491126], action: [-0.29238647 -0.167     ]\n",
      "Episode: 1494/3000, Reward: -2043.6735076626414, done: False\n",
      "state: [-0.45061255 31.23617159], action: [-0.29907358 -0.167     ]\n",
      "Episode: 1495/3000, Reward: -2037.9510068474408, done: False\n",
      "state: [-0.45022303 31.16887523], action: [-0.30587667 -0.167     ]\n",
      "Episode: 1496/3000, Reward: -2031.5234329519644, done: False\n",
      "state: [-0.44991043 31.11221856], action: [-0.30611524 -0.167     ]\n",
      "Episode: 1497/3000, Reward: -2020.3860126539175, done: False\n",
      "state: [-0.44952177 31.02289289], action: [-0.288901 -0.167   ]\n",
      "Episode: 1498/3000, Reward: -2019.8485003546257, done: False\n",
      "state: [-0.44910389 30.9827209 ], action: [-0.29505643 -0.167     ]\n",
      "Episode: 1499/3000, Reward: -2011.4508000140281, done: False\n",
      "state: [-0.44879198 30.90350241], action: [-0.3203787 -0.167    ]\n",
      "Episode: 1500/3000, Reward: -2007.5576434183827, done: False\n",
      "state: [-0.44830628 30.84384619], action: [-0.2733555 -0.167    ]\n",
      "Episode: 1501/3000, Reward: -1998.9789543744544, done: False\n",
      "state: [-0.44967556 30.83184378], action: [-0.14297989 -0.167     ]\n",
      "Episode: 1502/3000, Reward: -1996.242665937298, done: False\n",
      "state: [-0.44770713 30.73245963], action: [-0.29442248 -0.167     ]\n",
      "Episode: 1503/3000, Reward: -1996.1419574531851, done: False\n",
      "state: [-0.44744763 30.68129717], action: [-0.2963549 -0.167    ]\n",
      "Episode: 1504/3000, Reward: -1975.4295015125974, done: False\n",
      "state: [-0.44737079 30.63305902], action: [-0.3077945 -0.167    ]\n",
      "Episode: 1505/3000, Reward: -1978.5063678618346, done: False\n",
      "state: [-0.44680091 30.55911045], action: [-0.30625352 -0.167     ]\n",
      "Episode: 1506/3000, Reward: -1970.5287104006, done: False\n",
      "state: [-0.44617146 30.47952355], action: [-0.3139216 -0.167    ]\n",
      "Episode: 1507/3000, Reward: -1969.8840454152246, done: False\n",
      "state: [-0.44770609 30.4308505 ], action: [-0.67881346 -0.696368  ]\n",
      "Episode: 1508/3000, Reward: -1965.078923503963, done: False\n",
      "state: [-0.44536505 30.34947287], action: [-0.26466468 -0.167     ]\n",
      "Episode: 1509/3000, Reward: -1960.0788859763163, done: False\n",
      "state: [-0.4454194  30.33590065], action: [-0.3039356 -0.167    ]\n",
      "Episode: 1510/3000, Reward: -1956.5090689947262, done: False\n",
      "state: [-0.44472571 30.26457267], action: [-0.30132273 -0.167     ]\n",
      "Episode: 1511/3000, Reward: -1948.4464159402523, done: False\n",
      "state: [-0.44441406 30.18867745], action: [-0.28122574 -0.167     ]\n",
      "Episode: 1512/3000, Reward: -1944.9229616272055, done: False\n",
      "state: [-0.44434357 30.14932199], action: [-0.2957876 -0.167    ]\n",
      "Episode: 1513/3000, Reward: -1938.244203311905, done: False\n",
      "state: [-0.44392685 30.09288187], action: [-0.3041814 -0.167    ]\n",
      "Episode: 1514/3000, Reward: -1933.336120562239, done: False\n",
      "state: [-0.44355206 30.02713904], action: [-0.2986289 -0.167    ]\n",
      "Episode: 1515/3000, Reward: -1928.007806902648, done: False\n",
      "state: [-0.44281982 29.98781601], action: [-0.2709501 -0.167    ]\n",
      "Episode: 1516/3000, Reward: -1923.043085185278, done: False\n",
      "state: [-0.44265982 29.90739538], action: [-0.28199843 -0.167     ]\n",
      "Episode: 1517/3000, Reward: -1914.340900581974, done: False\n",
      "state: [-0.44218665 29.84739303], action: [-0.29416114 -0.167     ]\n",
      "Episode: 1518/3000, Reward: -1912.8638879600455, done: False\n",
      "state: [-0.44192948 29.80268543], action: [-0.28274617 -0.167     ]\n",
      "Episode: 1519/3000, Reward: -1906.8181582893762, done: False\n",
      "state: [-0.44204523 29.77160994], action: [-0.29052594 -0.167     ]\n",
      "Episode: 1520/3000, Reward: -1906.9702626029402, done: False\n",
      "state: [-0.44170816 29.73418856], action: [-0.27780756 -0.167     ]\n",
      "Episode: 1521/3000, Reward: -1901.5955944580887, done: False\n",
      "state: [-0.44115971 29.67336885], action: [-0.2746257 -0.167    ]\n",
      "Episode: 1522/3000, Reward: -1897.0870876801148, done: False\n",
      "state: [-0.44150069 29.67419036], action: [-0.2699106 -0.167    ]\n",
      "Episode: 1523/3000, Reward: -1894.388917700246, done: False\n",
      "state: [-0.44093421 29.61347314], action: [-0.29387885 -0.167     ]\n",
      "Episode: 1524/3000, Reward: -1895.812848921457, done: False\n",
      "state: [-0.44068606 29.59582482], action: [-0.27810675 -0.167     ]\n",
      "Episode: 1525/3000, Reward: -1901.1562809523275, done: False\n",
      "state: [-0.44082224 29.62152104], action: [-0.26949322 -0.167     ]\n",
      "Episode: 1526/3000, Reward: -1912.8644878506886, done: False\n",
      "state: [-0.44171038 29.74117056], action: [-0.31772667 -0.167     ]\n",
      "Episode: 1527/3000, Reward: -1927.3957867771433, done: False\n",
      "state: [-0.44186911 29.78130541], action: [-0.2423348 -0.167    ]\n",
      "Episode: 1528/3000, Reward: -1934.8969224844932, done: False\n",
      "state: [-0.44217103 29.81822914], action: [-0.27489725 -0.167     ]\n",
      "Episode: 1529/3000, Reward: -1937.034580056833, done: False\n",
      "state: [-0.44224958 29.84362635], action: [-0.29741234 -0.167     ]\n",
      "Episode: 1530/3000, Reward: -1930.2222804883681, done: False\n",
      "state: [-0.44213001 29.8046255 ], action: [-0.2832164 -0.167    ]\n",
      "Episode: 1531/3000, Reward: -1927.216364593233, done: False\n",
      "state: [-0.44155826 29.71653054], action: [-0.2989242 -0.167    ]\n",
      "Episode: 1532/3000, Reward: -1921.3749654700978, done: False\n",
      "state: [-0.44121021 29.63047358], action: [-0.31368774 -0.167     ]\n",
      "Episode: 1533/3000, Reward: -1913.0039041583127, done: False\n",
      "state: [-0.44056215 29.56526454], action: [-0.30678925 -0.167     ]\n",
      "Episode: 1534/3000, Reward: -1903.396270831034, done: False\n",
      "state: [-0.44017983 29.47706374], action: [-0.28420907 -0.167     ]\n",
      "Episode: 1535/3000, Reward: -1892.0981494530804, done: False\n",
      "state: [-0.43969805 29.4022235 ], action: [-0.31148833 -0.167     ]\n",
      "Episode: 1536/3000, Reward: -1891.1625953714154, done: False\n",
      "state: [-0.43907356 29.31826426], action: [-0.3208031 -0.167    ]\n",
      "Episode: 1537/3000, Reward: -1878.2806654330814, done: False\n",
      "state: [-0.4382821  29.23045009], action: [-0.2489804 -0.167    ]\n",
      "Episode: 1538/3000, Reward: -1872.4435408974336, done: False\n",
      "state: [-0.43788162 29.14645408], action: [-0.27845868 -0.167     ]\n",
      "Episode: 1539/3000, Reward: -1860.4385272273587, done: False\n",
      "state: [-0.43768641 29.07654038], action: [-0.29343268 -0.167     ]\n",
      "Episode: 1540/3000, Reward: -1856.6010118320714, done: False\n",
      "state: [-0.43685349 28.98986722], action: [-0.2983405 -0.167    ]\n",
      "Episode: 1541/3000, Reward: -1849.5192431928047, done: False\n",
      "state: [-0.43660553 28.92073242], action: [-0.2702784 -0.167    ]\n",
      "Episode: 1542/3000, Reward: -1848.2541781149193, done: False\n",
      "state: [-0.43601705 28.83573771], action: [-0.26744723 -0.167     ]\n",
      "Episode: 1543/3000, Reward: -1835.6946486788938, done: False\n",
      "state: [-0.43527762 28.72745925], action: [-0.29791299 -0.167     ]\n",
      "Episode: 1544/3000, Reward: -1827.571044193322, done: False\n",
      "state: [-0.43449278 28.62196428], action: [-0.27778292 -0.167     ]\n",
      "Episode: 1545/3000, Reward: -1814.927999736353, done: False\n",
      "state: [-0.43375438 28.48797802], action: [-0.28480157 -0.167     ]\n",
      "Episode: 1546/3000, Reward: -1803.6427937417768, done: False\n",
      "state: [-0.4329139  28.35083528], action: [-0.2811098 -0.167    ]\n",
      "Episode: 1547/3000, Reward: -1788.818706597439, done: False\n",
      "state: [-0.43209539 28.24863119], action: [-0.26816255 -0.167     ]\n",
      "Episode: 1548/3000, Reward: -1778.0199155340874, done: False\n",
      "state: [-0.43196223 28.21280764], action: [-0.3539271 -0.167    ]\n",
      "Episode: 1549/3000, Reward: -1770.983412510678, done: False\n",
      "state: [-0.43162963 28.06899108], action: [-0.22372778 -0.167     ]\n",
      "Episode: 1550/3000, Reward: -1767.2841578592722, done: False\n",
      "state: [-0.42775979 28.03008123], action: [ 0.31240368 -0.93899715]\n",
      "Episode: 1551/3000, Reward: -1756.3111596832566, done: False\n",
      "state: [-0.43004734 27.92003271], action: [-0.33162913 -0.167     ]\n",
      "Episode: 1552/3000, Reward: -1747.5170811823227, done: False\n",
      "state: [-0.42957657 27.85808087], action: [-0.29034433 -0.167     ]\n",
      "Episode: 1553/3000, Reward: -1738.690787555544, done: False\n",
      "state: [-0.43047013 27.86927708], action: [-0.30983055 -0.167     ]\n",
      "Episode: 1554/3000, Reward: -1730.5400320734248, done: False\n",
      "state: [-0.42837727 27.68340023], action: [-0.29437718 -0.167     ]\n",
      "Episode: 1555/3000, Reward: -1716.8028644931053, done: False\n",
      "state: [-0.42792655 27.61861006], action: [-0.27433294 -0.167     ]\n",
      "Episode: 1556/3000, Reward: -1709.529707560034, done: False\n",
      "state: [-0.42745931 27.5124235 ], action: [-0.24888378 -0.167     ]\n",
      "Episode: 1557/3000, Reward: -1703.8433664167994, done: False\n",
      "state: [-0.42690633 27.45208998], action: [-0.28810713 -0.167     ]\n",
      "Episode: 1558/3000, Reward: -1694.8107213085545, done: False\n",
      "state: [-0.42613356 27.37012073], action: [-0.28221962 -0.167     ]\n",
      "Episode: 1559/3000, Reward: -1676.936340723922, done: False\n",
      "state: [-0.42559176 27.27534101], action: [-0.29583982 -0.167     ]\n",
      "Episode: 1560/3000, Reward: -1680.324581336135, done: False\n",
      "state: [-0.42516965 27.21135327], action: [-0.2972524 -0.167    ]\n",
      "Episode: 1561/3000, Reward: -1668.0244849758267, done: False\n",
      "state: [-0.42476848 27.13176697], action: [-0.29848298 -0.167     ]\n",
      "Episode: 1562/3000, Reward: -1662.4599542436779, done: False\n",
      "state: [-0.42412627 27.05169405], action: [-0.28119412 -0.167     ]\n",
      "Episode: 1563/3000, Reward: -1651.7503388731366, done: False\n",
      "state: [-0.42280311 26.98527635], action: [-0.4086537 -0.167    ]\n",
      "Episode: 1564/3000, Reward: -1626.6310607576443, done: False\n",
      "state: [-0.42273078 26.88649017], action: [-0.27644113 -0.167     ]\n",
      "Episode: 1565/3000, Reward: -1636.8123298420014, done: False\n",
      "state: [-0.42205207 26.79998578], action: [-0.27303076 -0.167     ]\n",
      "Episode: 1566/3000, Reward: -1623.429374256531, done: False\n",
      "state: [-0.42178069 26.72623595], action: [-0.3139044 -0.167    ]\n",
      "Episode: 1567/3000, Reward: -1622.844450467823, done: False\n",
      "state: [-0.42120108 26.65205695], action: [-0.27065316 -0.167     ]\n",
      "Episode: 1568/3000, Reward: -1612.3562061437622, done: False\n",
      "state: [-0.41531891 26.5622753 ], action: [0.76289034 0.13078736]\n",
      "Episode: 1569/3000, Reward: -1608.2481837671276, done: False\n",
      "state: [-0.4200774  26.49588592], action: [-0.29009977 -0.167     ]\n",
      "Episode: 1570/3000, Reward: -1585.7388690454206, done: False\n",
      "state: [-0.41962786 26.43707792], action: [-0.26528537 -0.167     ]\n",
      "Episode: 1571/3000, Reward: -1589.0389790138563, done: False\n",
      "state: [-0.41889167 26.34173778], action: [-0.27709278 -0.167     ]\n",
      "Episode: 1572/3000, Reward: -1584.3565393957902, done: False\n",
      "state: [-0.41825182 26.26127182], action: [-0.28577572 -0.167     ]\n",
      "Episode: 1573/3000, Reward: -1576.7199556753033, done: False\n",
      "state: [-0.41791101 26.19852254], action: [-0.299407 -0.167   ]\n",
      "Episode: 1574/3000, Reward: -1570.3947367238977, done: False\n",
      "state: [-0.41727526 26.11421239], action: [-0.30493933 -0.167     ]\n",
      "Episode: 1575/3000, Reward: -1563.4358934233567, done: False\n",
      "state: [-0.41672184 26.0447618 ], action: [-0.28411087 -0.167     ]\n",
      "Episode: 1576/3000, Reward: -1552.4740034075783, done: False\n",
      "state: [-0.41598881 25.95808359], action: [-0.27902162 -0.167     ]\n",
      "Episode: 1577/3000, Reward: -1548.3136676411307, done: False\n",
      "state: [-0.41407866 25.94220607], action: [-0.50346696 -0.167     ]\n",
      "Episode: 1578/3000, Reward: -1542.691931607899, done: False\n",
      "state: [-0.41449043 25.86019702], action: [-0.3859007 -0.167    ]\n",
      "Episode: 1579/3000, Reward: -1539.2738465855753, done: False\n",
      "state: [-0.41451594 25.75948291], action: [-0.28320938 -0.167     ]\n",
      "Episode: 1580/3000, Reward: -1527.2260612472978, done: False\n",
      "state: [-0.41410135 25.68478415], action: [-0.30736625 -0.167     ]\n",
      "Episode: 1581/3000, Reward: -1521.6044758481564, done: False\n",
      "state: [-0.41351878 25.60742695], action: [-0.2862836 -0.167    ]\n",
      "Episode: 1582/3000, Reward: -1517.665518928176, done: False\n",
      "state: [-0.41294196 25.53259326], action: [-0.29239693 -0.167     ]\n",
      "Episode: 1583/3000, Reward: -1514.9826578112938, done: False\n",
      "state: [-0.41240147 25.46692833], action: [-0.28125736 -0.167     ]\n",
      "Episode: 1584/3000, Reward: -1504.870685789776, done: False\n",
      "state: [-0.41180436 25.39752191], action: [-0.28839046 -0.167     ]\n",
      "Episode: 1585/3000, Reward: -1500.4134548407512, done: False\n",
      "state: [-0.41099126 25.31364308], action: [-0.27906382 -0.167     ]\n",
      "Episode: 1586/3000, Reward: -1495.8054515495348, done: False\n",
      "state: [-0.41084945 25.25704872], action: [-0.28473496 -0.167     ]\n",
      "Episode: 1587/3000, Reward: -1487.662097483425, done: False\n",
      "state: [-0.41009036 25.18727646], action: [-0.25949198 -0.167     ]\n",
      "Episode: 1588/3000, Reward: -1483.5411475318679, done: False\n",
      "state: [-0.40955753 25.11218902], action: [-0.29280156 -0.167     ]\n",
      "Episode: 1589/3000, Reward: -1477.471510515697, done: False\n",
      "state: [-0.40924139 25.05491865], action: [-0.29729062 -0.167     ]\n",
      "Episode: 1590/3000, Reward: -1468.8603926444325, done: False\n",
      "state: [-0.40855512 24.97089566], action: [-0.28403723 -0.167     ]\n",
      "Episode: 1591/3000, Reward: -1464.9612502890338, done: False\n",
      "state: [-0.40804624 24.90109894], action: [-0.28999147 -0.167     ]\n",
      "Episode: 1592/3000, Reward: -1456.9948070056728, done: False\n",
      "state: [-0.40757764 24.84323185], action: [-0.27166396 -0.167     ]\n",
      "Episode: 1593/3000, Reward: -1443.0327393597413, done: False\n",
      "state: [-0.40691279 24.7674471 ], action: [-0.2780575 -0.167    ]\n",
      "Episode: 1594/3000, Reward: -1445.8476551648894, done: False\n",
      "state: [-0.40640583 24.70016751], action: [-0.2716887 -0.167    ]\n",
      "Episode: 1595/3000, Reward: -1435.2273054583661, done: False\n",
      "state: [-0.40592386 24.6306914 ], action: [-0.2873059 -0.167    ]\n",
      "Episode: 1596/3000, Reward: -1431.7316291279528, done: False\n",
      "state: [-0.40549425 24.57481726], action: [-0.27573633 -0.167     ]\n",
      "Episode: 1597/3000, Reward: -1427.5016569114282, done: False\n",
      "state: [-0.40473341 24.50076142], action: [-0.29002643 -0.167     ]\n",
      "Episode: 1598/3000, Reward: -1421.588476984091, done: False\n",
      "state: [-0.40424861 24.44186106], action: [-0.24480718 -0.167     ]\n",
      "Episode: 1599/3000, Reward: -1419.4032386002837, done: False\n",
      "state: [-0.40376145 24.37510424], action: [-0.2870749 -0.167    ]\n",
      "Episode: 1600/3000, Reward: -1408.6459472262525, done: False\n",
      "state: [-0.40313434 24.29042901], action: [-0.26609018 -0.167     ]\n",
      "Episode: 1601/3000, Reward: -1405.1214391046778, done: False\n",
      "state: [-0.40292636 24.2355305 ], action: [-0.29387537 -0.167     ]\n",
      "Episode: 1602/3000, Reward: -1394.274639861762, done: False\n",
      "state: [-0.40245668 24.19141636], action: [-0.28595787 -0.167     ]\n",
      "Episode: 1603/3000, Reward: -1392.6461682555291, done: False\n",
      "state: [-0.40236372 24.1463084 ], action: [-0.30839527 -0.167     ]\n",
      "Episode: 1604/3000, Reward: -1387.514053617695, done: False\n",
      "state: [-0.40039582 24.07151772], action: [-0.41954163 -0.167     ]\n",
      "Episode: 1605/3000, Reward: -1383.890455322363, done: False\n",
      "state: [-0.40036828 23.95563849], action: [-0.27801523 -0.167     ]\n",
      "Episode: 1606/3000, Reward: -1376.3549639590995, done: False\n",
      "state: [-0.399773   23.89710567], action: [-0.27432588 -0.167     ]\n",
      "Episode: 1607/3000, Reward: -1371.894986847799, done: False\n",
      "state: [-0.39861801 23.78632871], action: [-0.26401892 -0.167     ]\n",
      "Episode: 1608/3000, Reward: -1365.599529914895, done: False\n",
      "state: [-0.39881236 23.76025679], action: [-0.28619605 -0.167     ]\n",
      "Episode: 1609/3000, Reward: -1361.4559351928335, done: False\n",
      "state: [-0.39795438 23.68263805], action: [-0.27505946 -0.167     ]\n",
      "Episode: 1610/3000, Reward: -1350.6862116080158, done: False\n",
      "state: [-0.39843451 23.66893973], action: [-0.296334 -0.167   ]\n",
      "Episode: 1611/3000, Reward: -1347.480300461675, done: False\n",
      "state: [-0.39642273 23.56174161], action: [-0.32378742 -0.167     ]\n",
      "Episode: 1612/3000, Reward: -1340.522483039795, done: False\n",
      "state: [-0.39652868 23.49367879], action: [-0.30029228 -0.167     ]\n",
      "Episode: 1613/3000, Reward: -1339.869001463807, done: False\n",
      "state: [-0.39607526 23.43476656], action: [-0.27682862 -0.167     ]\n",
      "Episode: 1614/3000, Reward: -1332.6999393730748, done: False\n",
      "state: [-0.39566776 23.38491618], action: [-0.28851986 -0.167     ]\n",
      "Episode: 1615/3000, Reward: -1323.197106473254, done: False\n",
      "state: [-0.39473373 23.28003558], action: [-0.28819808 -0.167     ]\n",
      "Episode: 1616/3000, Reward: -1314.4960976057257, done: False\n",
      "state: [-0.39407168 23.19676758], action: [-0.27317902 -0.167     ]\n",
      "Episode: 1617/3000, Reward: -1310.8636624495812, done: False\n",
      "state: [-0.39364596 23.14827861], action: [-0.2828023 -0.167    ]\n",
      "Episode: 1618/3000, Reward: -1300.5215392103746, done: False\n",
      "state: [-0.3926852  23.05861186], action: [-0.29362094 -0.167     ]\n",
      "Episode: 1619/3000, Reward: -1296.3423456050625, done: False\n",
      "state: [-0.39233695 22.99771333], action: [-0.28625908 -0.167     ]\n",
      "Episode: 1620/3000, Reward: -1294.4725923498145, done: False\n",
      "state: [-0.39163618 22.9354948 ], action: [-0.27069914 -0.167     ]\n",
      "Episode: 1621/3000, Reward: -1287.901565580781, done: False\n",
      "state: [-0.39134116 22.8713685 ], action: [-0.2639302 -0.167    ]\n",
      "Episode: 1622/3000, Reward: -1278.2403771483048, done: False\n",
      "state: [-0.39025565 22.77317282], action: [-0.27866277 -0.167     ]\n",
      "Episode: 1623/3000, Reward: -1271.6606298523554, done: False\n",
      "state: [-0.38977016 22.69701834], action: [-0.2771632 -0.167    ]\n",
      "Episode: 1624/3000, Reward: -1267.9494416308216, done: False\n",
      "state: [-0.38885933 22.62358199], action: [-0.26124513 -0.167     ]\n",
      "Episode: 1625/3000, Reward: -1257.3300592324508, done: False\n",
      "state: [-0.38916453 22.59339931], action: [-0.29101136 -0.167     ]\n",
      "Episode: 1626/3000, Reward: -1254.3715121859705, done: False\n",
      "state: [-0.38758091 22.48168752], action: [-0.29849687 -0.167     ]\n",
      "Episode: 1627/3000, Reward: -1247.4473454882732, done: False\n",
      "state: [-0.38750195 22.41720387], action: [-0.28440893 -0.167     ]\n",
      "Episode: 1628/3000, Reward: -1238.826551607369, done: False\n",
      "state: [-0.38637807 22.32893221], action: [-0.26989645 -0.167     ]\n",
      "Episode: 1629/3000, Reward: -1233.3131790397879, done: False\n",
      "state: [-0.38554033 22.25847711], action: [-0.2548359 -0.167    ]\n",
      "Episode: 1630/3000, Reward: -1228.2061475002652, done: False\n",
      "state: [-0.38486779 22.17877879], action: [-0.2643028 -0.167    ]\n",
      "Episode: 1631/3000, Reward: -1223.8430484309215, done: False\n",
      "state: [-0.38437895 22.11179779], action: [-0.28401268 -0.167     ]\n",
      "Episode: 1632/3000, Reward: -1215.596841286195, done: False\n",
      "state: [-0.3838854  22.05378021], action: [-0.27283657 -0.167     ]\n",
      "Episode: 1633/3000, Reward: -1208.3254859087888, done: False\n",
      "state: [-0.38339938 21.99242535], action: [-0.27684623 -0.167     ]\n",
      "Episode: 1634/3000, Reward: -1204.5366973716605, done: False\n",
      "state: [-0.38235601 21.8986544 ], action: [-0.26579598 -0.167     ]\n",
      "Episode: 1635/3000, Reward: -1200.440338442907, done: False\n",
      "state: [-0.38192944 21.83978474], action: [-0.26713908 -0.167     ]\n",
      "Episode: 1636/3000, Reward: -1192.9904597887244, done: False\n",
      "state: [-0.38134777 21.76979772], action: [-0.27240223 -0.167     ]\n",
      "Episode: 1637/3000, Reward: -1188.2108544463429, done: False\n",
      "state: [-0.38056481 21.70277681], action: [-0.29083326 -0.167     ]\n",
      "Episode: 1638/3000, Reward: -1179.6125266064225, done: False\n",
      "state: [-0.38000105 21.64701981], action: [-0.2825426 -0.167    ]\n",
      "Episode: 1639/3000, Reward: -1176.6138907701259, done: False\n",
      "state: [-0.37938904 21.57596323], action: [-0.27122933 -0.167     ]\n",
      "Episode: 1640/3000, Reward: -1172.5089740433348, done: False\n",
      "state: [-0.3801105  21.50831015], action: [-0.5125374   0.02704177]\n",
      "Episode: 1641/3000, Reward: -1165.7436264025355, done: False\n",
      "state: [-0.37863887 21.45625932], action: [-0.25751275 -0.167     ]\n",
      "Episode: 1642/3000, Reward: -1161.8590654488632, done: False\n",
      "state: [-0.37782387 21.38347028], action: [-0.2787859 -0.167    ]\n",
      "Episode: 1643/3000, Reward: -1156.9033342485516, done: False\n",
      "state: [-0.37714647 21.32029169], action: [-0.27023244 -0.167     ]\n",
      "Episode: 1644/3000, Reward: -1151.1620643897882, done: False\n",
      "state: [-0.37644836 21.26117498], action: [-0.27327433 -0.167     ]\n",
      "Episode: 1645/3000, Reward: -1143.9904288952298, done: False\n",
      "state: [-0.37607264 21.2130982 ], action: [-0.24082254 -0.167     ]\n",
      "Episode: 1646/3000, Reward: -1139.9773346695615, done: False\n",
      "state: [-0.3762844  21.18835923], action: [-0.26280835 -0.167     ]\n",
      "Episode: 1647/3000, Reward: -1137.5203813004232, done: False\n",
      "state: [-0.37460046 21.07505249], action: [-0.2700238 -0.167    ]\n",
      "Episode: 1648/3000, Reward: -1132.028903885518, done: False\n",
      "state: [-0.37396843 21.01733975], action: [-0.2601216 -0.167    ]\n",
      "Episode: 1649/3000, Reward: -1128.0771432103936, done: False\n",
      "state: [-0.37431976 20.99406804], action: [-0.28344443 -0.167     ]\n",
      "Episode: 1650/3000, Reward: -1124.2041444430517, done: False\n",
      "state: [-0.37325766 20.9187805 ], action: [-0.2734755 -0.167    ]\n",
      "Episode: 1651/3000, Reward: -1117.7199199423164, done: False\n",
      "state: [-0.37266673 20.85908527], action: [-0.27497482 -0.167     ]\n",
      "Episode: 1652/3000, Reward: -1114.1607565098932, done: False\n",
      "state: [-0.37209    20.79778723], action: [-0.27010512 -0.167     ]\n",
      "Episode: 1653/3000, Reward: -1107.7719323788856, done: False\n",
      "state: [-0.37126398 20.72330417], action: [-0.23540695 -0.167     ]\n",
      "Episode: 1654/3000, Reward: -1104.1812578828215, done: False\n",
      "state: [-0.37058788 20.65552973], action: [-0.26900142 -0.167     ]\n",
      "Episode: 1655/3000, Reward: -1098.4906932036497, done: False\n",
      "state: [-0.36998636 20.58726905], action: [-0.2622152 -0.167    ]\n",
      "Episode: 1656/3000, Reward: -1090.796123722931, done: False\n",
      "state: [-0.36924551 20.51616179], action: [-0.262201 -0.167   ]\n",
      "Episode: 1657/3000, Reward: -1087.9573170573935, done: False\n",
      "state: [-0.36882392 20.46416559], action: [-0.2635149 -0.167    ]\n",
      "Episode: 1658/3000, Reward: -1081.806324020049, done: False\n",
      "state: [-0.36846191 20.40545345], action: [-0.25438643 -0.167     ]\n",
      "Episode: 1659/3000, Reward: -1073.119998237188, done: False\n",
      "state: [-0.36707497 20.31635095], action: [-0.25823918 -0.167     ]\n",
      "Episode: 1660/3000, Reward: -1067.3560638200506, done: False\n",
      "state: [-0.36669197 20.26401514], action: [-0.24799256 -0.167     ]\n",
      "Episode: 1661/3000, Reward: -1065.458804532371, done: False\n",
      "state: [-0.36601211 20.18696017], action: [-0.23181486 -0.167     ]\n",
      "Episode: 1662/3000, Reward: -1055.974355462738, done: False\n",
      "state: [-0.36476125 20.09035962], action: [-0.25415808 -0.167     ]\n",
      "Episode: 1663/3000, Reward: -1049.799342057441, done: False\n",
      "state: [-0.36438686 20.03047551], action: [-0.2628865 -0.167    ]\n",
      "Episode: 1664/3000, Reward: -1040.5847185826203, done: False\n",
      "state: [-0.36294691 19.91756638], action: [-0.27029607 -0.167     ]\n",
      "Episode: 1665/3000, Reward: -1030.4215798481812, done: False\n",
      "state: [-0.36285863 19.85993223], action: [-0.2842862 -0.167    ]\n",
      "Episode: 1666/3000, Reward: -1027.2524750887076, done: False\n",
      "state: [-0.36196287 19.79128815], action: [-0.27185827 -0.167     ]\n",
      "Episode: 1667/3000, Reward: -1018.6564891468, done: False\n",
      "state: [-0.36144577 19.71780334], action: [-0.24705076 -0.167     ]\n",
      "Episode: 1668/3000, Reward: -1009.2063017404274, done: False\n",
      "state: [-0.3602785  19.63230223], action: [-0.25185865 -0.167     ]\n",
      "Episode: 1669/3000, Reward: -999.2974000804156, done: False\n",
      "state: [-0.35968898 19.56562921], action: [-0.27558124 -0.167     ]\n",
      "Episode: 1670/3000, Reward: -993.8896301373298, done: False\n",
      "state: [-0.35953305 19.50457827], action: [-0.23727259 -0.167     ]\n",
      "Episode: 1671/3000, Reward: -993.9056841795264, done: False\n",
      "state: [-0.35810214 19.41776664], action: [-0.25412595 -0.167     ]\n",
      "Episode: 1672/3000, Reward: -984.0762793568373, done: False\n",
      "state: [-0.35728253 19.35134876], action: [-0.25757685 -0.167     ]\n",
      "Episode: 1673/3000, Reward: -978.0668365831247, done: False\n",
      "state: [-0.35688442 19.30872268], action: [-0.25639403 -0.167     ]\n",
      "Episode: 1674/3000, Reward: -974.78192296153, done: False\n",
      "state: [-0.35672529 19.27468314], action: [-0.27268827 -0.167     ]\n",
      "Episode: 1675/3000, Reward: -971.6451437292003, done: False\n",
      "state: [-0.35613984 19.22332867], action: [-0.28055462 -0.167     ]\n",
      "Episode: 1676/3000, Reward: -971.1844092212187, done: False\n",
      "state: [-0.35542947 19.2053071 ], action: [-0.30407408 -0.167     ]\n",
      "Episode: 1677/3000, Reward: -969.3055154070631, done: False\n",
      "state: [-0.35524081 19.1492908 ], action: [-0.27699417 -0.167     ]\n",
      "Episode: 1678/3000, Reward: -966.54575999245, done: False\n",
      "state: [-0.35494882 19.11357509], action: [-0.2504898 -0.167    ]\n",
      "Episode: 1679/3000, Reward: -963.8457331066403, done: False\n",
      "state: [-0.3546195  19.07395787], action: [-0.26623905 -0.167     ]\n",
      "Episode: 1680/3000, Reward: -959.9731691428221, done: False\n",
      "state: [-0.35417085 19.04026336], action: [-0.26899078 -0.167     ]\n",
      "Episode: 1681/3000, Reward: -962.9817504653918, done: False\n",
      "state: [-0.35372069 19.00905235], action: [-0.23947093 -0.167     ]\n",
      "Episode: 1682/3000, Reward: -961.5942995559489, done: False\n",
      "state: [-0.35337393 18.9809813 ], action: [-0.2566898 -0.167    ]\n",
      "Episode: 1683/3000, Reward: -956.278773145174, done: False\n",
      "state: [-0.35327726 18.96405893], action: [-0.2627977 -0.167    ]\n",
      "Episode: 1684/3000, Reward: -957.8587589093039, done: False\n",
      "state: [-0.35287926 18.9356757 ], action: [-0.27246934 -0.167     ]\n",
      "Episode: 1685/3000, Reward: -958.1862265592632, done: False\n",
      "state: [-0.35284119 18.92266451], action: [-0.2613198 -0.167    ]\n",
      "Episode: 1686/3000, Reward: -954.6625544396811, done: False\n",
      "state: [-0.35312128 18.92685693], action: [-0.26041323 -0.167     ]\n",
      "Episode: 1687/3000, Reward: -954.571685435222, done: False\n",
      "state: [-0.35256783 18.89501574], action: [-0.25866637 -0.167     ]\n",
      "Episode: 1688/3000, Reward: -955.420493260045, done: False\n",
      "state: [-0.3531989  18.91428477], action: [-0.25740588 -0.167     ]\n",
      "Episode: 1689/3000, Reward: -957.0065088414275, done: False\n",
      "state: [-0.35211691 18.85916488], action: [-0.2694543 -0.167    ]\n",
      "Episode: 1690/3000, Reward: -952.5173197286579, done: False\n",
      "state: [-0.35214628 18.85482262], action: [-0.2625349 -0.167    ]\n",
      "Episode: 1691/3000, Reward: -953.9717923031169, done: False\n",
      "state: [-0.35169915 18.82303883], action: [-0.26018208 -0.167     ]\n",
      "Episode: 1692/3000, Reward: -946.6581166327247, done: False\n",
      "state: [-0.35134642 18.79451121], action: [-0.245155 -0.167   ]\n",
      "Episode: 1693/3000, Reward: -948.0510950847702, done: False\n",
      "state: [-0.35110814 18.77391473], action: [-0.24771328 -0.167     ]\n",
      "Episode: 1694/3000, Reward: -949.0734931056896, done: False\n",
      "state: [-0.34666545 18.78228595], action: [-0.5584151 -0.167    ]\n",
      "Episode: 1695/3000, Reward: -951.5946447490574, done: False\n",
      "state: [-0.35119165 18.75474737], action: [-0.27171695 -0.167     ]\n",
      "Episode: 1696/3000, Reward: -948.1913903064285, done: False\n",
      "state: [-0.35066309 18.72827388], action: [-0.24242097 -0.167     ]\n",
      "Episode: 1697/3000, Reward: -950.8162660656652, done: False\n",
      "state: [-0.35079749 18.72825818], action: [-0.24295229 -0.167     ]\n",
      "Episode: 1698/3000, Reward: -948.7241678094434, done: False\n",
      "state: [-0.34996764 18.67909719], action: [-0.26062658 -0.167     ]\n",
      "Episode: 1699/3000, Reward: -943.920203415296, done: False\n",
      "state: [-0.35072295 18.69582472], action: [-0.2534514 -0.167    ]\n",
      "Episode: 1700/3000, Reward: -945.4720190976673, done: False\n",
      "state: [-0.34992737 18.69430366], action: [-0.31681755 -0.167     ]\n",
      "Episode: 1701/3000, Reward: -948.1240147282797, done: False\n",
      "state: [-0.35033453 18.66294893], action: [-0.26218325 -0.167     ]\n",
      "Episode: 1702/3000, Reward: -950.616171572563, done: False\n",
      "state: [-0.34989255 18.64738893], action: [-0.262201 -0.167   ]\n",
      "Episode: 1703/3000, Reward: -946.0983108858234, done: False\n",
      "state: [-0.35002431 18.64194983], action: [-0.26520026 -0.167     ]\n",
      "Episode: 1704/3000, Reward: -947.2725804909221, done: False\n",
      "state: [-0.34991809 18.64700259], action: [-0.28136978 -0.167     ]\n",
      "Episode: 1705/3000, Reward: -946.0587485954181, done: False\n",
      "state: [-0.3493372  18.60146024], action: [-0.2721338 -0.167    ]\n",
      "Episode: 1706/3000, Reward: -945.3732447960482, done: False\n",
      "state: [-0.34930231 18.60213277], action: [-0.24069317 -0.167     ]\n",
      "Episode: 1707/3000, Reward: -942.7475325211905, done: False\n",
      "state: [-0.34898244 18.57644742], action: [-0.24474622 -0.167     ]\n",
      "Episode: 1708/3000, Reward: -944.2125168599225, done: False\n",
      "state: [-0.34887094 18.57175874], action: [-0.27005914 -0.167     ]\n",
      "Episode: 1709/3000, Reward: -939.7652595415587, done: False\n",
      "state: [-0.34849408 18.54376899], action: [-0.2521766 -0.167    ]\n",
      "Episode: 1710/3000, Reward: -937.0033604522599, done: False\n",
      "state: [-0.34867246 18.53654756], action: [-0.25472176 -0.167     ]\n",
      "Episode: 1711/3000, Reward: -936.9072937051733, done: False\n",
      "state: [-0.34845778 18.4988912 ], action: [-0.24346912 -0.167     ]\n",
      "Episode: 1712/3000, Reward: -933.6685447876129, done: False\n",
      "state: [-0.34845098 18.49603071], action: [-0.2690368 -0.167    ]\n",
      "Episode: 1713/3000, Reward: -928.9155832274514, done: False\n",
      "state: [-0.34775916 18.45622565], action: [-0.24952064 -0.167     ]\n",
      "Episode: 1714/3000, Reward: -927.2461688285248, done: False\n",
      "state: [-0.34754649 18.43953432], action: [-0.26269117 -0.167     ]\n",
      "Episode: 1715/3000, Reward: -924.1585178816642, done: False\n",
      "state: [-0.34736027 18.41772764], action: [-0.25129765 -0.167     ]\n",
      "Episode: 1716/3000, Reward: -917.6883178056297, done: False\n",
      "state: [-0.34704432 18.39024403], action: [-0.26927388 -0.167     ]\n",
      "Episode: 1717/3000, Reward: -918.3115483981996, done: False\n",
      "state: [-0.34678801 18.3753864 ], action: [-0.2425215 -0.167    ]\n",
      "Episode: 1718/3000, Reward: -918.9791204703552, done: False\n",
      "state: [-0.3465718  18.34587553], action: [-0.24569274 -0.167     ]\n",
      "Episode: 1719/3000, Reward: -913.1752311550259, done: False\n",
      "state: [-0.3463514 18.3342099], action: [-0.26010028 -0.167     ]\n",
      "Episode: 1720/3000, Reward: -909.9644191885141, done: False\n",
      "state: [-0.34653003 18.32307424], action: [-0.24919866 -0.167     ]\n",
      "Episode: 1721/3000, Reward: -909.8125591125366, done: False\n",
      "state: [-0.34587991 18.2853685 ], action: [-0.25616592 -0.167     ]\n",
      "Episode: 1722/3000, Reward: -903.7829360846578, done: False\n",
      "state: [-0.34560958 18.26251338], action: [-0.25186223 -0.167     ]\n",
      "Episode: 1723/3000, Reward: -901.6009593467627, done: False\n",
      "state: [-0.34624624 18.26232612], action: [-0.22915278 -0.167     ]\n",
      "Episode: 1724/3000, Reward: -901.7764415112119, done: False\n",
      "state: [-0.34311544 18.23023442], action: [0.17568658 0.82141143]\n",
      "Episode: 1725/3000, Reward: -900.6823598789631, done: False\n",
      "state: [-0.34519486 18.22120174], action: [-0.2586842 -0.167    ]\n",
      "Episode: 1726/3000, Reward: -897.5342259053984, done: False\n",
      "state: [-0.34478083 18.19216908], action: [-0.2541188 -0.167    ]\n",
      "Episode: 1727/3000, Reward: -894.2520144384112, done: False\n",
      "state: [-0.34454263 18.17663559], action: [-0.24570708 -0.167     ]\n",
      "Episode: 1728/3000, Reward: -896.8169668163417, done: False\n",
      "state: [-0.34452143 18.15740146], action: [-0.2545327 -0.167    ]\n",
      "Episode: 1729/3000, Reward: -891.8157813158078, done: False\n",
      "state: [-0.34427686 18.14938284], action: [-0.25431862 -0.167     ]\n",
      "Episode: 1730/3000, Reward: -885.6871243727572, done: False\n",
      "state: [-0.34391393 18.11180976], action: [-0.2583567 -0.167    ]\n",
      "Episode: 1731/3000, Reward: -879.637385165384, done: False\n",
      "state: [-0.34352121 18.06853112], action: [-0.2225606 -0.167    ]\n",
      "Episode: 1732/3000, Reward: -879.8684274588477, done: False\n",
      "state: [-0.34332173 18.06393447], action: [-0.24534862 -0.167     ]\n",
      "Episode: 1733/3000, Reward: -883.5893134287061, done: False\n",
      "state: [-0.34316619 18.04244235], action: [-0.25396892 -0.167     ]\n",
      "Episode: 1734/3000, Reward: -878.5237628301577, done: False\n",
      "state: [-0.34304781 18.02924759], action: [-0.25726697 -0.167     ]\n",
      "Episode: 1735/3000, Reward: -880.5449936104061, done: False\n",
      "state: [-0.34274632 18.00700326], action: [-0.24283384 -0.167     ]\n",
      "Episode: 1736/3000, Reward: -879.025578586065, done: False\n",
      "state: [-0.34297518 18.00236446], action: [-0.24519086 -0.167     ]\n",
      "Episode: 1737/3000, Reward: -875.5582671544719, done: False\n",
      "state: [-0.34233677 17.9715235 ], action: [-0.24841496 -0.167     ]\n",
      "Episode: 1738/3000, Reward: -870.8737169709951, done: False\n",
      "state: [-0.34195172 17.94387459], action: [-0.26538822 -0.167     ]\n",
      "Episode: 1739/3000, Reward: -865.0240382243888, done: False\n",
      "state: [-0.34183107 17.93228947], action: [-0.25253022 -0.167     ]\n",
      "Episode: 1740/3000, Reward: -862.3459000891384, done: False\n",
      "state: [-0.34187896 17.96743033], action: [-0.3428365 -0.167    ]\n",
      "Episode: 1741/3000, Reward: -867.3032219441099, done: False\n",
      "state: [-0.34133719 17.88692018], action: [-0.24854381 -0.167     ]\n",
      "Episode: 1742/3000, Reward: -866.8984872521545, done: False\n",
      "state: [-0.3410886  17.87064997], action: [-0.2576267 -0.167    ]\n",
      "Episode: 1743/3000, Reward: -863.49961187848, done: False\n",
      "state: [-0.34091249 17.85097291], action: [-0.25954178 -0.167     ]\n",
      "Episode: 1744/3000, Reward: -861.3223772078379, done: False\n",
      "state: [-0.34072406 17.82911387], action: [-0.24687882 -0.167     ]\n",
      "Episode: 1745/3000, Reward: -858.3091329991036, done: False\n",
      "state: [-0.34058486 17.80995657], action: [-0.26654738 -0.167     ]\n",
      "Episode: 1746/3000, Reward: -858.8343689029227, done: False\n",
      "state: [-0.34029554 17.78741149], action: [-0.24764526 -0.167     ]\n",
      "Episode: 1747/3000, Reward: -851.303698637889, done: False\n",
      "state: [-0.33991534 17.76415779], action: [-0.24578953 -0.167     ]\n",
      "Episode: 1748/3000, Reward: -849.3095711826959, done: False\n",
      "state: [-0.33995902 17.76010648], action: [-0.24638084 -0.167     ]\n",
      "Episode: 1749/3000, Reward: -850.3385745770992, done: False\n",
      "state: [-0.33995962 17.73853932], action: [-0.25966632 -0.167     ]\n",
      "Episode: 1750/3000, Reward: -844.5247953018061, done: False\n",
      "state: [-0.33906732 17.69631859], action: [-0.26885632 -0.167     ]\n",
      "Episode: 1751/3000, Reward: -843.92993790793, done: False\n",
      "state: [-0.33904947 17.68445817], action: [-0.24050269 -0.167     ]\n",
      "Episode: 1752/3000, Reward: -840.4853845506306, done: False\n",
      "state: [-0.33946167 17.68972634], action: [-0.26572505 -0.167     ]\n",
      "Episode: 1753/3000, Reward: -841.2661489885448, done: False\n",
      "state: [-0.34029562 17.6374402 ], action: [-0.12874815 -0.167     ]\n",
      "Episode: 1754/3000, Reward: -836.2727329499519, done: False\n",
      "state: [-0.33831463 17.62517124], action: [-0.24850087 -0.167     ]\n",
      "Episode: 1755/3000, Reward: -835.1978959625395, done: False\n",
      "state: [-0.33821956 17.6019223 ], action: [-0.25907212 -0.167     ]\n",
      "Episode: 1756/3000, Reward: -834.6354976699989, done: False\n",
      "state: [-0.33830268 17.59731673], action: [-0.24121419 -0.167     ]\n",
      "Episode: 1757/3000, Reward: -831.9355750726978, done: False\n",
      "state: [-0.33780451 17.57488176], action: [-0.24946341 -0.167     ]\n",
      "Episode: 1758/3000, Reward: -830.3783859631251, done: False\n",
      "state: [-0.33749178 17.55114691], action: [-0.25176218 -0.167     ]\n",
      "Episode: 1759/3000, Reward: -829.3036492100725, done: False\n",
      "state: [-0.33737852 17.53783072], action: [-0.24705793 -0.167     ]\n",
      "Episode: 1760/3000, Reward: -822.8039436113692, done: False\n",
      "state: [-0.336961   17.50886667], action: [-0.23502856 -0.167     ]\n",
      "Episode: 1761/3000, Reward: -821.6012041648837, done: False\n",
      "state: [-0.33679401 17.49005409], action: [-0.24025828 -0.167     ]\n",
      "Episode: 1762/3000, Reward: -819.7076486779082, done: False\n",
      "state: [-0.33557933 17.48126437], action: [-0.3276475 -0.167    ]\n",
      "Episode: 1763/3000, Reward: -819.1788527001503, done: False\n",
      "state: [-0.33635001 17.45346442], action: [-0.2566007 -0.167    ]\n",
      "Episode: 1764/3000, Reward: -816.7227111070598, done: False\n",
      "state: [-0.33707467 17.45918895], action: [-0.24027984 -0.167     ]\n",
      "Episode: 1765/3000, Reward: -813.1689264884435, done: False\n",
      "state: [-0.33594189 17.41580297], action: [-0.24563181 -0.167     ]\n",
      "Episode: 1766/3000, Reward: -808.8155162634976, done: False\n",
      "state: [-0.33558005 17.39066824], action: [-0.23776571 -0.167     ]\n",
      "Episode: 1767/3000, Reward: -805.1235694927134, done: False\n",
      "state: [-0.33510194 17.36500058], action: [-0.24295588 -0.167     ]\n",
      "Episode: 1768/3000, Reward: -802.0802250435648, done: False\n",
      "state: [-0.33609768 17.37108564], action: [-0.22690342 -0.167     ]\n",
      "Episode: 1769/3000, Reward: -803.4717463991327, done: False\n",
      "state: [-0.33599548 17.40382233], action: [-0.2994313 -0.167    ]\n",
      "Episode: 1770/3000, Reward: -796.9811084082156, done: False\n",
      "state: [-0.33517216 17.32197807], action: [-0.2519444 -0.167    ]\n",
      "Episode: 1771/3000, Reward: -792.2574203768027, done: False\n",
      "state: [-0.3367369  17.32005473], action: [-0.5017187  0.7558305]\n",
      "Episode: 1772/3000, Reward: -794.0362767344456, done: False\n",
      "state: [-0.33405505 17.27948143], action: [-0.26268762 -0.167     ]\n",
      "Episode: 1773/3000, Reward: -793.3510258039622, done: False\n",
      "state: [-0.33407246 17.26081631], action: [-0.24764168 -0.167     ]\n",
      "Episode: 1774/3000, Reward: -790.503191808408, done: False\n",
      "state: [-0.33394794 17.23760788], action: [-0.2564368 -0.167    ]\n",
      "Episode: 1775/3000, Reward: -787.0553713289208, done: False\n",
      "state: [-0.33374677 17.22144251], action: [-0.24987474 -0.167     ]\n",
      "Episode: 1776/3000, Reward: -787.2156837315345, done: False\n",
      "state: [-0.33358848 17.21082812], action: [-0.25200155 -0.167     ]\n",
      "Episode: 1777/3000, Reward: -785.9313909277344, done: False\n",
      "state: [-0.3333816  17.18950222], action: [-0.24857602 -0.167     ]\n",
      "Episode: 1778/3000, Reward: -781.6263472657337, done: False\n",
      "state: [-0.33303889 17.16974712], action: [-0.23051856 -0.167     ]\n",
      "Episode: 1779/3000, Reward: -779.7957553798859, done: False\n",
      "state: [-0.33368618 17.18998978], action: [-0.28972942 -0.167     ]\n",
      "Episode: 1780/3000, Reward: -776.4142380579184, done: False\n",
      "state: [-0.33266362 17.12749579], action: [-0.26412538 -0.167     ]\n",
      "Episode: 1781/3000, Reward: -776.7756397675196, done: False\n",
      "state: [-0.33246536 17.10855922], action: [-0.24831474 -0.167     ]\n",
      "Episode: 1782/3000, Reward: -770.7795474738825, done: False\n",
      "state: [-0.33195655 17.08176299], action: [-0.23269905 -0.167     ]\n",
      "Episode: 1783/3000, Reward: -766.2826796294609, done: False\n",
      "state: [-0.32756699 17.05480514], action: [ 0.60797   -0.2814286]\n",
      "Episode: 1784/3000, Reward: -763.357152306924, done: False\n",
      "state: [-0.33131965 17.0240073 ], action: [-0.24174583 -0.167     ]\n",
      "Episode: 1785/3000, Reward: -761.7630511021626, done: False\n",
      "state: [-0.33109694 16.99970404], action: [-0.2451586 -0.167    ]\n",
      "Episode: 1786/3000, Reward: -759.4085738118084, done: False\n",
      "state: [-0.33092158 16.97986008], action: [-0.26028877 -0.167     ]\n",
      "Episode: 1787/3000, Reward: -752.0443718171458, done: False\n",
      "state: [-0.33066303 16.96614465], action: [-0.2435696 -0.167    ]\n",
      "Episode: 1788/3000, Reward: -752.6546331097209, done: False\n",
      "state: [-0.33208296 16.9382631 ], action: [-0.15410793 -0.167     ]\n",
      "Episode: 1789/3000, Reward: -756.7694695800578, done: False\n",
      "state: [-0.33034021 16.93645154], action: [-0.2505756 -0.167    ]\n",
      "Episode: 1790/3000, Reward: -748.0739091302073, done: False\n",
      "state: [-0.3302684  16.92154751], action: [-0.22964789 -0.167     ]\n",
      "Episode: 1791/3000, Reward: -753.4738403632741, done: False\n",
      "state: [-0.32992668 16.90383607], action: [-0.25167644 -0.167     ]\n",
      "Episode: 1792/3000, Reward: -745.7533445564308, done: False\n",
      "state: [-0.32981229 16.8941145 ], action: [-0.24198647 -0.167     ]\n",
      "Episode: 1793/3000, Reward: -745.8930246638852, done: False\n",
      "state: [-0.32964494 16.87643854], action: [-0.23486277 -0.167     ]\n",
      "Episode: 1794/3000, Reward: -746.2446753471038, done: False\n",
      "state: [-0.32950881 16.86838471], action: [-0.2439607 -0.167    ]\n",
      "Episode: 1795/3000, Reward: -753.5579533821425, done: False\n",
      "state: [-0.32903335 16.89805911], action: [-0.32804927 -0.167     ]\n",
      "Episode: 1796/3000, Reward: -741.6956182121136, done: False\n",
      "state: [-0.32911996 16.84356595], action: [-0.23800324 -0.167     ]\n",
      "Episode: 1797/3000, Reward: -739.7583297677568, done: False\n",
      "state: [-0.32899014 16.83133785], action: [-0.2420978 -0.167    ]\n",
      "Episode: 1798/3000, Reward: -744.0166760650418, done: False\n",
      "state: [-0.33222904 16.82469058], action: [-0.921912   -0.87252957]\n",
      "Episode: 1799/3000, Reward: -739.02329743949, done: False\n",
      "state: [-0.32530872 16.84022953], action: [-0.43000546 -0.167     ]\n",
      "Episode: 1800/3000, Reward: -743.5761736046524, done: False\n",
      "state: [-0.32879218 16.8070396 ], action: [-0.26107097 -0.167     ]\n",
      "Episode: 1801/3000, Reward: -753.882138504487, done: False\n",
      "state: [-0.32867232 16.79755688], action: [-0.2530944 -0.167    ]\n",
      "Episode: 1802/3000, Reward: -741.7149766654175, done: False\n",
      "state: [-0.32962907 16.81486295], action: [-0.24215885 -0.167     ]\n",
      "Episode: 1803/3000, Reward: -738.0155787643264, done: False\n",
      "state: [-0.32843587 16.78154437], action: [-0.2518265 -0.167    ]\n",
      "Episode: 1804/3000, Reward: -743.1742913205959, done: False\n",
      "state: [-0.32843359 16.78011728], action: [-0.24319637 -0.167     ]\n",
      "Episode: 1805/3000, Reward: -756.7687067192967, done: False\n",
      "state: [-0.32842057 16.78339185], action: [-0.23445185 -0.167     ]\n",
      "Episode: 1806/3000, Reward: -764.0505545787851, done: False\n",
      "state: [-0.32849469 16.78718513], action: [-0.23388939 -0.167     ]\n",
      "Episode: 1807/3000, Reward: -758.5972997572713, done: False\n",
      "state: [-0.32850654 16.79006087], action: [-0.2480212 -0.167    ]\n",
      "Episode: 1808/3000, Reward: -791.7778680704241, done: False\n",
      "state: [-0.32872517 16.80298672], action: [-0.25102603 -0.167     ]\n",
      "Episode: 1809/3000, Reward: -759.505669298025, done: False\n",
      "state: [-0.32993489 16.83784422], action: [-0.23770092 -0.167     ]\n",
      "Episode: 1810/3000, Reward: -764.9527423396414, done: False\n",
      "state: [-0.32877612 16.80457297], action: [-0.24757722 -0.167     ]\n",
      "Episode: 1811/3000, Reward: -798.9556379184763, done: False\n",
      "state: [-0.32893718 16.8130622 ], action: [-0.24711882 -0.167     ]\n",
      "Episode: 1812/3000, Reward: -781.6263406432579, done: False\n",
      "state: [-0.32869639 16.81437651], action: [-0.25423658 -0.167     ]\n",
      "Episode: 1813/3000, Reward: -809.407999161957, done: False\n",
      "state: [-0.32905676 16.82828319], action: [-0.26238218 -0.167     ]\n",
      "Episode: 1814/3000, Reward: -797.2888002814667, done: False\n",
      "state: [-0.32916813 16.82860086], action: [-0.25446135 -0.167     ]\n",
      "Episode: 1815/3000, Reward: -822.7446626832698, done: False\n",
      "state: [-0.32871477 16.80892938], action: [-0.24900545 -0.167     ]\n",
      "Episode: 1816/3000, Reward: -806.5647150418191, done: False\n",
      "state: [-0.32821219 16.80861   ], action: [-0.2768251 -0.167    ]\n",
      "Episode: 1817/3000, Reward: -880.2183035346902, done: False\n",
      "state: [-0.32830446 16.76725437], action: [-0.23610227 -0.167     ]\n",
      "Episode: 1818/3000, Reward: -839.8490061431932, done: False\n",
      "state: [-0.32760834 16.73146282], action: [-0.23568799 -0.167     ]\n",
      "Episode: 1819/3000, Reward: -823.5264965533404, done: False\n",
      "state: [-0.32751702 16.70381952], action: [-0.23161992 -0.167     ]\n",
      "Episode: 1820/3000, Reward: -814.0291564564734, done: False\n",
      "state: [-0.32712267 16.66853294], action: [-0.23289749 -0.167     ]\n",
      "Episode: 1821/3000, Reward: -836.48480890837, done: False\n",
      "state: [-0.32696737 16.65303619], action: [-0.25682163 -0.167     ]\n",
      "Episode: 1822/3000, Reward: -987.9395951824932, done: False\n",
      "state: [-0.32613194 16.60356504], action: [-0.22801393 -0.167     ]\n",
      "Episode: 1823/3000, Reward: -852.3757759056862, done: False\n",
      "state: [-0.32602477 16.5807703 ], action: [-0.22635336 -0.167     ]\n",
      "Episode: 1824/3000, Reward: -867.1925633937263, done: False\n",
      "state: [-0.32585558 16.56703967], action: [-0.2529266 -0.167    ]\n",
      "Episode: 1825/3000, Reward: -850.5837315239976, done: False\n",
      "state: [-0.32549365 16.5390485 ], action: [-0.23701337 -0.167     ]\n",
      "Episode: 1826/3000, Reward: -854.6318814828828, done: False\n",
      "state: [-0.32535708 16.51571021], action: [-0.24477491 -0.167     ]\n",
      "Episode: 1827/3000, Reward: -871.9927232272343, done: False\n",
      "state: [-0.32595687 16.51441531], action: [-0.23799604 -0.167     ]\n",
      "Episode: 1828/3000, Reward: -874.6778464708593, done: False\n",
      "state: [-0.32476638 16.4740145 ], action: [-0.2506936 -0.167    ]\n",
      "Episode: 1829/3000, Reward: -890.207646299606, done: False\n",
      "state: [-0.32437534 16.44780621], action: [-0.20980062 -0.167     ]\n",
      "Episode: 1830/3000, Reward: -898.6238785709614, done: False\n",
      "state: [-0.32415168 16.42490239], action: [-0.24383153 -0.167     ]\n",
      "Episode: 1831/3000, Reward: -915.2119407627763, done: False\n",
      "state: [-0.32347258 16.40226393], action: [-0.2394889 -0.167    ]\n",
      "Episode: 1832/3000, Reward: -930.2781782045903, done: False\n",
      "state: [-0.32340653 16.36922341], action: [-0.2420978 -0.167    ]\n",
      "Episode: 1833/3000, Reward: -993.0395953671948, done: False\n",
      "state: [-0.32336582 16.36010648], action: [-0.2315694 -0.167    ]\n",
      "Episode: 1834/3000, Reward: -972.8606127794066, done: False\n",
      "state: [-0.32285706 16.32213495], action: [-0.2490305 -0.167    ]\n",
      "Episode: 1835/3000, Reward: -982.5362073529717, done: False\n",
      "state: [-0.3227944  16.30637357], action: [-0.22872986 -0.167     ]\n",
      "Episode: 1836/3000, Reward: -1006.6467836033761, done: False\n",
      "state: [-0.32239323 16.28703003], action: [-0.25039685 -0.167     ]\n",
      "Episode: 1837/3000, Reward: -1136.8816765294503, done: False\n",
      "state: [-0.32234101 16.27940052], action: [-0.23865448 -0.167     ]\n",
      "Episode: 1838/3000, Reward: -1064.5945909889426, done: False\n",
      "state: [-0.32180682 16.29027543], action: [-0.30190876 -0.167     ]\n",
      "Episode: 1839/3000, Reward: -1087.8875382437757, done: False\n",
      "state: [-0.32188936 16.25336881], action: [-0.23418866 -0.167     ]\n",
      "Episode: 1840/3000, Reward: -1198.9182577613512, done: False\n",
      "state: [-0.32167546 16.23202424], action: [-0.22541577 -0.167     ]\n",
      "Episode: 1841/3000, Reward: -1154.4835729985411, done: False\n",
      "state: [-0.32119048 16.19239688], action: [-0.24222349 -0.167     ]\n",
      "Episode: 1842/3000, Reward: -1169.1398793769145, done: False\n",
      "state: [-0.32138998 16.19393491], action: [-0.23527722 -0.167     ]\n",
      "Episode: 1843/3000, Reward: -1200.623719404788, done: False\n",
      "state: [-0.32103785 16.17521654], action: [-0.22046752 -0.167     ]\n",
      "Episode: 1844/3000, Reward: -1270.8082535810147, done: False\n",
      "state: [-0.32208694 16.22210324], action: [-0.26373854 -0.167     ]\n",
      "Episode: 1845/3000, Reward: -1276.960513001644, done: False\n",
      "state: [-0.32112811 16.17689574], action: [-0.23786288 -0.167     ]\n",
      "Episode: 1846/3000, Reward: -1454.642045915464, done: False\n",
      "state: [-0.32106185 16.17495227], action: [-0.24085487 -0.167     ]\n",
      "Episode: 1847/3000, Reward: -1420.711648855835, done: False\n",
      "state: [-0.32073449 16.16847202], action: [-0.24819303 -0.167     ]\n",
      "Episode: 1848/3000, Reward: -1431.8014663400625, done: False\n",
      "state: [-0.32146154 16.20059389], action: [-0.24841496 -0.167     ]\n",
      "Episode: 1849/3000, Reward: -1490.2806592854313, done: False\n",
      "state: [-0.32116544 16.19278232], action: [-0.24484664 -0.167     ]\n",
      "Episode: 1850/3000, Reward: -1602.1642340715634, done: False\n",
      "state: [-0.32101952 16.18291423], action: [-0.22950335 -0.167     ]\n",
      "Episode: 1851/3000, Reward: -1649.6544550483486, done: False\n",
      "state: [-0.32102388 16.16473788], action: [-0.23775132 -0.167     ]\n",
      "Episode: 1852/3000, Reward: -1675.6895500425671, done: False\n",
      "state: [-0.32062727 16.14746233], action: [-0.24206907 -0.167     ]\n",
      "Episode: 1853/3000, Reward: -1933.1924168425498, done: False\n",
      "state: [-0.3204494  16.12852328], action: [-0.22522023 -0.167     ]\n",
      "Episode: 1854/3000, Reward: -1783.8877373747512, done: False\n",
      "state: [-0.31999674 16.10995488], action: [-0.24770255 -0.167     ]\n",
      "Episode: 1855/3000, Reward: -1734.3172775176683, done: False\n",
      "state: [-0.32016636 16.10597944], action: [-0.2566969 -0.167    ]\n",
      "Episode: 1856/3000, Reward: -2071.92450267779, done: False\n",
      "state: [-0.31989521 16.10204107], action: [-0.23685855 -0.167     ]\n",
      "Episode: 1857/3000, Reward: -1869.2825709886786, done: False\n",
      "state: [-0.32281327 16.08604341], action: [-0.15459575 -0.167     ]\n",
      "Episode: 1858/3000, Reward: -1886.1964751113196, done: False\n",
      "state: [-0.32002212 16.08033296], action: [-0.23241398 -0.167     ]\n",
      "Episode: 1859/3000, Reward: -1938.60405071181, done: False\n",
      "state: [-0.3196134  16.06727457], action: [-0.2520623 -0.167    ]\n",
      "Episode: 1860/3000, Reward: -2108.6316639922, done: False\n",
      "state: [-0.31907964 16.02328062], action: [-0.23483755 -0.167     ]\n",
      "Episode: 1861/3000, Reward: -1997.721899526508, done: False\n",
      "state: [-0.31940863 16.04777809], action: [-0.24427637 -0.167     ]\n",
      "Episode: 1862/3000, Reward: -2059.858127663153, done: False\n",
      "state: [-0.31963355 16.07044501], action: [-0.2588052 -0.167    ]\n",
      "Episode: 1863/3000, Reward: -2120.2757213815353, done: False\n",
      "state: [-0.31962054 16.06823459], action: [-0.25109395 -0.167     ]\n",
      "Episode: 1864/3000, Reward: -2150.4500818175507, done: False\n",
      "state: [-0.31872642 16.01900083], action: [-0.26230758 -0.167     ]\n",
      "Episode: 1865/3000, Reward: -2166.396184708333, done: False\n",
      "state: [-0.31905018 16.02096067], action: [-0.2624248 -0.167    ]\n",
      "Episode: 1866/3000, Reward: -2300.8213597277213, done: False\n",
      "state: [-0.31932891 15.99569937], action: [-0.23956801 -0.167     ]\n",
      "Episode: 1867/3000, Reward: -2239.194212984364, done: False\n",
      "state: [-0.31951862 15.96967123], action: [-0.27268472 -0.167     ]\n",
      "Episode: 1868/3000, Reward: -2312.191657291174, done: False\n",
      "state: [-0.3166753  15.87047699], action: [-0.25426155 -0.167     ]\n",
      "Episode: 1869/3000, Reward: -2302.169398362882, done: False\n",
      "state: [-0.31862205 15.91829168], action: [-0.25901517 -0.167     ]\n",
      "Episode: 1870/3000, Reward: -2337.318682909038, done: False\n",
      "state: [-0.31703599 15.86162584], action: [-0.251387 -0.167   ]\n",
      "Episode: 1871/3000, Reward: -2282.2546989604525, done: False\n",
      "state: [-0.31712055 15.85745175], action: [-0.23331234 -0.167     ]\n",
      "Episode: 1872/3000, Reward: -2400.258666545694, done: False\n",
      "state: [-0.31645336 15.84068438], action: [-0.23974779 -0.167     ]\n",
      "Episode: 1873/3000, Reward: -2343.3460552851357, done: False\n",
      "state: [-0.31672825 15.82373867], action: [-0.2813522 -0.167    ]\n",
      "Episode: 1874/3000, Reward: -2340.4249398805123, done: False\n",
      "state: [-0.31644052 15.81604903], action: [-0.26198074 -0.167     ]\n",
      "Episode: 1875/3000, Reward: -2402.561929657104, done: False\n",
      "state: [-0.31646386 15.81916164], action: [-0.23487718 -0.167     ]\n",
      "Episode: 1876/3000, Reward: -2509.0154376720106, done: False\n",
      "state: [-0.31547082 15.7636728 ], action: [-0.24519803 -0.167     ]\n",
      "Episode: 1877/3000, Reward: -2514.8773542672634, done: False\n",
      "state: [-0.31566964 15.74345022], action: [-0.26258108 -0.167     ]\n",
      "Episode: 1878/3000, Reward: -2479.691093086296, done: False\n",
      "state: [-0.31537931 15.70280854], action: [-0.25005713 -0.167     ]\n",
      "Episode: 1879/3000, Reward: -2492.1842928659125, done: False\n",
      "state: [-0.31467954 15.67848436], action: [-0.25483948 -0.167     ]\n",
      "Episode: 1880/3000, Reward: -2498.783709533619, done: False\n",
      "state: [-0.31472689 15.6659607 ], action: [-0.24624825 -0.167     ]\n",
      "Episode: 1881/3000, Reward: -2553.951582563552, done: False\n",
      "state: [-0.31423759 15.63462111], action: [-0.22048567 -0.167     ]\n",
      "Episode: 1882/3000, Reward: -2470.7281994794553, done: False\n",
      "state: [-0.31343427 15.56679457], action: [-0.23227324 -0.167     ]\n",
      "Episode: 1883/3000, Reward: -2703.2921795781817, done: False\n",
      "state: [-0.31354909 15.55832866], action: [-0.22284701 -0.167     ]\n",
      "Episode: 1884/3000, Reward: -2615.1278024148555, done: False\n",
      "state: [-0.3122246  15.52108121], action: [-0.22651261 -0.167     ]\n",
      "Episode: 1885/3000, Reward: -2587.477612046383, done: False\n",
      "state: [-0.31374291 15.55679962], action: [-0.29265854 -0.167     ]\n",
      "Episode: 1886/3000, Reward: -2689.7069519884485, done: False\n",
      "state: [-0.30997454 15.53279305], action: [0.32757932 0.6480231 ]\n",
      "Episode: 1887/3000, Reward: -2660.411876734771, done: False\n",
      "state: [-0.31218859 15.48754026], action: [-0.24426202 -0.167     ]\n",
      "Episode: 1888/3000, Reward: -2785.007899408289, done: False\n",
      "state: [-0.31251856 15.50370081], action: [-0.23762535 -0.167     ]\n",
      "Episode: 1889/3000, Reward: -2959.528618247698, done: False\n",
      "state: [-0.31201442 15.46566251], action: [-0.22711688 -0.167     ]\n",
      "Episode: 1890/3000, Reward: -2696.386490405208, done: False\n",
      "state: [-0.31213889 15.47231892], action: [-0.22039858 -0.167     ]\n",
      "Episode: 1891/3000, Reward: -2950.6983776446004, done: False\n",
      "state: [-0.31065435 15.40996436], action: [-0.27430117 -0.167     ]\n",
      "Episode: 1892/3000, Reward: -2768.09548785328, done: False\n",
      "state: [-0.31357119 15.40779906], action: [-0.16052169 -0.167     ]\n",
      "Episode: 1893/3000, Reward: -3005.5034803435865, done: False\n",
      "state: [-0.31136866 15.3771321 ], action: [-0.21390682 -0.167     ]\n",
      "Episode: 1894/3000, Reward: -2844.380780180221, done: False\n",
      "state: [-0.3109764  15.37880616], action: [-0.23401558 -0.167     ]\n",
      "Episode: 1895/3000, Reward: -2864.7690550022985, done: False\n",
      "state: [-0.31077098 15.34351294], action: [-0.25265878 -0.167     ]\n",
      "Episode: 1896/3000, Reward: -2896.698515111704, done: False\n",
      "state: [-0.31077059 15.32477069], action: [-0.21241021 -0.167     ]\n",
      "Episode: 1897/3000, Reward: -2965.6715685935246, done: False\n",
      "state: [-0.31142443 15.33819891], action: [-0.22858524 -0.167     ]\n",
      "Episode: 1898/3000, Reward: -2930.9549044025284, done: False\n",
      "state: [-0.31021316 15.33963532], action: [-0.22686723 -0.167     ]\n",
      "Episode: 1899/3000, Reward: -3010.7720856508936, done: False\n",
      "state: [-0.30961131 15.28813368], action: [-0.20601213 -0.167     ]\n",
      "Episode: 1900/3000, Reward: -3229.118629702596, done: False\n",
      "state: [-0.30940983 15.27246697], action: [-0.23358646 -0.167     ]\n",
      "Episode: 1901/3000, Reward: -3243.815840869815, done: False\n",
      "state: [-0.30895238 15.23388291], action: [-0.23810759 -0.167     ]\n",
      "Episode: 1902/3000, Reward: -3000.0082351928336, done: False\n",
      "state: [-0.30906688 15.2371577 ], action: [-0.22386184 -0.167     ]\n",
      "Episode: 1903/3000, Reward: -3117.3389854516486, done: False\n",
      "state: [-0.30973905 15.28257703], action: [-0.22878408 -0.167     ]\n",
      "Episode: 1904/3000, Reward: -3072.947450381344, done: False\n",
      "state: [-0.30829196 15.18817227], action: [-0.18098624 -0.167     ]\n",
      "Episode: 1905/3000, Reward: -3398.249643385919, done: False\n",
      "state: [-0.30857906 15.1994734 ], action: [-0.28302342 -0.167     ]\n",
      "Episode: 1906/3000, Reward: -3108.586973742157, done: False\n",
      "state: [-0.30860231 15.13834236], action: [-0.23984487 -0.167     ]\n",
      "Episode: 1907/3000, Reward: -3600.9259983502693, done: False\n",
      "state: [-0.30663228 15.10304657], action: [-0.23394708 -0.167     ]\n",
      "Episode: 1908/3000, Reward: -3117.0779551991495, done: False\n",
      "state: [-0.30777441 15.13557444], action: [-0.20855673 -0.167     ]\n",
      "Episode: 1909/3000, Reward: -3354.1465271560164, done: False\n",
      "state: [-0.30384589 15.07074508], action: [-0.11765445 -0.167     ]\n",
      "Episode: 1910/3000, Reward: -3142.773823165514, done: False\n",
      "state: [-0.30818997 15.14152255], action: [-0.25078654 -0.167     ]\n",
      "Episode: 1911/3000, Reward: -3238.540572944554, done: False\n",
      "state: [-0.30894842 15.13564171], action: [-0.2361815 -0.167    ]\n",
      "Episode: 1912/3000, Reward: -3345.9619060767927, done: False\n",
      "state: [-0.30725542 15.09970295], action: [-0.2251985 -0.167    ]\n",
      "Episode: 1913/3000, Reward: -3400.0176093959294, done: False\n",
      "state: [-0.30576213 15.07798884], action: [-0.25318366 -0.167     ]\n",
      "Episode: 1914/3000, Reward: -3302.0646278996646, done: False\n",
      "state: [-0.30706337 15.02279754], action: [-0.23069194 -0.167     ]\n",
      "Episode: 1915/3000, Reward: -3316.2076589694707, done: False\n",
      "state: [-0.30597285 15.02465749], action: [-0.21676613 -0.167     ]\n",
      "Episode: 1916/3000, Reward: -3361.7964426274098, done: False\n",
      "state: [-0.30628117 14.97512852], action: [-0.19348294 -0.167     ]\n",
      "Episode: 1917/3000, Reward: -3380.1631300115805, done: False\n",
      "state: [-0.30527187 14.9744021 ], action: [-0.2052851 -0.167    ]\n",
      "Episode: 1918/3000, Reward: -3329.081686209865, done: False\n",
      "state: [-0.30622251 14.95051886], action: [-0.19512372 -0.167     ]\n",
      "Episode: 1919/3000, Reward: -3348.806855328537, done: False\n",
      "state: [-0.30534561 14.93346367], action: [-0.2222814 -0.167    ]\n",
      "Episode: 1920/3000, Reward: -3444.3628093726265, done: False\n",
      "state: [-0.30554285 14.95286979], action: [-0.21676977 -0.167     ]\n",
      "Episode: 1921/3000, Reward: -3788.025512340144, done: False\n",
      "state: [-0.30516384 14.95316213], action: [-0.24178894 -0.167     ]\n",
      "Episode: 1922/3000, Reward: -3611.966398249969, done: False\n",
      "state: [-0.3055906  14.93500912], action: [-0.22183533 -0.167     ]\n",
      "Episode: 1923/3000, Reward: -3814.3564145849923, done: False\n",
      "state: [-0.30500802 14.92276221], action: [-0.22780779 -0.167     ]\n",
      "Episode: 1924/3000, Reward: -3473.0860418803686, done: False\n",
      "state: [-0.3044768  14.89243973], action: [-0.22101548 -0.167     ]\n",
      "Episode: 1925/3000, Reward: -3603.119487658766, done: False\n",
      "state: [-0.30486932 14.92843981], action: [-0.22644384 -0.167     ]\n",
      "Episode: 1926/3000, Reward: -3560.788279512147, done: False\n",
      "state: [-0.30079761 14.92805251], action: [-0.36773962 -0.167     ]\n",
      "Episode: 1927/3000, Reward: -3526.5424224336252, done: False\n",
      "state: [-0.30428685 14.88162471], action: [-0.22638232 -0.167     ]\n",
      "Episode: 1928/3000, Reward: -3506.5652802472914, done: False\n",
      "state: [-0.30474013 14.89471255], action: [-0.22331825 -0.167     ]\n",
      "Episode: 1929/3000, Reward: -3558.4943716530524, done: False\n",
      "state: [-0.30450577 14.88399423], action: [-0.23699537 -0.167     ]\n",
      "Episode: 1930/3000, Reward: -3596.1034087013977, done: False\n",
      "state: [-0.30485248 14.88793113], action: [-0.22015901 -0.167     ]\n",
      "Episode: 1931/3000, Reward: -3714.682423662586, done: False\n",
      "state: [-0.30435382 14.87601327], action: [-0.24770255 -0.167     ]\n",
      "Episode: 1932/3000, Reward: -3851.9973575495387, done: False\n",
      "state: [-0.30387385 14.8757258 ], action: [-0.19081204 -0.167     ]\n",
      "Episode: 1933/3000, Reward: -3689.4690526209065, done: False\n",
      "state: [-0.30116059 14.89688853], action: [-0.36426082 -0.167     ]\n",
      "Episode: 1934/3000, Reward: -3680.7521566378964, done: False\n",
      "state: [-0.30488868 14.90549617], action: [-0.23767933 -0.167     ]\n",
      "Episode: 1935/3000, Reward: -3691.9853960658475, done: False\n",
      "state: [-0.30319939 14.92395615], action: [-0.26736933 -0.167     ]\n",
      "Episode: 1936/3000, Reward: -3820.7796412261823, done: False\n",
      "state: [-0.3052656  14.93036397], action: [-0.25330862 -0.167     ]\n",
      "Episode: 1937/3000, Reward: -3855.7837052619575, done: False\n",
      "state: [-0.30404944 14.86520342], action: [-0.21868844 -0.167     ]\n",
      "Episode: 1938/3000, Reward: -3998.3189625718724, done: False\n",
      "state: [-0.30433183 14.88332898], action: [-0.21226451 -0.167     ]\n",
      "Episode: 1939/3000, Reward: -3997.4052414483767, done: False\n",
      "state: [-0.30647717 14.77693451], action: [-0.12713093 -0.167     ]\n",
      "Episode: 1940/3000, Reward: -3862.7916264865075, done: False\n",
      "state: [-0.30365669 14.82127702], action: [-0.2078962 -0.167    ]\n",
      "Episode: 1941/3000, Reward: -3898.6692364363, done: False\n",
      "state: [-0.3037977  14.85391795], action: [-0.23003812 -0.167     ]\n",
      "Episode: 1942/3000, Reward: -3888.002356019286, done: False\n",
      "state: [-0.30489473 14.92016999], action: [-0.2574985 -0.167    ]\n",
      "Episode: 1943/3000, Reward: -3942.081914868585, done: False\n",
      "state: [-0.30398817 14.85457896], action: [-0.21671161 -0.167     ]\n",
      "Episode: 1944/3000, Reward: -3922.5850118316644, done: False\n",
      "state: [-0.30442107 14.88521723], action: [-0.21451464 -0.167     ]\n",
      "Episode: 1945/3000, Reward: -4004.821586906197, done: False\n",
      "state: [-0.30489644 14.88589144], action: [-0.22184621 -0.167     ]\n",
      "Episode: 1946/3000, Reward: -4149.660143120822, done: False\n",
      "state: [-0.30458192 14.8920886 ], action: [-0.21672978 -0.167     ]\n",
      "Episode: 1947/3000, Reward: -3975.665607488193, done: False\n",
      "state: [-0.30397828 14.87056106], action: [-0.21612257 -0.167     ]\n",
      "Episode: 1948/3000, Reward: -3982.1105423450626, done: False\n",
      "state: [-0.30357769 14.88568433], action: [-0.24824673 -0.167     ]\n",
      "Episode: 1949/3000, Reward: -4119.836396373396, done: False\n",
      "state: [-0.30448404 14.86945676], action: [-0.20541665 -0.167     ]\n",
      "Episode: 1950/3000, Reward: -4070.3182351375835, done: False\n",
      "state: [-0.30463952 14.88661754], action: [-0.21636257 -0.167     ]\n",
      "Episode: 1951/3000, Reward: -4116.720560926008, done: False\n",
      "state: [-0.30389919 14.86592508], action: [-0.2506221 -0.167    ]\n",
      "Episode: 1952/3000, Reward: -4132.483960311833, done: False\n",
      "state: [-0.30452563 14.89204433], action: [-0.22767398 -0.167     ]\n",
      "Episode: 1953/3000, Reward: -4097.886406795638, done: False\n",
      "state: [-0.30409703 14.872936  ], action: [-0.19935828 -0.167     ]\n",
      "Episode: 1954/3000, Reward: -4087.2047624962174, done: False\n",
      "state: [-0.3062636 14.9275684], action: [-0.2643312 -0.167    ]\n",
      "Episode: 1955/3000, Reward: -4017.2525838148504, done: False\n",
      "state: [-0.30436826 14.88514415], action: [-0.2193458 -0.167    ]\n",
      "Episode: 1956/3000, Reward: -4243.59103874578, done: False\n",
      "state: [-0.30455642 14.87874213], action: [-0.22265486 -0.167     ]\n",
      "Episode: 1957/3000, Reward: -4208.402930088386, done: False\n",
      "state: [-0.30439216 14.88496242], action: [-0.2295142 -0.167    ]\n",
      "Episode: 1958/3000, Reward: -4147.207539559261, done: False\n",
      "state: [-0.30495991 14.89854922], action: [-0.24406473 -0.167     ]\n",
      "Episode: 1959/3000, Reward: -4567.404556702831, done: False\n",
      "state: [-0.30290196 14.86551934], action: [-0.16985378 -0.167     ]\n",
      "Episode: 1960/3000, Reward: -4204.760510718097, done: False\n",
      "state: [-0.30456498 14.90059023], action: [-0.19594555 -0.167     ]\n",
      "Episode: 1961/3000, Reward: -4220.524899126023, done: False\n",
      "state: [-0.3070608  14.92458995], action: [-0.15252478 -0.167     ]\n",
      "Episode: 1962/3000, Reward: -4314.294214825921, done: False\n",
      "state: [-0.30497019 14.90994943], action: [-0.22950697 -0.167     ]\n",
      "Episode: 1963/3000, Reward: -4269.896575075203, done: False\n",
      "state: [-0.30500301 14.91219616], action: [-0.20040204 -0.167     ]\n",
      "Episode: 1964/3000, Reward: -4319.868660880489, done: False\n",
      "state: [-0.30524777 14.93019973], action: [-0.20030683 -0.167     ]\n",
      "Episode: 1965/3000, Reward: -4224.913113698379, done: False\n",
      "state: [-0.30553369 14.93865729], action: [-0.19155444 -0.167     ]\n",
      "Episode: 1966/3000, Reward: -4468.54589723091, done: False\n",
      "state: [-0.30535261 14.95995151], action: [-0.20212598 -0.167     ]\n",
      "Episode: 1967/3000, Reward: -4357.486113367598, done: False\n",
      "state: [-0.30705977 14.99440171], action: [-0.2589867 -0.167    ]\n",
      "Episode: 1968/3000, Reward: -4320.856321766312, done: False\n",
      "state: [-0.30539625 14.95153089], action: [-0.23634358 -0.167     ]\n",
      "Episode: 1969/3000, Reward: -4299.64664280343, done: False\n",
      "state: [-0.30546262 14.95377418], action: [-0.2051426 -0.167    ]\n",
      "Episode: 1970/3000, Reward: -4528.666560000653, done: False\n",
      "state: [-0.30574693 14.9838051 ], action: [-0.24816798 -0.167     ]\n",
      "Episode: 1971/3000, Reward: -4639.259133731903, done: False\n",
      "state: [-0.30572587 14.96979501], action: [-0.23462127 -0.167     ]\n",
      "Episode: 1972/3000, Reward: -4429.000338010276, done: False\n",
      "state: [-0.30543598 14.99068962], action: [-0.22239743 -0.167     ]\n",
      "Episode: 1973/3000, Reward: -4680.046788951489, done: False\n",
      "state: [-0.30592194 14.99245456], action: [-0.22454296 -0.167     ]\n",
      "Episode: 1974/3000, Reward: -4614.228114915257, done: False\n",
      "state: [-0.3051004  14.97801735], action: [-0.21288371 -0.167     ]\n",
      "Episode: 1975/3000, Reward: -4637.399026415651, done: False\n",
      "state: [-0.30609579 15.01428291], action: [-0.20776115 -0.167     ]\n",
      "Episode: 1976/3000, Reward: -4693.417726765395, done: False\n",
      "state: [-0.30544031 15.05370329], action: [-0.304351 -0.167   ]\n",
      "Episode: 1977/3000, Reward: -4508.053585376165, done: False\n",
      "state: [-0.3061465 15.0160849], action: [-0.2164571 -0.167    ]\n",
      "Episode: 1978/3000, Reward: -4535.09907219948, done: False\n",
      "state: [-0.30647775 15.02383617], action: [-0.21943294 -0.167     ]\n",
      "Episode: 1979/3000, Reward: -4517.925790806905, done: False\n",
      "state: [-0.30567873 15.02432126], action: [-0.24261485 -0.167     ]\n",
      "Episode: 1980/3000, Reward: -4589.875461699963, done: False\n",
      "state: [-0.3068814  15.04000059], action: [-0.21967258 -0.167     ]\n",
      "Episode: 1981/3000, Reward: -4704.819820788786, done: False\n",
      "state: [-0.30608354 15.03540169], action: [-0.23894225 -0.167     ]\n",
      "Episode: 1982/3000, Reward: -4888.45384978255, done: False\n",
      "state: [-0.30628223 15.05113885], action: [-0.19913483 -0.167     ]\n",
      "Episode: 1983/3000, Reward: -4620.942614491901, done: False\n",
      "state: [-0.30624917 15.05412963], action: [-0.22573438 -0.167     ]\n",
      "Episode: 1984/3000, Reward: -4732.4444750096145, done: False\n",
      "state: [-0.30572602 15.04090008], action: [-0.22070342 -0.167     ]\n",
      "Episode: 1985/3000, Reward: -4666.06964069384, done: False\n",
      "state: [-0.3065445  15.11524309], action: [-0.2741883 -0.167    ]\n",
      "Episode: 1986/3000, Reward: -4670.6766811209345, done: False\n",
      "state: [-0.30719821 15.1037949 ], action: [-0.22705899 -0.167     ]\n",
      "Episode: 1987/3000, Reward: -4826.66668686547, done: False\n",
      "state: [-0.30898435 15.09306289], action: [-0.16917203 -0.167     ]\n",
      "Episode: 1988/3000, Reward: -4926.208625406257, done: False\n",
      "state: [-0.30752162 15.11690021], action: [-0.22275276 -0.167     ]\n",
      "Episode: 1989/3000, Reward: -4752.167322983877, done: False\n",
      "state: [-0.30747722 15.11186007], action: [-0.21147752 -0.167     ]\n",
      "Episode: 1990/3000, Reward: -4763.9574204248465, done: False\n",
      "state: [-0.30854231 15.14789196], action: [-0.25614452 -0.167     ]\n",
      "Episode: 1991/3000, Reward: -4803.015677305459, done: False\n",
      "state: [-0.30778276 15.15016678], action: [-0.2465564 -0.167    ]\n",
      "Episode: 1992/3000, Reward: -4822.254513641213, done: False\n",
      "state: [-0.30807062 15.17319616], action: [-0.21520962 -0.167     ]\n",
      "Episode: 1993/3000, Reward: -4855.1332240477095, done: False\n",
      "state: [-0.30853644 15.18752746], action: [-0.23643722 -0.167     ]\n",
      "Episode: 1994/3000, Reward: -4854.966955187062, done: False\n",
      "state: [-0.30837107 15.20813863], action: [-0.2803859 -0.167    ]\n",
      "Episode: 1995/3000, Reward: -5033.530379387981, done: False\n",
      "state: [-0.30805307 15.18484344], action: [-0.20256865 -0.167     ]\n",
      "Episode: 1996/3000, Reward: -4901.176608876933, done: False\n",
      "state: [-0.30810322 15.17500677], action: [-0.24447365 -0.167     ]\n",
      "Episode: 1997/3000, Reward: -4993.471799220947, done: False\n",
      "state: [-0.30848659 15.21713778], action: [-0.23507541 -0.167     ]\n",
      "Episode: 1998/3000, Reward: -4952.5278637145175, done: False\n",
      "state: [-0.30923766 15.2108672 ], action: [-0.2743188 -0.167    ]\n",
      "Episode: 1999/3000, Reward: -5175.446459824991, done: False\n",
      "state: [-0.30906666 15.24606276], action: [-0.21568978 -0.167     ]\n",
      "Episode: 2000/3000, Reward: -4957.057558774367, done: False\n",
      "state: [-0.31015552 15.25671357], action: [-0.1994352 -0.167    ]\n",
      "Episode: 2001/3000, Reward: -4964.098617231042, done: False\n",
      "state: [-0.30980197 15.27763451], action: [-0.22687447 -0.167     ]\n",
      "Episode: 2002/3000, Reward: -5405.011790162979, done: False\n",
      "state: [-0.30947725 15.25739162], action: [-0.26352203 -0.167     ]\n",
      "Episode: 2003/3000, Reward: -5162.980051826708, done: False\n",
      "state: [-0.3093642 15.2799804], action: [-0.2344266 -0.167    ]\n",
      "Episode: 2004/3000, Reward: -4998.199989927078, done: False\n",
      "state: [-0.31001953 15.29108801], action: [-0.25341928 -0.167     ]\n",
      "Episode: 2005/3000, Reward: -5168.899000391905, done: False\n",
      "state: [-0.31000279 15.2978212 ], action: [-0.21819441 -0.167     ]\n",
      "Episode: 2006/3000, Reward: -5026.161470237637, done: False\n",
      "state: [-0.31007647 15.31753758], action: [-0.22412997 -0.167     ]\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer(memory_size)\n",
    "epsilon = 1.0\n",
    "# Set up the environment\n",
    "env = cstr_env()\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.shape[0]\n",
    "\n",
    "# Initialize networks and optimizer\n",
    "naf_network = NAFNetwork(state_size, action_size)\n",
    "target_naf_network = NAFNetwork(state_size, action_size)\n",
    "target_naf_network.load_state_dict(naf_network.state_dict())\n",
    "target_naf_network.eval()\n",
    "\n",
    "optimizer = optim.Adam(naf_network.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for e in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    step = 0\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        action = get_action(state, epsilon)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        train_model()\n",
    "        if step == 500:\n",
    "            break\n",
    "\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    print(f\"Episode: {e+1}/{num_episodes}, Reward: {total_reward}, done: {done}\")\n",
    "    print(f\"state: {state}, action: {action}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a08d4-b186-44b8-bf8b-f93700e4377a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
