{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1930bee-616f-4fa9-be3b-74e8a8161bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from CSTREnv import cstr_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ac932f-1381-4347-975f-735c51592d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment\n",
    "env = cstr_env(order=2)\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = 4*4\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "discount_factor = 0.99\n",
    "batch_size = 64\n",
    "tau = 0.001\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.01\n",
    "memory_size = int(1e6)\n",
    "update_target_network_steps = 1000\n",
    "u1 = np.linspace(-1, 1, 4)\n",
    "u2 = np.linspace(-0.0167, 0.0167, 4)\n",
    "XX, YY = np.meshgrid(u1, u2)\n",
    "XX, YY = XX.flatten(), YY.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f37c5b8-99c1-439a-aa3f-610acc3b0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, size):\n",
    "        self.memory = deque(maxlen=size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.memory.append(experience)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68f235b-a77b-4e8d-a254-9b36afcf7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network for Q-learning\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4babd5-9312-4c8a-88bb-7fff66f2b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize networks and optimizer\n",
    "q_network = QNetwork(state_size, action_size)\n",
    "target_q_network = QNetwork(state_size, action_size)\n",
    "target_q_network.load_state_dict(q_network.state_dict())\n",
    "target_q_network.eval()\n",
    "\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "778dd000-855b-4be0-96d7-13d86e51d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return random.randint(0, action_size - 1)\n",
    "    state = torch.FloatTensor(state).unsqueeze(0)\n",
    "    q_values = q_network(state)\n",
    "    return torch.argmax(q_values).item()\n",
    "\n",
    "def train_model():\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "\n",
    "    minibatch = memory.sample(batch_size)\n",
    "    states = torch.FloatTensor([e[0] for e in minibatch])\n",
    "    actions = torch.FloatTensor([e[1] for e in minibatch])\n",
    "    rewards = torch.FloatTensor([e[2] for e in minibatch])\n",
    "    next_states = torch.FloatTensor([e[3] for e in minibatch])\n",
    "    dones = torch.FloatTensor([e[4] for e in minibatch])\n",
    "\n",
    "    # Compute target Q-values\n",
    "    next_q_values = target_q_network(next_states).detach().max(1)[0]\n",
    "    target_q_values = rewards + (1 - dones) * discount_factor * next_q_values\n",
    "\n",
    "    # Compute predicted Q-values\n",
    "    predicted_q_values = q_network(states).gather(1, actions.unsqueeze(1).to(torch.int64)).squeeze()\n",
    "\n",
    "    loss = loss_fn(predicted_q_values, target_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ba2313-0151-4b2a-873e-7db4532ecaa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuxinji\\AppData\\Local\\Temp\\ipykernel_8300\\2432326707.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  states = torch.FloatTensor([e[0] for e in minibatch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/2000, Reward: -269.3275707655591, done: False\n",
      "state: [-0.04255057  0.03617751], action: [-1.0, -0.005566666666666666]\n",
      "Episode: 2/2000, Reward: -282.6987037532213, done: False\n",
      "state: [0.03791183 0.06788833], action: [1.0, 0.0167]\n",
      "Episode: 3/2000, Reward: -278.1738421161644, done: False\n",
      "state: [-0.03782443 -0.02717348], action: [1.0, -0.005566666666666666]\n",
      "Episode: 4/2000, Reward: -266.6502809484551, done: False\n",
      "state: [-0.03316798 -0.02338236], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 5/2000, Reward: -278.2260729852215, done: False\n",
      "state: [0.15584933 0.19163795], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 6/2000, Reward: -255.9943126999232, done: False\n",
      "state: [0.05358835 0.1469392 ], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 7/2000, Reward: -271.97816067540896, done: False\n",
      "state: [-0.05889323 -0.11649244], action: [1.0, 0.005566666666666668]\n",
      "Episode: 8/2000, Reward: -260.4572607129579, done: False\n",
      "state: [0.03045894 0.04978906], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 9/2000, Reward: -266.68959723007265, done: False\n",
      "state: [0.11828942 0.11115381], action: [1.0, 0.0167]\n",
      "Episode: 10/2000, Reward: -271.08853707151104, done: False\n",
      "state: [0.01004639 0.10892339], action: [-1.0, -0.005566666666666666]\n",
      "Episode: 11/2000, Reward: -267.5350077407648, done: False\n",
      "state: [ 0.08110923 -0.08212775], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 12/2000, Reward: -263.985783191291, done: False\n",
      "state: [0.00186455 0.00162937], action: [1.0, -0.005566666666666666]\n",
      "Episode: 13/2000, Reward: -263.0766707737966, done: False\n",
      "state: [-0.08985766 -0.01322267], action: [-1.0, 0.005566666666666668]\n",
      "Episode: 14/2000, Reward: -256.870268417959, done: False\n",
      "state: [-0.0635655  -0.06581611], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 15/2000, Reward: -277.3635256039103, done: False\n",
      "state: [ 0.02520568 -0.07297835], action: [-1.0, -0.005566666666666666]\n",
      "Episode: 16/2000, Reward: -260.4621487492662, done: False\n",
      "state: [0.02719804 0.0026622 ], action: [-1.0, -0.005566666666666666]\n",
      "Episode: 17/2000, Reward: -268.4193277543416, done: False\n",
      "state: [0.13182488 0.06053   ], action: [1.0, -0.0167]\n",
      "Episode: 18/2000, Reward: -161.549565332892, done: True\n",
      "state: [0.00928951 0.00326572], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 19/2000, Reward: -277.3476275199056, done: False\n",
      "state: [ 0.04216618 -0.01936658], action: [1.0, 0.0167]\n",
      "Episode: 20/2000, Reward: -256.0079110386252, done: False\n",
      "state: [0.12471868 0.14335031], action: [1.0, 0.005566666666666668]\n",
      "Episode: 21/2000, Reward: -266.6239874298449, done: False\n",
      "state: [-0.08105431 -0.07422139], action: [-1.0, -0.005566666666666666]\n",
      "Episode: 22/2000, Reward: -255.13539953018778, done: False\n",
      "state: [-0.17565092 -0.19834623], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 23/2000, Reward: -252.40477199928705, done: False\n",
      "state: [0.03175069 0.0512123 ], action: [-1.0, 0.005566666666666668]\n",
      "Episode: 24/2000, Reward: -243.570554800447, done: False\n",
      "state: [0.01867069 0.07945996], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 25/2000, Reward: -246.20869049802386, done: False\n",
      "state: [-0.08803181 -0.18227509], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 26/2000, Reward: -129.54062596501004, done: True\n",
      "state: [ 0.00935057 -0.0015218 ], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 27/2000, Reward: -250.67527998376542, done: False\n",
      "state: [ 0.00749026 -0.08166632], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 28/2000, Reward: -248.89606421183595, done: False\n",
      "state: [-0.02367268 -0.05871819], action: [1.0, -0.0167]\n",
      "Episode: 29/2000, Reward: -178.47202960934194, done: True\n",
      "state: [-0.00842724  0.00547205], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 30/2000, Reward: -250.6462681533772, done: False\n",
      "state: [ 0.00804629 -0.04720385], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 31/2000, Reward: -255.14257641143166, done: False\n",
      "state: [0.04542459 0.001992  ], action: [-1.0, 0.0167]\n",
      "Episode: 32/2000, Reward: -244.46625569242366, done: False\n",
      "state: [-0.04689937 -0.02972166], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 33/2000, Reward: -239.0876650566263, done: False\n",
      "state: [-0.20908118 -0.06855159], action: [-1.0, 0.0167]\n",
      "Episode: 34/2000, Reward: -249.7574752496486, done: False\n",
      "state: [0.09244398 0.03468894], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 35/2000, Reward: -245.23846883761388, done: True\n",
      "state: [-0.00467405 -0.00249856], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 36/2000, Reward: -143.43703970620217, done: True\n",
      "state: [0.00958269 0.00146965], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 37/2000, Reward: -247.96116736250616, done: False\n",
      "state: [-0.01551363  0.0193272 ], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 38/2000, Reward: -232.90160321782022, done: False\n",
      "state: [0.0258034 0.0337448], action: [1.0, -0.0167]\n",
      "Episode: 39/2000, Reward: -237.30833502893324, done: False\n",
      "state: [-0.0226364  -0.08350702], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 40/2000, Reward: -239.99686058058307, done: False\n",
      "state: [-0.04631447 -0.10350801], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 41/2000, Reward: -229.32519476337393, done: False\n",
      "state: [-0.05239425 -0.02900236], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 42/2000, Reward: -236.48492023987572, done: False\n",
      "state: [0.05171742 0.02387115], action: [1.0, 0.0167]\n",
      "Episode: 43/2000, Reward: -220.43655594484218, done: False\n",
      "state: [0.03323789 0.11268647], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 44/2000, Reward: -227.5165304713711, done: False\n",
      "state: [0.07036125 0.0673326 ], action: [1.0, -0.005566666666666666]\n",
      "Episode: 45/2000, Reward: -239.1065255296246, done: False\n",
      "state: [0.17361635 0.24589445], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 46/2000, Reward: -232.93189413603176, done: False\n",
      "state: [-0.01647041 -0.02357734], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 47/2000, Reward: -245.33943178754285, done: False\n",
      "state: [-0.12962804 -0.13330499], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 48/2000, Reward: -231.98455445684678, done: False\n",
      "state: [ 0.03347755 -0.02576581], action: [1.0, 0.0167]\n",
      "Episode: 49/2000, Reward: -161.53030552451406, done: True\n",
      "state: [0.00858964 0.00461403], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 50/2000, Reward: -212.3401895595265, done: True\n",
      "state: [0.00469371 0.00176662], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 51/2000, Reward: -236.41683372053095, done: False\n",
      "state: [0.0310759  0.09309755], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 52/2000, Reward: -212.46795932017378, done: False\n",
      "state: [-0.00166121  0.08271141], action: [1.0, 0.0167]\n",
      "Episode: 53/2000, Reward: -230.19547586496915, done: False\n",
      "state: [0.05359095 0.11258171], action: [-1.0, 0.005566666666666668]\n",
      "Episode: 54/2000, Reward: -113.02169151767282, done: True\n",
      "state: [2.42984405e-03 3.32729163e-05], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 55/2000, Reward: -208.9356507449288, done: False\n",
      "state: [-0.03755362  0.09954021], action: [-1.0, -0.0167]\n",
      "Episode: 56/2000, Reward: -121.27360428271896, done: True\n",
      "state: [ 0.00434758 -0.00614729], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 57/2000, Reward: -216.92220376260386, done: False\n",
      "state: [-0.03902362 -0.06013466], action: [1.0, -0.005566666666666666]\n",
      "Episode: 58/2000, Reward: -227.51407772460175, done: False\n",
      "state: [-0.06574253  0.0297125 ], action: [-1.0, 0.0167]\n",
      "Episode: 59/2000, Reward: -215.15733094768407, done: False\n",
      "state: [0.11432287 0.20325782], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 60/2000, Reward: -224.0293583194292, done: False\n",
      "state: [0.18670202 0.14432546], action: [1.0, 0.0167]\n",
      "Episode: 61/2000, Reward: -220.43946445087994, done: False\n",
      "state: [0.05042377 0.11097215], action: [-1.0, 0.0167]\n",
      "Episode: 62/2000, Reward: -222.21968696081984, done: False\n",
      "state: [-0.02483151  0.00931971], action: [-1.0, -0.0167]\n",
      "Episode: 63/2000, Reward: -214.22130820933748, done: False\n",
      "state: [0.11238723 0.24110931], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 64/2000, Reward: -169.064205988213, done: True\n",
      "state: [-0.00572049  0.00592792], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 65/2000, Reward: -227.5479806031366, done: False\n",
      "state: [0.03638077 0.06160026], action: [1.0, 0.005566666666666668]\n",
      "Episode: 66/2000, Reward: -120.24199928081038, done: True\n",
      "state: [0.0086567  0.00447691], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 67/2000, Reward: -222.20883903801365, done: False\n",
      "state: [ 0.04652064 -0.08097693], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 68/2000, Reward: -210.68195041524785, done: False\n",
      "state: [-0.01188623  0.04137734], action: [-1.0, 0.0167]\n",
      "Episode: 69/2000, Reward: -157.2628100433283, done: True\n",
      "state: [-0.0075652   0.00257775], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 70/2000, Reward: -127.50205619638882, done: True\n",
      "state: [ 0.00862939 -0.00091904], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 71/2000, Reward: -212.43494500020753, done: False\n",
      "state: [-0.0126171  -0.01333859], action: [-1.0, 0.0167]\n",
      "Episode: 72/2000, Reward: -197.33578444525253, done: False\n",
      "state: [-0.0484353   0.04618544], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 73/2000, Reward: -214.22187524427127, done: False\n",
      "state: [ 0.04465403 -0.02369232], action: [1.0, -0.0167]\n",
      "Episode: 74/2000, Reward: -187.1609556328973, done: True\n",
      "state: [ 0.00504801 -0.00683257], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 75/2000, Reward: -202.67435916153397, done: False\n",
      "state: [0.07028557 0.11836375], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 76/2000, Reward: -208.89033741291084, done: False\n",
      "state: [0.07301288 0.09116397], action: [-1.0, 0.0167]\n",
      "Episode: 77/2000, Reward: -134.82584788169615, done: True\n",
      "state: [ 0.00114382 -0.00769773], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 78/2000, Reward: -200.88246928470727, done: False\n",
      "state: [-0.05178554 -0.05322295], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 79/2000, Reward: -84.46838055398602, done: True\n",
      "state: [-0.00539212 -0.00887232], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 80/2000, Reward: -220.44901237267752, done: False\n",
      "state: [0.05273816 0.06856252], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 81/2000, Reward: -222.24810943390005, done: False\n",
      "state: [-0.03589022  0.02822184], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 82/2000, Reward: -216.9111020418541, done: False\n",
      "state: [-0.09057685 -0.16438125], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 83/2000, Reward: -207.96141834816888, done: False\n",
      "state: [0.10172422 0.10575487], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 84/2000, Reward: -200.87702632525662, done: False\n",
      "state: [0.03837832 0.13255506], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 85/2000, Reward: -189.27581537877086, done: False\n",
      "state: [0.03915903 0.05592655], action: [-1.0, 0.0167]\n",
      "Episode: 86/2000, Reward: -190.17954336250497, done: False\n",
      "state: [0.01554112 0.04154397], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 87/2000, Reward: -207.95631877293667, done: False\n",
      "state: [-0.06949468 -0.1020392 ], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 88/2000, Reward: -105.4734430165895, done: True\n",
      "state: [-3.16763986e-05  9.31565431e-03], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 89/2000, Reward: -188.41410889512812, done: False\n",
      "state: [0.01563952 0.04717715], action: [-1.0, -0.0167]\n",
      "Episode: 90/2000, Reward: -202.63661736832884, done: False\n",
      "state: [0.06036341 0.0114697 ], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 91/2000, Reward: -117.70925182751479, done: True\n",
      "state: [ 0.00710265 -0.00655121], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 92/2000, Reward: -201.7303442938025, done: False\n",
      "state: [-0.06517441  0.01230345], action: [-1.0, 0.005566666666666668]\n",
      "Episode: 93/2000, Reward: -208.01652340962457, done: False\n",
      "state: [0.05530313 0.03466882], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 94/2000, Reward: -180.29905890094756, done: True\n",
      "state: [-0.0084346  -0.00571397], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 95/2000, Reward: -191.103980197066, done: False\n",
      "state: [-0.05397124  0.06272088], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 96/2000, Reward: -208.85136091144045, done: False\n",
      "state: [ 0.01068959 -0.04598527], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 97/2000, Reward: -184.852411133117, done: False\n",
      "state: [-0.0231768 -0.0309332], action: [-1.0, 0.0167]\n",
      "Episode: 98/2000, Reward: -198.2217464173836, done: False\n",
      "state: [-0.00380699  0.05548924], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 99/2000, Reward: -162.05154214701622, done: True\n",
      "state: [-0.00551118 -0.00398923], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 100/2000, Reward: -183.9975141544969, done: False\n",
      "state: [0.03170001 0.06021255], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 101/2000, Reward: -162.52667024956594, done: True\n",
      "state: [-0.00944268 -0.00594823], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 102/2000, Reward: -200.00258048517182, done: False\n",
      "state: [0.07387776 0.13320182], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 103/2000, Reward: -153.05126327948435, done: True\n",
      "state: [ 0.00312277 -0.00501751], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 104/2000, Reward: -181.29422083418166, done: False\n",
      "state: [0.06043259 0.02782163], action: [1.0, 0.0167]\n",
      "Episode: 105/2000, Reward: -114.52560594123524, done: True\n",
      "state: [ 0.00631938 -0.00146764], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 106/2000, Reward: -184.86876747076278, done: False\n",
      "state: [0.04371736 0.06147559], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 107/2000, Reward: -188.48884440006734, done: False\n",
      "state: [0.00260256 0.03971261], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 108/2000, Reward: -186.51323532670642, done: True\n",
      "state: [0.00983125 0.00601387], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 109/2000, Reward: -194.6418564100206, done: False\n",
      "state: [0.06599669 0.12818774], action: [1.0, -0.005566666666666666]\n",
      "Episode: 110/2000, Reward: -205.35826181613606, done: False\n",
      "state: [-0.01374044 -0.18970772], action: [1.0, -0.005566666666666666]\n",
      "Episode: 111/2000, Reward: -142.73559724611178, done: True\n",
      "state: [-0.00203853  0.00103544], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 112/2000, Reward: -74.0389953670023, done: True\n",
      "state: [-0.00724095 -0.0035526 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 113/2000, Reward: -90.41450213559787, done: True\n",
      "state: [ 0.00235021 -0.00497917], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 114/2000, Reward: -159.07397208470812, done: False\n",
      "state: [0.03731717 0.05414815], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 115/2000, Reward: -200.85515744347828, done: False\n",
      "state: [0.00884515 0.01822262], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 116/2000, Reward: -178.66048758094735, done: False\n",
      "state: [0.0468355  0.06106358], action: [1.0, 0.0167]\n",
      "Episode: 117/2000, Reward: -78.06219969276383, done: True\n",
      "state: [-0.00885601 -0.00438775], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 118/2000, Reward: -89.81537326515675, done: True\n",
      "state: [0.00404076 0.00940099], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 119/2000, Reward: -166.38048238271924, done: True\n",
      "state: [-0.00939173 -0.00252359], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 120/2000, Reward: -88.16601302500436, done: True\n",
      "state: [-0.00951997  0.00873039], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 121/2000, Reward: -160.9077103871863, done: False\n",
      "state: [-0.03491317 -0.03398612], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 122/2000, Reward: -167.94997052137776, done: False\n",
      "state: [-0.06026088 -0.07221967], action: [1.0, 0.0167]\n",
      "Episode: 123/2000, Reward: -173.3103186380699, done: False\n",
      "state: [ 0.00643945 -0.00303338], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 124/2000, Reward: -167.12633199813624, done: False\n",
      "state: [-0.01454127 -0.04183485], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 125/2000, Reward: -184.88789310357257, done: False\n",
      "state: [-0.0356935  -0.02050773], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 126/2000, Reward: -161.71981910138982, done: False\n",
      "state: [-0.04636348 -0.04073683], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 127/2000, Reward: -63.05083731255599, done: True\n",
      "state: [-0.00923337  0.00092733], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 128/2000, Reward: -108.17147735919878, done: True\n",
      "state: [-0.00342206  0.00659666], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 129/2000, Reward: -149.7452779666856, done: True\n",
      "state: [ 0.00795707 -0.00371532], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 130/2000, Reward: -89.49611011389466, done: True\n",
      "state: [-0.00202375  0.00213936], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 131/2000, Reward: -93.68614728394815, done: True\n",
      "state: [-0.0096316   0.00449414], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 132/2000, Reward: -115.31614919395096, done: True\n",
      "state: [0.00787987 0.00199747], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 133/2000, Reward: -101.3880833205672, done: True\n",
      "state: [0.00462133 0.00821605], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 134/2000, Reward: -171.52303537653674, done: False\n",
      "state: [-0.05985149 -0.05719367], action: [-1.0, 0.005566666666666668]\n",
      "Episode: 135/2000, Reward: -97.18407960781754, done: True\n",
      "state: [-0.00861524 -0.00647532], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 136/2000, Reward: -107.30595914780663, done: True\n",
      "state: [ 0.00361701 -0.00202995], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 137/2000, Reward: -159.103345855455, done: False\n",
      "state: [0.14360137 0.17309945], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 138/2000, Reward: -157.95721916339724, done: True\n",
      "state: [0.00128497 0.00451373], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 139/2000, Reward: -67.07120491836847, done: True\n",
      "state: [-0.00619487  0.00396769], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 140/2000, Reward: -159.0928952844001, done: False\n",
      "state: [-0.00897524 -0.020115  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 141/2000, Reward: -75.85418797565583, done: True\n",
      "state: [0.00848172 0.00495479], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 142/2000, Reward: -62.80536061095442, done: True\n",
      "state: [ 0.00933915 -0.0038832 ], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 143/2000, Reward: -74.48989958026799, done: True\n",
      "state: [-0.00360163  0.00784025], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 144/2000, Reward: -115.93472234688934, done: True\n",
      "state: [ 0.00415683 -0.007594  ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 145/2000, Reward: -119.52613312192398, done: True\n",
      "state: [-0.00720678  0.00537958], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 146/2000, Reward: -131.96759916002725, done: True\n",
      "state: [-0.0036822  -0.00463303], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 147/2000, Reward: -152.84609397746584, done: True\n",
      "state: [-0.00918342 -0.00717754], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 148/2000, Reward: -77.24498876876032, done: True\n",
      "state: [ 0.00737705 -0.00734089], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 149/2000, Reward: -166.21181905765005, done: False\n",
      "state: [-0.08987859  0.00253755], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 150/2000, Reward: -107.27177030496759, done: True\n",
      "state: [ 0.00406891 -0.00645121], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 151/2000, Reward: -138.71885631493123, done: True\n",
      "state: [ 0.00688784 -0.0071871 ], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 152/2000, Reward: -105.05946374485337, done: True\n",
      "state: [ 0.00770323 -0.00639859], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 153/2000, Reward: -92.28773525738758, done: True\n",
      "state: [ 0.00643941 -0.0006286 ], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 154/2000, Reward: -78.2857268830301, done: True\n",
      "state: [-0.00316135  0.00732191], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 155/2000, Reward: -69.69164733697883, done: True\n",
      "state: [0.00923114 0.00155537], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 156/2000, Reward: -76.15368551475247, done: True\n",
      "state: [-0.00994729  0.00736184], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 157/2000, Reward: -83.81003581563387, done: True\n",
      "state: [ 0.00825021 -0.00784221], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 158/2000, Reward: -123.36836626892979, done: True\n",
      "state: [0.00759102 0.00449393], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 159/2000, Reward: -148.44508513210283, done: False\n",
      "state: [0.00750796 0.13047646], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 160/2000, Reward: -72.9319856451583, done: True\n",
      "state: [0.00184373 0.00058715], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 161/2000, Reward: -117.05107337770144, done: True\n",
      "state: [0.00999726 0.00311078], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 162/2000, Reward: -79.29107617854655, done: True\n",
      "state: [-0.00217199 -0.0093657 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 163/2000, Reward: -55.23778038997693, done: True\n",
      "state: [-0.00948661 -0.00643539], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 164/2000, Reward: -69.38513933587345, done: True\n",
      "state: [ 0.00588769 -0.00407444], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 165/2000, Reward: -51.28426643387132, done: True\n",
      "state: [-0.00340995 -0.00075463], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 166/2000, Reward: -92.38596702819294, done: True\n",
      "state: [-0.0080746  -0.00417101], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 167/2000, Reward: -131.97107584382633, done: True\n",
      "state: [ 0.00508821 -0.00198288], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 168/2000, Reward: -76.24501656230967, done: True\n",
      "state: [-0.00856922 -0.00729666], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 169/2000, Reward: -67.80752839248561, done: True\n",
      "state: [-0.00542997  0.00397852], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 170/2000, Reward: -65.6095747326334, done: True\n",
      "state: [ 0.00206847 -0.00617191], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 171/2000, Reward: -90.2802667915919, done: True\n",
      "state: [-0.00852822 -0.00190273], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 172/2000, Reward: -68.6066940798459, done: True\n",
      "state: [0.00248907 0.00676769], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 173/2000, Reward: -46.17370860685186, done: True\n",
      "state: [ 0.00707626 -0.00571334], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 174/2000, Reward: -69.40943725202536, done: True\n",
      "state: [-0.00233087 -0.00730067], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 175/2000, Reward: -86.18170900205574, done: True\n",
      "state: [-0.0030749  -0.00021519], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 176/2000, Reward: -96.9769450723919, done: True\n",
      "state: [ 0.00765698 -0.00639506], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 177/2000, Reward: -103.53482159301947, done: True\n",
      "state: [ 0.00926451 -0.00226052], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 178/2000, Reward: -68.37123843653221, done: True\n",
      "state: [ 0.00399754 -0.00882985], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 179/2000, Reward: -123.84392641495866, done: True\n",
      "state: [-0.00062348 -0.00921239], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 180/2000, Reward: -136.20011947047797, done: True\n",
      "state: [-0.00617169  0.00709767], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 181/2000, Reward: -89.15813205755609, done: True\n",
      "state: [0.00333812 0.00714522], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 182/2000, Reward: -70.41042776485264, done: True\n",
      "state: [ 0.00967382 -0.00769794], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 183/2000, Reward: -109.52302472747509, done: True\n",
      "state: [-0.00713872 -0.00970055], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 184/2000, Reward: -110.98786357937936, done: True\n",
      "state: [-0.00786783 -0.00466228], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 185/2000, Reward: -118.86900166580696, done: True\n",
      "state: [ 0.00224116 -0.00128575], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 186/2000, Reward: -66.85025605251023, done: True\n",
      "state: [-0.00935685 -0.00737526], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 187/2000, Reward: -76.93919000053484, done: True\n",
      "state: [-0.00693252 -0.00796745], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 188/2000, Reward: -41.70475016227969, done: True\n",
      "state: [-0.00869471 -0.00445373], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 189/2000, Reward: -79.54362156731044, done: True\n",
      "state: [ 0.00465879 -0.00939566], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 190/2000, Reward: -55.58255591772665, done: True\n",
      "state: [0.00635751 0.00391768], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 191/2000, Reward: -86.38131928441258, done: True\n",
      "state: [-0.00043165 -0.00332438], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 192/2000, Reward: -77.93301649180341, done: True\n",
      "state: [ 0.00771257 -0.00030537], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 193/2000, Reward: -68.3169976491319, done: True\n",
      "state: [ 0.00165798 -0.0062451 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 194/2000, Reward: -57.14488638476959, done: True\n",
      "state: [-0.0019603  -0.00080789], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 195/2000, Reward: -56.0581492017531, done: True\n",
      "state: [-0.00363947 -0.00126892], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 196/2000, Reward: -47.72668023418823, done: True\n",
      "state: [ 0.00759983 -0.00517335], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 197/2000, Reward: -56.49008990813612, done: True\n",
      "state: [-0.00026086 -0.0089668 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 198/2000, Reward: -86.30319947512852, done: True\n",
      "state: [-0.00725491 -0.00445475], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 199/2000, Reward: -80.61083623185844, done: True\n",
      "state: [-0.00953724 -0.00618674], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 200/2000, Reward: -68.06375996790123, done: True\n",
      "state: [0.00782568 0.00876104], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 201/2000, Reward: -93.18523611347872, done: True\n",
      "state: [ 0.00992011 -0.00149895], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 202/2000, Reward: -87.59564733267928, done: True\n",
      "state: [-0.00986716  0.00140993], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 203/2000, Reward: -89.83726399553277, done: True\n",
      "state: [-0.00952876 -0.00662298], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 204/2000, Reward: -83.72755140468342, done: True\n",
      "state: [-0.00785987 -0.00476092], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 205/2000, Reward: -65.6277621844049, done: True\n",
      "state: [-0.00701503 -0.00315587], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 206/2000, Reward: -76.27779631240686, done: True\n",
      "state: [0.0049524  0.00402119], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 207/2000, Reward: -117.72989760282297, done: True\n",
      "state: [-0.00299853 -0.00911124], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 208/2000, Reward: -56.054555694445426, done: True\n",
      "state: [ 0.00446226 -0.00726002], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 209/2000, Reward: -84.38546398601966, done: True\n",
      "state: [-0.00900783 -0.00614057], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 210/2000, Reward: -72.94116870747487, done: True\n",
      "state: [0.00843117 0.00304062], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 211/2000, Reward: -108.53306708689017, done: True\n",
      "state: [-0.00364646 -0.00469123], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 212/2000, Reward: -88.27342181969622, done: True\n",
      "state: [-0.00433828 -0.00932024], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 213/2000, Reward: -56.98709567517206, done: True\n",
      "state: [-0.002759   -0.00480694], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 214/2000, Reward: -52.5052892056824, done: True\n",
      "state: [-0.00357508  0.00717624], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 215/2000, Reward: -84.17466494645296, done: True\n",
      "state: [-0.00744575 -0.00353189], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 216/2000, Reward: -59.505642639023, done: True\n",
      "state: [ 0.00581486 -0.0078752 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 217/2000, Reward: -68.38944295976, done: True\n",
      "state: [ 0.00770635 -0.00649807], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 218/2000, Reward: -68.58675627384305, done: True\n",
      "state: [ 0.00165669 -0.00734694], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 219/2000, Reward: -45.178646187454106, done: True\n",
      "state: [-0.00917735  0.002235  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 220/2000, Reward: -84.14079440248243, done: True\n",
      "state: [-0.00170347 -0.00837549], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 221/2000, Reward: -52.64235240971872, done: True\n",
      "state: [ 0.00566452 -0.00884911], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 222/2000, Reward: -84.50877391139824, done: True\n",
      "state: [0.00918781 0.00078396], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 223/2000, Reward: -63.85477173620453, done: True\n",
      "state: [ 0.00813433 -0.00965372], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 224/2000, Reward: -64.71777290463227, done: True\n",
      "state: [-0.00086407  0.00619821], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 225/2000, Reward: -57.583517709588584, done: True\n",
      "state: [ 0.00788299 -0.00291026], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 226/2000, Reward: -48.09699272179323, done: True\n",
      "state: [ 0.00741886 -0.00367163], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 227/2000, Reward: -70.39545651209471, done: True\n",
      "state: [ 0.00428035 -0.00655416], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 228/2000, Reward: -38.391687300094254, done: True\n",
      "state: [ 0.00305383 -0.0092849 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 229/2000, Reward: -63.387385649995615, done: True\n",
      "state: [-0.00591418  0.00070656], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 230/2000, Reward: -48.27142924343139, done: True\n",
      "state: [ 0.00448837 -0.00759087], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 231/2000, Reward: -87.39112679980035, done: True\n",
      "state: [-0.00533718  0.0071275 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 232/2000, Reward: -54.68640047681811, done: True\n",
      "state: [0.00818309 0.00623304], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 233/2000, Reward: -62.04303688465508, done: True\n",
      "state: [-0.00019798  0.00064457], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 234/2000, Reward: -51.958430922691676, done: True\n",
      "state: [-0.0062301   0.00560353], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 235/2000, Reward: -44.90128608555007, done: True\n",
      "state: [ 0.00158038 -0.00315468], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 236/2000, Reward: -53.26392754916733, done: True\n",
      "state: [0.00758452 0.0026197 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 237/2000, Reward: -63.03120556810839, done: True\n",
      "state: [ 0.00043349 -0.00908324], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 238/2000, Reward: -55.81361437089358, done: True\n",
      "state: [-0.00823631  0.0052745 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 239/2000, Reward: -42.169605807040014, done: True\n",
      "state: [ 0.00971907 -0.00817002], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 240/2000, Reward: -54.261261058100104, done: True\n",
      "state: [-0.00570992 -0.00103743], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 241/2000, Reward: -68.69683296309981, done: True\n",
      "state: [ 0.00833053 -0.00793643], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 242/2000, Reward: -45.79081350026281, done: True\n",
      "state: [-0.00419951 -0.00468288], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 243/2000, Reward: -62.20958410443489, done: True\n",
      "state: [ 0.00740069 -0.00927127], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 244/2000, Reward: -62.06940884935678, done: True\n",
      "state: [-0.00766017 -0.00273183], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 245/2000, Reward: -40.07215465984081, done: True\n",
      "state: [-0.00666432  0.00153159], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 246/2000, Reward: -54.38177688895648, done: True\n",
      "state: [-0.00192972  0.00875012], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 247/2000, Reward: -47.496862648426976, done: True\n",
      "state: [0.0065324  0.00267918], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 248/2000, Reward: -52.61280752747088, done: True\n",
      "state: [0.00032198 0.00925555], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 249/2000, Reward: -52.17333325234764, done: True\n",
      "state: [-0.00194626 -0.00788598], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 250/2000, Reward: -69.50010312499859, done: True\n",
      "state: [ 0.00929656 -0.00247785], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 251/2000, Reward: -59.14750569220865, done: True\n",
      "state: [-0.00190717  0.00973575], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 252/2000, Reward: -54.06836276863024, done: True\n",
      "state: [-0.00244726  0.00971118], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 253/2000, Reward: -60.47302744805313, done: True\n",
      "state: [-0.00921877 -0.00288174], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 254/2000, Reward: -51.13608434172125, done: True\n",
      "state: [ 0.00594234 -0.00744541], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 255/2000, Reward: -63.47896662034792, done: True\n",
      "state: [-0.00875298  0.00935441], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 256/2000, Reward: -55.522248062960955, done: True\n",
      "state: [-0.00671727  0.00891602], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 257/2000, Reward: -46.92249095363842, done: True\n",
      "state: [-0.00890099  0.00717941], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 258/2000, Reward: -48.58592338513904, done: True\n",
      "state: [0.00440359 0.00106451], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 259/2000, Reward: -44.678220991585675, done: True\n",
      "state: [-0.00810807  0.00886645], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 260/2000, Reward: -69.14012582550238, done: True\n",
      "state: [ 0.00890762 -0.00502179], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 261/2000, Reward: -51.80714112819308, done: True\n",
      "state: [ 0.0096471  -0.00534573], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 262/2000, Reward: -44.38716769137805, done: True\n",
      "state: [ 0.00117834 -0.00714413], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 263/2000, Reward: -42.57041260339785, done: True\n",
      "state: [0.00701155 0.00720086], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 264/2000, Reward: -45.04724281893909, done: True\n",
      "state: [ 0.00292498 -0.00157826], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 265/2000, Reward: -41.19239022821973, done: True\n",
      "state: [-0.0053626   0.00833095], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 266/2000, Reward: -47.04718551317045, done: True\n",
      "state: [ 0.00739945 -0.00210126], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 267/2000, Reward: -53.13032275521399, done: True\n",
      "state: [-0.00189612 -0.00905151], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 268/2000, Reward: -46.61108538055227, done: True\n",
      "state: [0.00416867 0.00020792], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 269/2000, Reward: -43.80687256656526, done: True\n",
      "state: [-0.00915313  0.00705386], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 270/2000, Reward: -41.63203184234864, done: True\n",
      "state: [-0.00438335  0.00912719], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 271/2000, Reward: -42.825403085665826, done: True\n",
      "state: [0.00178487 0.0042395 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 272/2000, Reward: -41.16008592694188, done: True\n",
      "state: [-0.00810642 -0.0037511 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 273/2000, Reward: -50.47437647691778, done: True\n",
      "state: [-0.0019777  0.0088327], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 274/2000, Reward: -42.92606788298141, done: True\n",
      "state: [-0.0037414   0.00634126], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 275/2000, Reward: -39.60000074597158, done: True\n",
      "state: [0.00891191 0.00042635], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 276/2000, Reward: -43.37849064309675, done: True\n",
      "state: [ 0.00734119 -0.00195887], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 277/2000, Reward: -47.918921742518975, done: True\n",
      "state: [-0.0069351   0.00934108], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 278/2000, Reward: -51.479278459936104, done: True\n",
      "state: [-0.00759955  0.00625037], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 279/2000, Reward: -42.361457332244896, done: True\n",
      "state: [-0.00297891  0.00938288], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 280/2000, Reward: -46.48403479027584, done: True\n",
      "state: [ 0.00113155 -0.00057549], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 281/2000, Reward: -38.35777769467139, done: True\n",
      "state: [-0.00917597  0.00784542], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 282/2000, Reward: -46.12305580052138, done: True\n",
      "state: [ 0.00774787 -0.00209739], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 283/2000, Reward: -43.01692339326145, done: True\n",
      "state: [0.00121692 0.00126597], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 284/2000, Reward: -37.62010069180298, done: True\n",
      "state: [ 0.00279178 -0.00971937], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 285/2000, Reward: -38.581757543724756, done: True\n",
      "state: [ 0.00645401 -0.00786424], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 286/2000, Reward: -40.3720035943505, done: True\n",
      "state: [0.00171326 0.00425508], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 287/2000, Reward: -40.78091009404118, done: True\n",
      "state: [-0.00419641 -0.00224764], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 288/2000, Reward: -43.15708751540997, done: True\n",
      "state: [-0.00895154  0.0084054 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 289/2000, Reward: -30.2311028487487, done: True\n",
      "state: [ 0.0039382  -0.00371414], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 290/2000, Reward: -40.13720112010521, done: True\n",
      "state: [0.00247518 0.00309641], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 291/2000, Reward: -49.27012250700318, done: True\n",
      "state: [-0.00777085  0.00219793], action: [-0.33333333333333337, -0.005566666666666666]\n",
      "Episode: 292/2000, Reward: -45.30547225584882, done: True\n",
      "state: [ 0.00956106 -0.00047398], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 293/2000, Reward: -31.394670975115698, done: True\n",
      "state: [ 0.00836392 -0.00579877], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 294/2000, Reward: -47.90418924970655, done: True\n",
      "state: [ 0.00370715 -0.0005704 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 295/2000, Reward: -45.742034960992164, done: True\n",
      "state: [-0.00271909  0.00476913], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 296/2000, Reward: -41.48060283963767, done: True\n",
      "state: [-0.00185552  0.00416211], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 297/2000, Reward: -97.93117286813656, done: False\n",
      "state: [-0.34118887 -0.57278831], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 298/2000, Reward: -42.35424171640269, done: True\n",
      "state: [-0.00257321 -0.00622325], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 299/2000, Reward: -73.57327183134686, done: True\n",
      "state: [0.00594531 0.00230499], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 300/2000, Reward: -37.904429446577005, done: True\n",
      "state: [-0.00946247  0.00853416], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 301/2000, Reward: -67.40484956303469, done: True\n",
      "state: [-0.00131271  0.00509131], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 302/2000, Reward: -46.22997506604405, done: True\n",
      "state: [-0.0073263   0.00802589], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 303/2000, Reward: -33.67561452160749, done: True\n",
      "state: [ 0.00700295 -0.0046632 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 304/2000, Reward: -39.51565673725899, done: True\n",
      "state: [ 0.00139213 -0.0033058 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 305/2000, Reward: -38.60367132462126, done: True\n",
      "state: [-0.00249487  0.00372643], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 306/2000, Reward: -39.559759032304825, done: True\n",
      "state: [ 0.00664108 -0.00467811], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 307/2000, Reward: -56.24025148149736, done: True\n",
      "state: [ 0.00593495 -0.00050029], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 308/2000, Reward: -47.70495473433377, done: True\n",
      "state: [0.00327197 0.00247151], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 309/2000, Reward: -49.36907436278468, done: True\n",
      "state: [-0.00443933  0.00595699], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 310/2000, Reward: -35.391416949184396, done: True\n",
      "state: [ 0.00960167 -0.00869702], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 311/2000, Reward: -40.9595038272576, done: True\n",
      "state: [0.00895428 0.00137203], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 312/2000, Reward: -37.69455695532911, done: True\n",
      "state: [-0.00284857  0.00083453], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 313/2000, Reward: -32.69083107757006, done: True\n",
      "state: [0.00611958 0.00660984], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 314/2000, Reward: -35.835112234527415, done: True\n",
      "state: [0.00863904 0.00446489], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 315/2000, Reward: -45.68968804119216, done: True\n",
      "state: [-0.00255575  0.00833784], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 316/2000, Reward: -54.47890228137319, done: True\n",
      "state: [ 0.00888283 -0.00853044], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 317/2000, Reward: -39.89955240170492, done: True\n",
      "state: [0.00581782 0.00477205], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 318/2000, Reward: -37.4497107908489, done: True\n",
      "state: [ 0.00123071 -0.00108454], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 319/2000, Reward: -59.04763865185262, done: True\n",
      "state: [-0.00905534  0.00772999], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 320/2000, Reward: -39.334145172924295, done: True\n",
      "state: [ 0.00134355 -0.00349409], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 321/2000, Reward: -36.33629250343822, done: True\n",
      "state: [0.00761843 0.00029775], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 322/2000, Reward: -38.34636755418819, done: True\n",
      "state: [-0.00811397  0.00686156], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 323/2000, Reward: -37.355526672608676, done: True\n",
      "state: [-0.00710306  0.00758995], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 324/2000, Reward: -38.02331303618808, done: True\n",
      "state: [-0.00093139  0.00972267], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 325/2000, Reward: -41.892983468838175, done: True\n",
      "state: [0.00871373 0.00183126], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 326/2000, Reward: -32.280616736452394, done: True\n",
      "state: [-0.00805112 -0.00054234], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 327/2000, Reward: -33.2382019880506, done: True\n",
      "state: [-0.00540889  0.00104365], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 328/2000, Reward: -45.116708632100625, done: True\n",
      "state: [ 0.00598581 -0.00341907], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 329/2000, Reward: -34.73259788808805, done: True\n",
      "state: [-0.007198    0.00934398], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 330/2000, Reward: -39.01421538284556, done: True\n",
      "state: [-0.00339031  0.00336484], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 331/2000, Reward: -44.46720860492631, done: True\n",
      "state: [-0.0071957   0.00296015], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 332/2000, Reward: -33.65427846636497, done: True\n",
      "state: [-0.00952528  0.00444674], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 333/2000, Reward: -53.82447895382873, done: True\n",
      "state: [0.00172685 0.00056169], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 334/2000, Reward: -45.45168927529215, done: True\n",
      "state: [-0.00420626  0.00057268], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 335/2000, Reward: -35.71640112558546, done: True\n",
      "state: [0.00777356 0.00026694], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 336/2000, Reward: -37.664309867292076, done: True\n",
      "state: [-0.00938455  0.00842616], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 337/2000, Reward: -31.904773571950106, done: True\n",
      "state: [ 0.00582178 -0.00163004], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 338/2000, Reward: -42.48067493816932, done: True\n",
      "state: [-0.00570214  0.00568066], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 339/2000, Reward: -40.88925023463887, done: True\n",
      "state: [-0.00867133  0.00785466], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 340/2000, Reward: -43.688850206016674, done: True\n",
      "state: [0.00318926 0.0032492 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 341/2000, Reward: -29.242678369797048, done: True\n",
      "state: [-0.00776271  0.00456802], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 342/2000, Reward: -28.794064688306854, done: True\n",
      "state: [ 0.00869088 -0.00071333], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 343/2000, Reward: -32.89665916408636, done: True\n",
      "state: [-0.00785708  0.00740625], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 344/2000, Reward: -32.84111819910529, done: True\n",
      "state: [-0.00664294  0.00478554], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 345/2000, Reward: -47.66995636339617, done: True\n",
      "state: [ 0.00509553 -0.00423994], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 346/2000, Reward: -32.69975698861677, done: True\n",
      "state: [-0.00539021  0.00158109], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 347/2000, Reward: -28.240514056796375, done: True\n",
      "state: [ 0.00804792 -0.0038526 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 348/2000, Reward: -33.24491213110791, done: True\n",
      "state: [-0.0013199  0.0089027], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 349/2000, Reward: -29.454355084481023, done: True\n",
      "state: [-0.00298305  0.00161498], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 350/2000, Reward: -36.32970512421691, done: True\n",
      "state: [ 0.0046916  -0.00191299], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 351/2000, Reward: -31.77684620510321, done: True\n",
      "state: [-0.00847519  0.00467799], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 352/2000, Reward: -31.16502082275682, done: True\n",
      "state: [-0.00118314 -0.00166005], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 353/2000, Reward: -38.2524027234842, done: True\n",
      "state: [-0.00396123 -0.00444729], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 354/2000, Reward: -40.56702818957261, done: True\n",
      "state: [-0.00952982  0.00626583], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 355/2000, Reward: -29.167400341523397, done: True\n",
      "state: [ 0.001596   -0.00075002], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 356/2000, Reward: -31.67393711701898, done: True\n",
      "state: [ 0.00521991 -0.00511853], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 357/2000, Reward: -32.94838762063132, done: True\n",
      "state: [-0.00626769 -0.0007532 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 358/2000, Reward: -31.67644474043043, done: True\n",
      "state: [0.00800331 0.00420248], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 359/2000, Reward: -40.1244339145562, done: True\n",
      "state: [ 0.00745074 -0.00250257], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 360/2000, Reward: -41.77888866479787, done: True\n",
      "state: [ 0.00174098 -0.00247879], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 361/2000, Reward: -34.502952914419424, done: True\n",
      "state: [ 0.0053873  -0.00497327], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 362/2000, Reward: -31.68674966145207, done: True\n",
      "state: [ 0.00122235 -0.00403122], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 363/2000, Reward: -26.15098142620742, done: True\n",
      "state: [ 0.0061533  -0.00374944], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 364/2000, Reward: -33.34899229548338, done: True\n",
      "state: [-0.00911916  0.00374329], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 365/2000, Reward: -26.262326629306493, done: True\n",
      "state: [ 0.00399987 -0.00275425], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 366/2000, Reward: -29.681452180480616, done: True\n",
      "state: [ 0.0046109  -0.00344377], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 367/2000, Reward: -32.38313669507291, done: True\n",
      "state: [-0.00886871  0.00505855], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 368/2000, Reward: -26.17140350443139, done: True\n",
      "state: [ 0.00117421 -0.00690675], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 369/2000, Reward: -33.10994190374717, done: True\n",
      "state: [ 0.00975281 -0.00650048], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 370/2000, Reward: -32.23155921849844, done: True\n",
      "state: [ 0.00329556 -0.00530086], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 371/2000, Reward: -32.60016741701436, done: True\n",
      "state: [ 0.00177283 -0.00332061], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 372/2000, Reward: -41.34299343883192, done: True\n",
      "state: [-0.00122905  0.00061594], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 373/2000, Reward: -38.236729839636865, done: True\n",
      "state: [-0.00256055  0.0007705 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 374/2000, Reward: -36.629464852907304, done: True\n",
      "state: [-0.00240193 -0.00057577], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 375/2000, Reward: -39.915889716961914, done: True\n",
      "state: [-0.00829383 -0.00061078], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 376/2000, Reward: -40.009195209648524, done: True\n",
      "state: [-0.00301943  0.00191501], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 377/2000, Reward: -40.02031008396513, done: True\n",
      "state: [0.0066462  0.00082194], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 378/2000, Reward: -29.682452131498163, done: True\n",
      "state: [ 0.0093581 -0.0021128], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 379/2000, Reward: -38.348179992046376, done: True\n",
      "state: [ 0.00921625 -0.00331344], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 380/2000, Reward: -36.13116903983492, done: True\n",
      "state: [ 0.00666352 -0.00078247], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 381/2000, Reward: -27.353201689457247, done: True\n",
      "state: [ 0.00115273 -0.00476152], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 382/2000, Reward: -34.120218291137455, done: True\n",
      "state: [-0.00837055  0.00607597], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 383/2000, Reward: -34.23213524311987, done: True\n",
      "state: [ 0.00842796 -0.00585053], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 384/2000, Reward: -24.18992963995209, done: True\n",
      "state: [0.00430465 0.001939  ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 385/2000, Reward: -27.67596110090637, done: True\n",
      "state: [-0.00838197 -0.00119083], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 386/2000, Reward: -31.013687000223964, done: True\n",
      "state: [-0.00127546  0.00481536], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 387/2000, Reward: -26.260098338371474, done: True\n",
      "state: [ 0.00181076 -0.0016693 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 388/2000, Reward: -37.363091614000616, done: True\n",
      "state: [-0.009024    0.00255204], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 389/2000, Reward: -29.919370594805102, done: True\n",
      "state: [ 0.00920269 -0.00474381], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 390/2000, Reward: -27.13681874583678, done: True\n",
      "state: [ 0.00494306 -0.00251885], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 391/2000, Reward: -26.838168522356728, done: True\n",
      "state: [ 0.00676691 -0.00384935], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 392/2000, Reward: -33.34734983956931, done: True\n",
      "state: [ 0.00957955 -0.00725718], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 393/2000, Reward: -32.44828860447951, done: True\n",
      "state: [ 0.00656083 -0.00380813], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 394/2000, Reward: -31.48119063252367, done: True\n",
      "state: [ 0.00805867 -0.00243773], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 395/2000, Reward: -27.597109447702934, done: True\n",
      "state: [ 0.00450599 -0.00554048], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 396/2000, Reward: -25.921040546735174, done: True\n",
      "state: [ 0.00116814 -0.00642702], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 397/2000, Reward: -35.510788738207665, done: True\n",
      "state: [-0.00970135  0.00399968], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 398/2000, Reward: -28.470988693548225, done: True\n",
      "state: [-0.00876454 -0.0021163 ], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 399/2000, Reward: -30.266124602691647, done: True\n",
      "state: [-0.0015897 -0.0046581], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 400/2000, Reward: -22.15912642377045, done: True\n",
      "state: [ 0.00896048 -0.0052205 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 401/2000, Reward: -23.388244724132846, done: True\n",
      "state: [ 0.00864384 -0.00908844], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 402/2000, Reward: -29.280540740720514, done: True\n",
      "state: [ 0.00202508 -0.00325891], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 403/2000, Reward: -28.130609170532814, done: True\n",
      "state: [0.0077035  0.00039865], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 404/2000, Reward: -28.143335298594234, done: True\n",
      "state: [-0.00547772 -0.00378144], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 405/2000, Reward: -26.830446354901458, done: True\n",
      "state: [ 0.00707973 -0.00476221], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 406/2000, Reward: -31.695618396700684, done: True\n",
      "state: [ 0.00121911 -0.0063063 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 407/2000, Reward: -24.814323748211038, done: True\n",
      "state: [ 0.00807535 -0.00594825], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 408/2000, Reward: -22.79845039111485, done: True\n",
      "state: [ 0.00686155 -0.00653728], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 409/2000, Reward: -25.14076964908163, done: True\n",
      "state: [ 0.00366591 -0.0005127 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 410/2000, Reward: -26.06391433289173, done: True\n",
      "state: [ 0.00788148 -0.00302015], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 411/2000, Reward: -24.25506035026042, done: True\n",
      "state: [ 0.00878731 -0.00435946], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 412/2000, Reward: -29.609963257676373, done: True\n",
      "state: [-0.00583374 -0.00212801], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 413/2000, Reward: -24.020321148193368, done: True\n",
      "state: [ 0.00736958 -0.00604485], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 414/2000, Reward: -30.24882259722169, done: True\n",
      "state: [ 0.00132177 -0.00630001], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 415/2000, Reward: -32.694601686687434, done: True\n",
      "state: [ 0.00895695 -0.00913177], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 416/2000, Reward: -23.375323258731235, done: True\n",
      "state: [ 0.00665676 -0.00580188], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 417/2000, Reward: -23.42273998596383, done: True\n",
      "state: [ 0.00968401 -0.0041164 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 418/2000, Reward: -30.593482497364462, done: True\n",
      "state: [ 0.00112863 -0.0068589 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 419/2000, Reward: -25.954150827850437, done: True\n",
      "state: [ 0.00838142 -0.00540994], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 420/2000, Reward: -30.243784324420997, done: True\n",
      "state: [ 0.00856001 -0.00529271], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 421/2000, Reward: -30.45269586159648, done: True\n",
      "state: [ 0.00513651 -0.00451568], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 422/2000, Reward: -24.703155957392045, done: True\n",
      "state: [ 0.00116473 -0.00214318], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 423/2000, Reward: -28.02622601732435, done: True\n",
      "state: [-0.00433429 -0.00058451], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 424/2000, Reward: -30.52306097495646, done: True\n",
      "state: [0.00775609 0.00449315], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 425/2000, Reward: -29.265062286459383, done: True\n",
      "state: [ 0.00638467 -0.00229817], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 426/2000, Reward: -27.682807546301422, done: True\n",
      "state: [ 0.009041   -0.00398718], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 427/2000, Reward: -27.601737406535598, done: True\n",
      "state: [0.00131092 0.00011434], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 428/2000, Reward: -19.905032849184614, done: True\n",
      "state: [ 0.00508151 -0.00343596], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 429/2000, Reward: -27.46504617832495, done: True\n",
      "state: [ 0.00457435 -0.00012037], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 430/2000, Reward: -25.259571055372156, done: True\n",
      "state: [0.00300062 0.0042538 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 431/2000, Reward: -25.516349494155556, done: True\n",
      "state: [ 0.00924283 -0.00766493], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 432/2000, Reward: -30.05699801788867, done: True\n",
      "state: [ 0.0074903  -0.00325412], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 433/2000, Reward: -30.905690565391673, done: True\n",
      "state: [ 0.00205564 -0.00300626], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 434/2000, Reward: -28.683513671543544, done: True\n",
      "state: [ 0.00134149 -0.00140941], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 435/2000, Reward: -29.338256562680293, done: True\n",
      "state: [ 0.00244994 -0.00179094], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 436/2000, Reward: -27.511096175744274, done: True\n",
      "state: [ 0.00133448 -0.00073579], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 437/2000, Reward: -28.24749206671769, done: True\n",
      "state: [ 0.00677387 -0.00505814], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 438/2000, Reward: -33.836767626274266, done: True\n",
      "state: [ 0.00126455 -0.00384109], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 439/2000, Reward: -27.72969426512452, done: True\n",
      "state: [ 0.00643092 -0.00183855], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 440/2000, Reward: -23.808211543957356, done: True\n",
      "state: [ 0.00137091 -0.00478432], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 441/2000, Reward: -28.463909951436488, done: True\n",
      "state: [0.00930772 0.00152828], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 442/2000, Reward: -22.475876208573233, done: True\n",
      "state: [ 0.0079808  -0.00186148], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 443/2000, Reward: -27.94004152740816, done: True\n",
      "state: [-0.00848981  0.00615192], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 444/2000, Reward: -31.415360843309188, done: True\n",
      "state: [-0.00365638  0.00324186], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 445/2000, Reward: -21.75907185564707, done: True\n",
      "state: [ 0.00344713 -0.00390493], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 446/2000, Reward: -23.388737961802672, done: True\n",
      "state: [ 0.0011473  -0.00206702], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 447/2000, Reward: -30.901051053349043, done: True\n",
      "state: [ 0.00417316 -0.00690478], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 448/2000, Reward: -25.818165749992062, done: True\n",
      "state: [ 0.00848871 -0.004739  ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 449/2000, Reward: -32.67893059542583, done: True\n",
      "state: [ 0.00441715 -0.00610572], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 450/2000, Reward: -28.894476239776836, done: True\n",
      "state: [ 0.00744066 -0.00836213], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 451/2000, Reward: -26.798117197693024, done: True\n",
      "state: [ 0.00697122 -0.00653285], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 452/2000, Reward: -23.24253974805384, done: True\n",
      "state: [4.75253976e-03 6.97261840e-05], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 453/2000, Reward: -23.363448583272604, done: True\n",
      "state: [ 0.00580644 -0.00747242], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 454/2000, Reward: -21.0983021496438, done: True\n",
      "state: [-0.00744717  0.00526334], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 455/2000, Reward: -26.271202329093953, done: True\n",
      "state: [-0.0084558  -0.00302447], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 456/2000, Reward: -26.624686484853775, done: True\n",
      "state: [ 0.000707   -0.00878769], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 457/2000, Reward: -23.615342266083026, done: True\n",
      "state: [ 0.00162267 -0.00350568], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 458/2000, Reward: -22.700114376194673, done: True\n",
      "state: [ 0.00786725 -0.00367338], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 459/2000, Reward: -23.809861307200677, done: True\n",
      "state: [ 0.00037697 -0.00880614], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 460/2000, Reward: -21.899824451905996, done: True\n",
      "state: [ 0.00278085 -0.00061752], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 461/2000, Reward: -26.729812094064336, done: True\n",
      "state: [0.00161339 0.00066039], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 462/2000, Reward: -28.02183147327943, done: True\n",
      "state: [0.00469532 0.00470121], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 463/2000, Reward: -25.85555375620721, done: True\n",
      "state: [ 0.00191288 -0.00330948], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 464/2000, Reward: -25.11946035643427, done: True\n",
      "state: [ 0.00123217 -0.00704463], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 465/2000, Reward: -25.819720313704174, done: True\n",
      "state: [ 0.00338958 -0.00223051], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 466/2000, Reward: -24.24995053973352, done: True\n",
      "state: [ 0.00882032 -0.00386531], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 467/2000, Reward: -24.940304312650976, done: True\n",
      "state: [ 0.00157237 -0.0016929 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 468/2000, Reward: -25.526859771160133, done: True\n",
      "state: [ 0.00955189 -0.00227782], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 469/2000, Reward: -23.849771184593344, done: True\n",
      "state: [ 0.00116085 -0.00258732], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 470/2000, Reward: -26.28915889262717, done: True\n",
      "state: [ 0.00229944 -0.0024601 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 471/2000, Reward: -26.79883909598461, done: True\n",
      "state: [-0.00263318  0.00625915], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 472/2000, Reward: -28.347360183777656, done: True\n",
      "state: [-0.00251471 -0.00168641], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 473/2000, Reward: -22.38697978922755, done: True\n",
      "state: [ 0.00820948 -0.00367673], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 474/2000, Reward: -20.892092951807072, done: True\n",
      "state: [0.00941478 0.00143196], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 475/2000, Reward: -21.957588749236667, done: True\n",
      "state: [ 0.00367192 -0.0021219 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 476/2000, Reward: -23.536970493548758, done: True\n",
      "state: [ 0.00119927 -0.00688721], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 477/2000, Reward: -22.907968920222675, done: True\n",
      "state: [ 0.00243927 -0.0090116 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 478/2000, Reward: -20.609405522693752, done: True\n",
      "state: [ 0.00654418 -0.00823204], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 479/2000, Reward: -22.91651048782369, done: True\n",
      "state: [ 0.00729065 -0.00078238], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 480/2000, Reward: -23.452670113971475, done: True\n",
      "state: [ 0.00084878 -0.00897078], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 481/2000, Reward: -19.861874302674597, done: True\n",
      "state: [ 0.00853604 -0.00664207], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 482/2000, Reward: -27.272094566902094, done: True\n",
      "state: [ 0.00622034 -0.00829141], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 483/2000, Reward: -22.072423223983364, done: True\n",
      "state: [ 0.00851786 -0.00824751], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 484/2000, Reward: -21.074182710077395, done: True\n",
      "state: [ 0.00209366 -0.0049835 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 485/2000, Reward: -20.052715674868853, done: True\n",
      "state: [ 0.00466825 -0.00885188], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 486/2000, Reward: -20.962749270281172, done: True\n",
      "state: [ 0.00879516 -0.00899022], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 487/2000, Reward: -23.29763345141555, done: True\n",
      "state: [ 0.00677842 -0.005548  ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 488/2000, Reward: -21.258589929839854, done: True\n",
      "state: [ 0.00156386 -0.00339655], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 489/2000, Reward: -22.709322355710682, done: True\n",
      "state: [ 0.00268077 -0.00702408], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 490/2000, Reward: -24.79495359638686, done: True\n",
      "state: [ 0.00347497 -0.00630804], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 491/2000, Reward: -24.60207852017458, done: True\n",
      "state: [ 0.00125034 -0.00871151], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 492/2000, Reward: -23.71282430764988, done: True\n",
      "state: [ 0.00512837 -0.00167723], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 493/2000, Reward: -22.063246314956114, done: True\n",
      "state: [-0.00849193  0.00466352], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 494/2000, Reward: -23.068890271031016, done: True\n",
      "state: [ 0.00372025 -0.00223216], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 495/2000, Reward: -25.594418936815682, done: True\n",
      "state: [-0.00259321 -0.0057121 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 496/2000, Reward: -22.2747292210339, done: True\n",
      "state: [ 0.00386715 -0.00678696], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 497/2000, Reward: -21.73665041106786, done: True\n",
      "state: [ 0.00813585 -0.0030335 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 498/2000, Reward: -27.234512226463536, done: True\n",
      "state: [0.00752087 0.00153624], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 499/2000, Reward: -18.824458290873388, done: True\n",
      "state: [ 0.00963453 -0.0038996 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 500/2000, Reward: -21.167149865633867, done: True\n",
      "state: [ 0.0013005  -0.00039741], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 501/2000, Reward: -21.297720145766323, done: True\n",
      "state: [ 0.00478302 -0.00489915], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 502/2000, Reward: -18.85520761600837, done: True\n",
      "state: [ 0.00140857 -0.00586675], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 503/2000, Reward: -21.631087279941895, done: True\n",
      "state: [ 0.00951273 -0.00160088], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 504/2000, Reward: -24.507039565061387, done: True\n",
      "state: [ 0.00862882 -0.00912438], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 505/2000, Reward: -19.85704699408682, done: True\n",
      "state: [ 0.00957081 -0.00694896], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 506/2000, Reward: -21.48725564965234, done: True\n",
      "state: [ 0.00507787 -0.00869849], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 507/2000, Reward: -20.504234077542748, done: True\n",
      "state: [ 0.00281046 -0.002613  ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 508/2000, Reward: -21.96359013224686, done: True\n",
      "state: [ 0.00138561 -0.00729426], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 509/2000, Reward: -31.509797771960223, done: True\n",
      "state: [ 0.00186716 -0.00317066], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 510/2000, Reward: -20.590358976946106, done: True\n",
      "state: [ 0.00696933 -0.00573062], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 511/2000, Reward: -20.39481291037703, done: True\n",
      "state: [-0.0072008  -0.00279581], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 512/2000, Reward: -23.60308368772812, done: True\n",
      "state: [-0.00079154 -0.00892047], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 513/2000, Reward: -22.90971303434771, done: True\n",
      "state: [ 0.00301807 -0.00539481], action: [0.33333333333333326, -0.0167]\n",
      "Episode: 514/2000, Reward: -21.830303508191196, done: True\n",
      "state: [ 0.00765234 -0.00783301], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 515/2000, Reward: -21.18742320961839, done: True\n",
      "state: [ 0.00851752 -0.00903257], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 516/2000, Reward: -26.502681054491887, done: True\n",
      "state: [ 0.00128505 -0.00562521], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 517/2000, Reward: -24.27720970580852, done: True\n",
      "state: [ 0.00245314 -0.00417143], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 518/2000, Reward: -23.245874987407053, done: True\n",
      "state: [ 0.0062961  -0.00574326], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 519/2000, Reward: -20.0418484978986, done: True\n",
      "state: [ 0.00130011 -0.00816446], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 520/2000, Reward: -19.27271600587283, done: True\n",
      "state: [ 0.00121958 -0.00711989], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 521/2000, Reward: -20.869431812194495, done: True\n",
      "state: [ 0.00874816 -0.00543202], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 522/2000, Reward: -23.15138544599931, done: True\n",
      "state: [ 0.0093757  -0.00627284], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 523/2000, Reward: -26.271730484865174, done: True\n",
      "state: [-0.00968526  0.00893039], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 524/2000, Reward: -21.175008304419805, done: True\n",
      "state: [ 0.00926425 -0.0051331 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 525/2000, Reward: -20.177173972888657, done: True\n",
      "state: [ 0.0040009  -0.00637016], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 526/2000, Reward: -19.83676596328024, done: True\n",
      "state: [ 0.0088673  -0.00519458], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 527/2000, Reward: -22.620098686544633, done: True\n",
      "state: [-0.00753544  0.00137471], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 528/2000, Reward: -24.154681707599952, done: True\n",
      "state: [ 0.00255308 -0.00084783], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 529/2000, Reward: -27.495812602212286, done: True\n",
      "state: [0.00629447 0.00298132], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 530/2000, Reward: -21.388200451263213, done: True\n",
      "state: [-0.00920842  0.00905356], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 531/2000, Reward: -23.034549997201882, done: True\n",
      "state: [ 0.00278305 -0.00420312], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 532/2000, Reward: -19.60926926884083, done: True\n",
      "state: [-0.00936109 -0.00051887], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 533/2000, Reward: -28.181472753359127, done: True\n",
      "state: [-0.00466938  0.00591502], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 534/2000, Reward: -21.81702974240236, done: True\n",
      "state: [ 0.00455585 -0.00737957], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 535/2000, Reward: -21.69135098684722, done: True\n",
      "state: [-0.00961653  0.00693897], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 536/2000, Reward: -22.384544913693496, done: True\n",
      "state: [ 0.00766056 -0.00461236], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 537/2000, Reward: -20.731122706755983, done: True\n",
      "state: [ 0.00877745 -0.0055176 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 538/2000, Reward: -23.159188340103675, done: True\n",
      "state: [ 0.00121574 -0.00652585], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 539/2000, Reward: -22.140957961771836, done: True\n",
      "state: [ 0.00130922 -0.00895018], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 540/2000, Reward: -17.76776249722329, done: True\n",
      "state: [ 0.00502046 -0.00291553], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 541/2000, Reward: -21.576586094627572, done: True\n",
      "state: [ 0.00269164 -0.00283668], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 542/2000, Reward: -20.36245862618533, done: True\n",
      "state: [ 0.00705352 -0.0088299 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 543/2000, Reward: -21.530788867388132, done: True\n",
      "state: [ 0.00373963 -0.00554768], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 544/2000, Reward: -19.94168234427665, done: True\n",
      "state: [-0.00589882 -0.00449812], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 545/2000, Reward: -18.63421450729124, done: True\n",
      "state: [ 0.00406684 -0.00787734], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 546/2000, Reward: -24.387511201669554, done: True\n",
      "state: [ 0.00372912 -0.00311573], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 547/2000, Reward: -17.71191140799249, done: True\n",
      "state: [ 0.00874202 -0.00420865], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 548/2000, Reward: -18.36539673481152, done: True\n",
      "state: [ 0.00926774 -0.00629515], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 549/2000, Reward: -23.027594877478645, done: True\n",
      "state: [ 0.00368496 -0.00587677], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 550/2000, Reward: -21.381960118238872, done: True\n",
      "state: [-0.00868986  0.00090299], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 551/2000, Reward: -20.16445590853337, done: True\n",
      "state: [ 0.00610305 -0.00324595], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 552/2000, Reward: -23.372621748497615, done: True\n",
      "state: [ 0.0055816  -0.00730754], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 553/2000, Reward: -18.150895281795172, done: True\n",
      "state: [ 0.00118773 -0.00275269], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 554/2000, Reward: -18.953033773478445, done: True\n",
      "state: [ 0.00128566 -0.00736579], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 555/2000, Reward: -16.74570606266955, done: True\n",
      "state: [ 0.00484136 -0.0051659 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 556/2000, Reward: -21.485331216764873, done: True\n",
      "state: [0.00117993 0.00037078], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 557/2000, Reward: -17.618094897802777, done: True\n",
      "state: [ 0.00085936 -0.00887155], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 558/2000, Reward: -22.054724949672355, done: True\n",
      "state: [ 0.00956036 -0.00705623], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 559/2000, Reward: -19.658731955093923, done: True\n",
      "state: [ 0.00597956 -0.00657169], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 560/2000, Reward: -16.404736368762194, done: True\n",
      "state: [ 0.00876307 -0.00503955], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 561/2000, Reward: -19.18982222823572, done: True\n",
      "state: [ 0.00894018 -0.00270355], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 562/2000, Reward: -22.508684067335775, done: True\n",
      "state: [0.00777402 0.00437661], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 563/2000, Reward: -17.66205887215327, done: True\n",
      "state: [ 0.00959884 -0.00108383], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 564/2000, Reward: -19.74054438170243, done: True\n",
      "state: [ 0.00467085 -0.00224737], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 565/2000, Reward: -18.858217283490447, done: True\n",
      "state: [0.00324773 0.00491233], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 566/2000, Reward: -18.06940574678123, done: True\n",
      "state: [ 0.00126907 -0.00298284], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 567/2000, Reward: -18.84532766807504, done: True\n",
      "state: [ 0.00719586 -0.00360913], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 568/2000, Reward: -19.554661427945927, done: True\n",
      "state: [-0.00291983  0.00817172], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 569/2000, Reward: -16.188064372301767, done: True\n",
      "state: [ 0.00619322 -0.00616687], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 570/2000, Reward: -16.656093983862718, done: True\n",
      "state: [ 0.0013062  -0.00580031], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 571/2000, Reward: -19.168780531698577, done: True\n",
      "state: [ 0.00513991 -0.00111015], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 572/2000, Reward: -20.528439342403125, done: True\n",
      "state: [ 6.22465035e-05 -8.91938260e-03], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 573/2000, Reward: -20.750540963910236, done: True\n",
      "state: [ 0.00840149 -0.00918243], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 574/2000, Reward: -20.873163747696253, done: True\n",
      "state: [ 0.00661511 -0.00625349], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 575/2000, Reward: -20.942050105157094, done: True\n",
      "state: [ 0.00116858 -0.0076837 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 576/2000, Reward: -17.271885486495908, done: True\n",
      "state: [-0.00153969 -0.00917502], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 577/2000, Reward: -18.752821320208625, done: True\n",
      "state: [-0.00965806  0.00252755], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 578/2000, Reward: -19.205930880912323, done: True\n",
      "state: [-0.00285283 -0.00689945], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 579/2000, Reward: -19.971658851557724, done: True\n",
      "state: [ 0.00120749 -0.00132607], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 580/2000, Reward: -21.028510190211513, done: True\n",
      "state: [ 0.00802272 -0.00883623], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 581/2000, Reward: -18.11265583763266, done: True\n",
      "state: [ 0.00135786 -0.0061347 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 582/2000, Reward: -17.548091885375577, done: True\n",
      "state: [ 0.00823975 -0.00593046], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 583/2000, Reward: -20.95306359646923, done: True\n",
      "state: [ 0.00137153 -0.00351585], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 584/2000, Reward: -21.655900885156388, done: True\n",
      "state: [-0.00277169 -0.00020679], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 585/2000, Reward: -18.6096691074895, done: True\n",
      "state: [ 0.00764809 -0.0087257 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 586/2000, Reward: -16.531787860108217, done: True\n",
      "state: [-0.00835648  0.00052871], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 587/2000, Reward: -16.535361079385876, done: True\n",
      "state: [ 0.0090203  -0.00702318], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 588/2000, Reward: -16.859508125493065, done: True\n",
      "state: [ 0.00230029 -0.00132627], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 589/2000, Reward: -16.435195354153173, done: True\n",
      "state: [ 0.00338506 -0.00540076], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 590/2000, Reward: -14.663041093279478, done: True\n",
      "state: [ 0.00091818 -0.00893121], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 591/2000, Reward: -23.874665321832595, done: True\n",
      "state: [-0.00123403  0.0016978 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 592/2000, Reward: -17.658525427110323, done: True\n",
      "state: [ 0.00415582 -0.00851798], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 593/2000, Reward: -15.849805541734922, done: True\n",
      "state: [ 0.00897644 -0.00616152], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 594/2000, Reward: -21.25634813374696, done: True\n",
      "state: [-0.00360861  0.00024427], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 595/2000, Reward: -18.53475302728106, done: True\n",
      "state: [ 0.00116547 -0.00362789], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 596/2000, Reward: -22.51798476267507, done: True\n",
      "state: [-0.00812034 -0.00582392], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 597/2000, Reward: -17.641122800358595, done: True\n",
      "state: [ 0.00312684 -0.00818496], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 598/2000, Reward: -21.74184009716933, done: True\n",
      "state: [-0.00818943 -0.00496269], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 599/2000, Reward: -16.851861650913268, done: True\n",
      "state: [ 0.00124785 -0.00592506], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 600/2000, Reward: -19.06091650373799, done: True\n",
      "state: [ 0.00603553 -0.0047814 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 601/2000, Reward: -16.072345914429828, done: True\n",
      "state: [ 0.00657956 -0.00634546], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 602/2000, Reward: -18.436146596038494, done: True\n",
      "state: [ 0.00392807 -0.00386151], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 603/2000, Reward: -18.41714354021509, done: True\n",
      "state: [ 0.00255088 -0.00544649], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 604/2000, Reward: -20.297261079674165, done: True\n",
      "state: [ 0.00372421 -0.00306006], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 605/2000, Reward: -23.309893475624985, done: True\n",
      "state: [ 0.00773412 -0.0020291 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 606/2000, Reward: -14.968389005455698, done: True\n",
      "state: [ 0.00447304 -0.00725369], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 607/2000, Reward: -17.32580845917236, done: True\n",
      "state: [ 0.00120148 -0.00863797], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 608/2000, Reward: -18.517773963870923, done: True\n",
      "state: [ 0.00200656 -0.00354466], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 609/2000, Reward: -18.40146184011413, done: True\n",
      "state: [ 0.00506123 -0.00648815], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 610/2000, Reward: -21.40509721935965, done: True\n",
      "state: [ 0.00501795 -0.00444829], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 611/2000, Reward: -17.53865821412033, done: True\n",
      "state: [ 0.00269515 -0.00565695], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 612/2000, Reward: -16.20066515427012, done: True\n",
      "state: [ 0.00608911 -0.00637223], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 613/2000, Reward: -18.7672365137088, done: True\n",
      "state: [ 0.00040893 -0.00872945], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 614/2000, Reward: -19.64123169837015, done: True\n",
      "state: [ 0.00589063 -0.00437398], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 615/2000, Reward: -19.08398666219788, done: True\n",
      "state: [ 0.00230917 -0.00245063], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 616/2000, Reward: -14.852808534318786, done: True\n",
      "state: [ 0.00938161 -0.00658829], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 617/2000, Reward: -17.209009726592488, done: True\n",
      "state: [ 0.00794577 -0.0055477 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 618/2000, Reward: -18.53681843308875, done: True\n",
      "state: [ 0.00820593 -0.00848476], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 619/2000, Reward: -17.750032630225363, done: True\n",
      "state: [ 0.00364196 -0.00284081], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 620/2000, Reward: -20.309601965711042, done: True\n",
      "state: [-0.00582162 -0.00205777], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 621/2000, Reward: -15.100726074141793, done: True\n",
      "state: [ 0.00118575 -0.00301386], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 622/2000, Reward: -20.102679407978233, done: True\n",
      "state: [ 0.00588078 -0.0044148 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 623/2000, Reward: -19.44861820126825, done: True\n",
      "state: [-0.0035662   0.00273587], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 624/2000, Reward: -17.859456601074687, done: True\n",
      "state: [ 0.00740032 -0.00055805], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 625/2000, Reward: -15.630058645033955, done: True\n",
      "state: [ 0.00962331 -0.00858864], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 626/2000, Reward: -18.41508404968476, done: True\n",
      "state: [ 0.00316157 -0.00289934], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 627/2000, Reward: -15.873703638531666, done: True\n",
      "state: [ 0.00337383 -0.00140953], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 628/2000, Reward: -18.850873510322874, done: True\n",
      "state: [ 0.00113989 -0.00129455], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 629/2000, Reward: -20.96524325649978, done: True\n",
      "state: [ 0.00131575 -0.00316684], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 630/2000, Reward: -19.18201670530513, done: True\n",
      "state: [-0.00895989  0.00398142], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 631/2000, Reward: -15.512949388328856, done: True\n",
      "state: [ 0.00132913 -0.0081856 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 632/2000, Reward: -17.53392049358413, done: True\n",
      "state: [ 0.00803115 -0.00484613], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 633/2000, Reward: -17.986478963598007, done: True\n",
      "state: [ 0.00116918 -0.00268447], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 634/2000, Reward: -22.074252751584243, done: True\n",
      "state: [ 0.00789606 -0.00544789], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 635/2000, Reward: -17.75269178092217, done: True\n",
      "state: [ 0.00126127 -0.00542129], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 636/2000, Reward: -16.53553721970908, done: True\n",
      "state: [ 0.00306575 -0.00359668], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 637/2000, Reward: -21.095063405720115, done: True\n",
      "state: [ 0.00249146 -0.0029882 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 638/2000, Reward: -20.967582310661513, done: True\n",
      "state: [ 0.00727474 -0.00774647], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 639/2000, Reward: -17.83889199709526, done: True\n",
      "state: [-0.00235906 -0.00401632], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 640/2000, Reward: -20.428588360990386, done: True\n",
      "state: [ 0.0020268  -0.00427398], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 641/2000, Reward: -17.757455061189702, done: True\n",
      "state: [ 0.0030138  -0.00097341], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 642/2000, Reward: -19.870316772219546, done: True\n",
      "state: [ 0.0046695 -0.0036911], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 643/2000, Reward: -16.943152998556545, done: True\n",
      "state: [ 0.00453031 -0.00895604], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 644/2000, Reward: -18.19492458502148, done: True\n",
      "state: [ 0.0052484  -0.00689766], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 645/2000, Reward: -16.76989487199007, done: True\n",
      "state: [-0.00874659 -0.00168856], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 646/2000, Reward: -18.97898784738496, done: True\n",
      "state: [ 0.007341   -0.00754739], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 647/2000, Reward: -21.09096350064148, done: True\n",
      "state: [-0.00275004  0.00244723], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 648/2000, Reward: -17.739405092808145, done: True\n",
      "state: [ 0.00697257 -0.00634046], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 649/2000, Reward: -16.648256802066896, done: True\n",
      "state: [ 0.00742932 -0.00629218], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 650/2000, Reward: -18.529674902082245, done: True\n",
      "state: [ 0.00728259 -0.00130632], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 651/2000, Reward: -15.54284253182905, done: True\n",
      "state: [ 0.00834369 -0.00893513], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 652/2000, Reward: -20.204696175527367, done: True\n",
      "state: [ 0.00864732 -0.00462544], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 653/2000, Reward: -16.85654669443749, done: True\n",
      "state: [ 0.0025877  -0.00642647], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 654/2000, Reward: -16.203255633585623, done: True\n",
      "state: [ 0.00939907 -0.00848641], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 655/2000, Reward: -18.318084526266674, done: True\n",
      "state: [ 0.00225678 -0.00527028], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 656/2000, Reward: -15.9752456491225, done: True\n",
      "state: [ 0.00759527 -0.00903161], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 657/2000, Reward: -20.056765398664698, done: True\n",
      "state: [ 0.00093242 -0.00874856], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 658/2000, Reward: -17.099611691937877, done: True\n",
      "state: [ 0.00118155 -0.00730471], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 659/2000, Reward: -16.945505390570002, done: True\n",
      "state: [ 0.00771541 -0.00642374], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 660/2000, Reward: -19.183722245435717, done: True\n",
      "state: [ 0.00268965 -0.00527859], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 661/2000, Reward: -16.21269360157025, done: True\n",
      "state: [ 0.00066709 -0.0087758 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 662/2000, Reward: -16.421797673730357, done: True\n",
      "state: [ 0.00924689 -0.00911413], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 663/2000, Reward: -20.07800056479731, done: True\n",
      "state: [ 0.00958323 -0.00667715], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 664/2000, Reward: -20.987171085654253, done: True\n",
      "state: [-0.00117216 -0.00042789], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 665/2000, Reward: -18.987625780326212, done: True\n",
      "state: [ 0.0012028  -0.00708788], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 666/2000, Reward: -16.655695777933765, done: True\n",
      "state: [ 0.00120153 -0.00808099], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 667/2000, Reward: -16.328256129302964, done: True\n",
      "state: [-0.00044867 -0.00899715], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 668/2000, Reward: -20.864211743956183, done: True\n",
      "state: [ 0.00134841 -0.00555802], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 669/2000, Reward: -17.197746539168534, done: True\n",
      "state: [ 0.00368126 -0.00712657], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 670/2000, Reward: -17.192320477624524, done: True\n",
      "state: [ 0.0077031  -0.00609518], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 671/2000, Reward: -18.396989936389208, done: True\n",
      "state: [ 0.00849517 -0.00739439], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 672/2000, Reward: -15.540281871476052, done: True\n",
      "state: [ 0.00915421 -0.00699856], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 673/2000, Reward: -20.52781485385643, done: True\n",
      "state: [ 0.00233361 -0.00483337], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 674/2000, Reward: -16.5684524017017, done: True\n",
      "state: [ 0.00754902 -0.00931799], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 675/2000, Reward: -16.959235689169137, done: True\n",
      "state: [ 0.00051088 -0.00891901], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 676/2000, Reward: -22.058794425341336, done: True\n",
      "state: [ 0.00870602 -0.00620815], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 677/2000, Reward: -16.42703679091411, done: True\n",
      "state: [ 0.00541032 -0.0086728 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 678/2000, Reward: -15.883627212983985, done: True\n",
      "state: [ 0.00656782 -0.00832342], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 679/2000, Reward: -15.627371857253982, done: True\n",
      "state: [ 0.00726722 -0.00798068], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 680/2000, Reward: -16.751290778042847, done: True\n",
      "state: [-0.00187289 -0.00934228], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 681/2000, Reward: -16.523589960852345, done: True\n",
      "state: [ 0.00059866 -0.009024  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 682/2000, Reward: -17.971526064263404, done: True\n",
      "state: [-0.00023811 -0.00914149], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 683/2000, Reward: -18.297650554443358, done: True\n",
      "state: [ 0.00285594 -0.00514571], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 684/2000, Reward: -20.30144773527638, done: True\n",
      "state: [ 0.00525793 -0.00749723], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 685/2000, Reward: -16.074620390202885, done: True\n",
      "state: [-5.76637496e-05 -9.08751144e-03], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 686/2000, Reward: -18.409262605978427, done: True\n",
      "state: [ 0.00376399 -0.0047256 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 687/2000, Reward: -16.64883270989829, done: True\n",
      "state: [ 0.00592949 -0.00740713], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 688/2000, Reward: -18.191404533635964, done: True\n",
      "state: [ 0.00838868 -0.00929987], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 689/2000, Reward: -18.18386784198604, done: True\n",
      "state: [ 0.00119808 -0.00528886], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 690/2000, Reward: -18.513370988455417, done: True\n",
      "state: [ 0.00760323 -0.00867653], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 691/2000, Reward: -20.430915283206478, done: True\n",
      "state: [-0.00744381  0.00512236], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 692/2000, Reward: -17.28382292810897, done: True\n",
      "state: [ 0.0013315  -0.00746533], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 693/2000, Reward: -18.765570944077734, done: True\n",
      "state: [ 0.00366612 -0.00645278], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 694/2000, Reward: -21.744622576184213, done: True\n",
      "state: [-0.00198695 -0.00912431], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 695/2000, Reward: -17.477761786008674, done: True\n",
      "state: [ 0.00113746 -0.00796685], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 696/2000, Reward: -18.87900204225665, done: True\n",
      "state: [ 0.00378858 -0.00703226], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 697/2000, Reward: -17.522632536783515, done: True\n",
      "state: [-0.00788448 -0.0002674 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 698/2000, Reward: -16.627826925949474, done: True\n",
      "state: [-0.0005068  -0.00888582], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 699/2000, Reward: -18.063498093152564, done: True\n",
      "state: [ 0.00933607 -0.00686462], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 700/2000, Reward: -19.84004219897516, done: True\n",
      "state: [ 0.00542556 -0.00649957], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 701/2000, Reward: -16.843636874965565, done: True\n",
      "state: [ 0.00540151 -0.00818117], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 702/2000, Reward: -16.861321503288966, done: True\n",
      "state: [ 0.00772046 -0.00601779], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 703/2000, Reward: -21.424620505284206, done: True\n",
      "state: [-0.00134141 -0.00145338], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 704/2000, Reward: -15.409464104223186, done: True\n",
      "state: [-0.00174326 -0.00899799], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 705/2000, Reward: -18.522387460560743, done: True\n",
      "state: [ 0.00879397 -0.00875064], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 706/2000, Reward: -18.41925278395206, done: True\n",
      "state: [ 0.00264455 -0.0055968 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 707/2000, Reward: -20.415573467326404, done: True\n",
      "state: [ 0.00633057 -0.00930351], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 708/2000, Reward: -16.542363106576115, done: True\n",
      "state: [ 0.00810964 -0.00923465], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 709/2000, Reward: -19.29632118411254, done: True\n",
      "state: [ 0.00129083 -0.00428662], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 710/2000, Reward: -17.39187247146844, done: True\n",
      "state: [ 0.00564964 -0.00654851], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 711/2000, Reward: -16.73115607385247, done: True\n",
      "state: [ 0.00744006 -0.00879594], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 712/2000, Reward: -15.957420718461998, done: True\n",
      "state: [ 0.00727293 -0.00639995], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 713/2000, Reward: -17.087723753794585, done: True\n",
      "state: [ 0.00547741 -0.00538484], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 714/2000, Reward: -18.54088886419752, done: True\n",
      "state: [ 0.00601424 -0.00712673], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 715/2000, Reward: -16.74792470611331, done: True\n",
      "state: [ 0.00121063 -0.00405811], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 716/2000, Reward: -16.641051077674476, done: True\n",
      "state: [ 0.00138663 -0.00875814], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 717/2000, Reward: -15.670862571922344, done: True\n",
      "state: [ 0.00623926 -0.00786936], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 718/2000, Reward: -18.62567027910933, done: True\n",
      "state: [ 0.00899825 -0.00891665], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 719/2000, Reward: -19.529612127761688, done: True\n",
      "state: [ 0.0011625 -0.0056376], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 720/2000, Reward: -18.40851783302174, done: True\n",
      "state: [-0.00738698  0.00461586], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 721/2000, Reward: -19.40914366051761, done: True\n",
      "state: [-0.00793619 -0.00036511], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 722/2000, Reward: -19.52058284057623, done: True\n",
      "state: [ 0.00117488 -0.00152474], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 723/2000, Reward: -19.115364743292513, done: True\n",
      "state: [ 0.0013318  -0.00283302], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 724/2000, Reward: -19.637455728534214, done: True\n",
      "state: [ 0.00129378 -0.00374997], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 725/2000, Reward: -16.443399004607446, done: True\n",
      "state: [ 0.00924471 -0.00637212], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 726/2000, Reward: -17.97165709245381, done: True\n",
      "state: [ 0.0025425  -0.00419309], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 727/2000, Reward: -18.53535763051152, done: True\n",
      "state: [ 0.00590185 -0.00660333], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 728/2000, Reward: -19.076780812800216, done: True\n",
      "state: [ 0.00124945 -0.00527995], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 729/2000, Reward: -16.215461002100632, done: True\n",
      "state: [ 0.00853537 -0.00889322], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 730/2000, Reward: -18.540207550549415, done: True\n",
      "state: [ 0.00319675 -0.00408341], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 731/2000, Reward: -17.428014025442792, done: True\n",
      "state: [ 0.00226634 -0.00452711], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 732/2000, Reward: -18.73353187987873, done: True\n",
      "state: [ 0.00710368 -0.00723483], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 733/2000, Reward: -17.18260602627583, done: True\n",
      "state: [ 0.00841959 -0.00688251], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 734/2000, Reward: -18.097395737004465, done: True\n",
      "state: [ 0.00730205 -0.00479464], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 735/2000, Reward: -16.536384747985277, done: True\n",
      "state: [ 0.00350261 -0.0018893 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 736/2000, Reward: -18.087192383460202, done: True\n",
      "state: [ 0.00808032 -0.00504113], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 737/2000, Reward: -18.313861695037996, done: True\n",
      "state: [ 0.00449859 -0.0043247 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 738/2000, Reward: -17.08704197659971, done: True\n",
      "state: [ 0.00874354 -0.00888724], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 739/2000, Reward: -18.31788098657253, done: True\n",
      "state: [ 0.00695679 -0.00409579], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 740/2000, Reward: -18.978332016200792, done: True\n",
      "state: [ 0.00237713 -0.0020672 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 741/2000, Reward: -18.2281023368476, done: True\n",
      "state: [0.00136244 0.00043371], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 742/2000, Reward: -17.210948067591623, done: True\n",
      "state: [ 0.00894171 -0.00647655], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 743/2000, Reward: -20.860737098417456, done: True\n",
      "state: [0.00135108 0.00043297], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 744/2000, Reward: -17.9911303487178, done: True\n",
      "state: [ 0.00455223 -0.00384899], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 745/2000, Reward: -19.297237285600012, done: True\n",
      "state: [ 0.0017452  -0.00304359], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 746/2000, Reward: -17.65858915104304, done: True\n",
      "state: [ 0.00137359 -0.00256265], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 747/2000, Reward: -17.76282165928193, done: True\n",
      "state: [0.00853535 0.00010911], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 748/2000, Reward: -17.747400980239462, done: True\n",
      "state: [-0.0071113   0.00228162], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 749/2000, Reward: -18.74561290906833, done: True\n",
      "state: [ 0.0037352  -0.00337724], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 750/2000, Reward: -18.403485236821577, done: True\n",
      "state: [ 0.00688258 -0.0056994 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 751/2000, Reward: -18.96879759002226, done: True\n",
      "state: [ 0.00912904 -0.00585753], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 752/2000, Reward: -17.331620943065353, done: True\n",
      "state: [ 0.00207233 -0.0024132 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 753/2000, Reward: -18.32155372906661, done: True\n",
      "state: [ 0.00696369 -0.00631702], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 754/2000, Reward: -16.19996388272162, done: True\n",
      "state: [ 0.00964083 -0.00800742], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 755/2000, Reward: -15.623877495744917, done: True\n",
      "state: [ 0.00786115 -0.00739388], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 756/2000, Reward: -16.196395631243398, done: True\n",
      "state: [ 0.00669075 -0.00456658], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 757/2000, Reward: -18.39975339166471, done: True\n",
      "state: [ 0.00114334 -0.00409021], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 758/2000, Reward: -15.874897390542603, done: True\n",
      "state: [ 0.0042394  -0.00593334], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 759/2000, Reward: -16.21991246586236, done: True\n",
      "state: [ 0.00758016 -0.00830397], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 760/2000, Reward: -16.65366479248779, done: True\n",
      "state: [ 0.00512293 -0.00570006], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 761/2000, Reward: -17.22194866985468, done: True\n",
      "state: [ 0.001311   -0.00496083], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 762/2000, Reward: -17.08698681973934, done: True\n",
      "state: [ 0.00124878 -0.00456306], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 763/2000, Reward: -16.198224513801105, done: True\n",
      "state: [ 0.00899331 -0.00723794], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 764/2000, Reward: -15.188078597481107, done: True\n",
      "state: [ 0.00129658 -0.00637752], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 765/2000, Reward: -17.435393999309706, done: True\n",
      "state: [ 0.00722666 -0.00203668], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 766/2000, Reward: -20.41057238902738, done: True\n",
      "state: [ 0.001194   -0.00159844], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 767/2000, Reward: -18.444611155863495, done: True\n",
      "state: [ 0.00556296 -0.00552222], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 768/2000, Reward: -19.97603446816775, done: True\n",
      "state: [ 0.00958964 -0.00878088], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 769/2000, Reward: -18.545322150533973, done: True\n",
      "state: [ 0.00131867 -0.00318736], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 770/2000, Reward: -17.751490200571737, done: True\n",
      "state: [ 0.0011797  -0.00426807], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 771/2000, Reward: -20.5593217155338, done: True\n",
      "state: [-0.00833151  0.00015177], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 772/2000, Reward: -17.462699506411184, done: True\n",
      "state: [-0.00883774  0.0046471 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 773/2000, Reward: -19.554813393016612, done: True\n",
      "state: [-0.00464568 -0.0038231 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 774/2000, Reward: -20.555588842736903, done: True\n",
      "state: [ 0.00121702 -0.00171433], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 775/2000, Reward: -17.775945399924527, done: True\n",
      "state: [ 0.00131495 -0.00326908], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 776/2000, Reward: -16.79645872260042, done: True\n",
      "state: [ 0.00812539 -0.00542175], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 777/2000, Reward: -17.236695893257483, done: True\n",
      "state: [ 0.0086055  -0.00589808], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 778/2000, Reward: -16.548775421324287, done: True\n",
      "state: [ 0.00602768 -0.00384734], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 779/2000, Reward: -16.14616894269846, done: True\n",
      "state: [-0.00530918  0.00457986], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 780/2000, Reward: -18.19796963239302, done: True\n",
      "state: [ 0.00717314 -0.00399141], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 781/2000, Reward: -17.751996549724403, done: True\n",
      "state: [ 0.00134858 -0.00018044], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 782/2000, Reward: -16.317021168415035, done: True\n",
      "state: [ 0.00117127 -0.00428179], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 783/2000, Reward: -18.439558887724118, done: True\n",
      "state: [-0.00128207  0.0057112 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 784/2000, Reward: -14.655438723804306, done: True\n",
      "state: [-0.00724463 -0.00257812], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 785/2000, Reward: -19.226648447924667, done: True\n",
      "state: [-0.00904986  0.00657551], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 786/2000, Reward: -14.866403221838906, done: True\n",
      "state: [0.00575541 0.00319927], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 787/2000, Reward: -18.235587892637394, done: True\n",
      "state: [-0.00363696  0.00662374], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 788/2000, Reward: -16.5341154301647, done: True\n",
      "state: [ 0.00409673 -0.00194332], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 789/2000, Reward: -18.515202391036528, done: True\n",
      "state: [ 0.00771693 -0.00367718], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 790/2000, Reward: -14.563467109340907, done: True\n",
      "state: [ 0.00431832 -0.00169762], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 791/2000, Reward: -14.779428998287438, done: True\n",
      "state: [ 0.00351432 -0.00162282], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 792/2000, Reward: -23.34851096483378, done: True\n",
      "state: [-0.00944695  0.0060551 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 793/2000, Reward: -19.259368710628436, done: True\n",
      "state: [-0.00651188  0.00411797], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 794/2000, Reward: -19.982310067743946, done: True\n",
      "state: [-0.0088363   0.00271712], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 795/2000, Reward: -20.869135838777304, done: True\n",
      "state: [-0.00505282  0.00527657], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 796/2000, Reward: -20.330589262518856, done: True\n",
      "state: [-0.00468128  0.00118301], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 797/2000, Reward: -18.345904500626034, done: True\n",
      "state: [-0.00806162  0.00533002], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 798/2000, Reward: -18.23832980348646, done: True\n",
      "state: [-0.00123974  0.00810896], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 799/2000, Reward: -19.00284847192856, done: True\n",
      "state: [-0.00640682  0.00427114], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 800/2000, Reward: -18.82378204313159, done: True\n",
      "state: [-0.00812241  0.00418166], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 801/2000, Reward: -16.747584589266683, done: True\n",
      "state: [-0.00835099  0.0029361 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 802/2000, Reward: -18.115731066201985, done: True\n",
      "state: [-0.00129983  0.00682657], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 803/2000, Reward: -23.42392110283489, done: True\n",
      "state: [-0.00134023 -0.00045553], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 804/2000, Reward: -19.14573280699563, done: True\n",
      "state: [-0.00124244  0.00415983], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 805/2000, Reward: -20.318429057821337, done: True\n",
      "state: [-0.00122804  0.00062291], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 806/2000, Reward: -19.47725745765521, done: True\n",
      "state: [-0.00132816  0.00356501], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 807/2000, Reward: -20.089100433895744, done: True\n",
      "state: [-0.00131987  0.00420938], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 808/2000, Reward: -20.32374032735067, done: True\n",
      "state: [-0.00891363  0.00470184], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 809/2000, Reward: -19.722142457064706, done: True\n",
      "state: [-0.00509073  0.00495436], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 810/2000, Reward: -19.562869170096217, done: True\n",
      "state: [-2.50519487e-03  4.45384750e-05], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 811/2000, Reward: -19.74304497045189, done: True\n",
      "state: [-0.00910759  0.00608132], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 812/2000, Reward: -18.197644235552428, done: True\n",
      "state: [-0.00925648  0.00749903], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 813/2000, Reward: -20.766286469682502, done: True\n",
      "state: [-0.00714274  0.00535727], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 814/2000, Reward: -17.702417033916024, done: True\n",
      "state: [-0.00546152  0.00296241], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 815/2000, Reward: -20.300340793566125, done: True\n",
      "state: [-0.00708375  0.00417339], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 816/2000, Reward: -18.935800027233327, done: True\n",
      "state: [-0.00559462  0.00254788], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 817/2000, Reward: -17.80531109200811, done: True\n",
      "state: [-0.00536176  0.0026223 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 818/2000, Reward: -15.862136530903234, done: True\n",
      "state: [-0.00951979  0.00542639], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 819/2000, Reward: -18.091465997423086, done: True\n",
      "state: [-0.00778053  0.00363972], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 820/2000, Reward: -20.536679985652736, done: True\n",
      "state: [-0.00645402  0.00423452], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 821/2000, Reward: -21.653670968413813, done: True\n",
      "state: [-0.00129629  0.00282329], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 822/2000, Reward: -20.909104823371788, done: True\n",
      "state: [-0.00913456  0.00650593], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 823/2000, Reward: -20.526706503338072, done: True\n",
      "state: [-0.00356953  0.00183521], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 824/2000, Reward: -21.65191179447431, done: True\n",
      "state: [-2.87871960e-03 -9.12045442e-05], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 825/2000, Reward: -15.974440399694625, done: True\n",
      "state: [0.00213542 0.00106311], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 826/2000, Reward: -18.85762921859703, done: True\n",
      "state: [-0.00958377  0.00452019], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 827/2000, Reward: -20.524596976359742, done: True\n",
      "state: [-0.0095887   0.00840897], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 828/2000, Reward: -18.07642290689871, done: True\n",
      "state: [-0.00521797  0.00351542], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 829/2000, Reward: -19.66432019629134, done: True\n",
      "state: [-0.00965433  0.00529484], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 830/2000, Reward: -18.443082555923702, done: True\n",
      "state: [-0.00758434  0.00659192], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 831/2000, Reward: -17.12451273449417, done: True\n",
      "state: [-0.00297827  0.001797  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 832/2000, Reward: -17.536565329064867, done: True\n",
      "state: [-0.00508404  0.00292374], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 833/2000, Reward: -18.677250687786792, done: True\n",
      "state: [-0.00114412  0.0008154 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 834/2000, Reward: -22.39716988392038, done: True\n",
      "state: [-0.0048628   0.00310848], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 835/2000, Reward: -18.431005183879673, done: True\n",
      "state: [-0.00517498  0.00211248], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 836/2000, Reward: -15.22749631242926, done: True\n",
      "state: [-0.00746038  0.00483695], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 837/2000, Reward: -18.564462615149296, done: True\n",
      "state: [-0.00688763  0.0028598 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 838/2000, Reward: -19.874809989449727, done: True\n",
      "state: [-0.00807859  0.00452719], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 839/2000, Reward: -16.76605114115533, done: True\n",
      "state: [ 0.00297145 -0.00054428], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 840/2000, Reward: -18.08829848070373, done: True\n",
      "state: [-0.00658515 -0.00162016], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 841/2000, Reward: -19.99135322206509, done: True\n",
      "state: [-0.00116701 -0.00181939], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 842/2000, Reward: -19.737908662156308, done: True\n",
      "state: [-0.00119904  0.00345991], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 843/2000, Reward: -15.650832927362673, done: True\n",
      "state: [-0.00139876  0.00329735], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 844/2000, Reward: -19.528618543200576, done: True\n",
      "state: [-0.00659895  0.00330598], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 845/2000, Reward: -19.086302615699545, done: True\n",
      "state: [-0.0039509  -0.00022278], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 846/2000, Reward: -17.181193654878086, done: True\n",
      "state: [-0.00119801  0.00449672], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 847/2000, Reward: -17.463873436583658, done: True\n",
      "state: [ 0.0011681  -0.00114586], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 848/2000, Reward: -16.27640077917703, done: True\n",
      "state: [0.00438671 0.00143072], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 849/2000, Reward: -15.546696607286803, done: True\n",
      "state: [-0.00923514 -0.00069851], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 850/2000, Reward: -16.01457134530493, done: True\n",
      "state: [ 0.00906727 -0.00141775], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 851/2000, Reward: -16.848958118925776, done: True\n",
      "state: [0.00482497 0.00094285], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 852/2000, Reward: -16.526291754184463, done: True\n",
      "state: [0.00591153 0.00132977], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 853/2000, Reward: -20.864927642643902, done: True\n",
      "state: [ 0.00229656 -0.00082934], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 854/2000, Reward: -14.774866726942056, done: True\n",
      "state: [0.00297974 0.00417438], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 855/2000, Reward: -19.426819640627706, done: True\n",
      "state: [-0.00125816  0.00161303], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 856/2000, Reward: -16.627481590441718, done: True\n",
      "state: [ 0.00122053 -0.00167795], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 857/2000, Reward: -16.677503352068577, done: True\n",
      "state: [-0.00512163  0.00600673], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 858/2000, Reward: -17.02361309559809, done: True\n",
      "state: [ 0.00252961 -0.00120267], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 859/2000, Reward: -15.859331673343753, done: True\n",
      "state: [ 0.00594427 -0.00426911], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 860/2000, Reward: -15.232565725793314, done: True\n",
      "state: [-0.00963271  0.00664017], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 861/2000, Reward: -15.013851978773369, done: True\n",
      "state: [-7.55333782e-03  9.19533479e-06], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 862/2000, Reward: -15.661048112552447, done: True\n",
      "state: [-0.00772146  0.00260089], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 863/2000, Reward: -14.453409033807368, done: True\n",
      "state: [ 7.24092362e-03 -4.08004634e-05], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 864/2000, Reward: -16.65210778846402, done: True\n",
      "state: [0.0056142  0.00030196], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 865/2000, Reward: -17.001658256632876, done: True\n",
      "state: [ 0.00864718 -0.00021853], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 866/2000, Reward: -15.293494538450295, done: True\n",
      "state: [0.00301695 0.00093738], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 867/2000, Reward: -15.651926729920017, done: True\n",
      "state: [0.00526098 0.00170723], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 868/2000, Reward: -16.777725001215753, done: True\n",
      "state: [-0.00828524  0.00493894], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 869/2000, Reward: -16.319350098209767, done: True\n",
      "state: [ 0.0012156  -0.00560382], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 870/2000, Reward: -14.687731646987313, done: True\n",
      "state: [ 0.00124839 -0.00379491], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 871/2000, Reward: -14.353044364553437, done: True\n",
      "state: [ 0.00850515 -0.00531829], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 872/2000, Reward: -16.563804878195324, done: True\n",
      "state: [ 0.0041621  -0.00160219], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 873/2000, Reward: -17.890012226696832, done: True\n",
      "state: [0.00758441 0.00110143], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 874/2000, Reward: -17.97183131507085, done: True\n",
      "state: [ 0.00130623 -0.00443701], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 875/2000, Reward: -15.661743734643826, done: True\n",
      "state: [ 0.00168808 -0.00482218], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 876/2000, Reward: -16.325486761067886, done: True\n",
      "state: [ 0.00739212 -0.00770492], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 877/2000, Reward: -18.772176618617205, done: True\n",
      "state: [-0.00517433 -0.00049051], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 878/2000, Reward: -14.449443849708276, done: True\n",
      "state: [ 0.00684812 -0.00615765], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 879/2000, Reward: -14.781766787644774, done: True\n",
      "state: [ 0.00136307 -0.00497547], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 880/2000, Reward: -14.883208025143922, done: True\n",
      "state: [ 0.00204529 -0.00390337], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 881/2000, Reward: -16.100147690464222, done: True\n",
      "state: [-0.00990263  0.00360976], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 882/2000, Reward: -15.336358997437246, done: True\n",
      "state: [ 0.00530273 -0.00518268], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 883/2000, Reward: -15.74637609703358, done: True\n",
      "state: [ 0.0037914  -0.00043988], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 884/2000, Reward: -17.222531689962647, done: True\n",
      "state: [ 0.00231495 -0.00280354], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 885/2000, Reward: -16.216386257316667, done: True\n",
      "state: [ 0.00682714 -0.00664242], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 886/2000, Reward: -14.445410049157017, done: True\n",
      "state: [ 0.0092002  -0.00669218], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 887/2000, Reward: -14.879703462530234, done: True\n",
      "state: [0.00299522 0.00165551], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 888/2000, Reward: -15.564099426362775, done: True\n",
      "state: [ 0.00870588 -0.00655594], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 889/2000, Reward: -15.098229754138115, done: True\n",
      "state: [ 0.00137325 -0.00171222], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 890/2000, Reward: -14.665979921328983, done: True\n",
      "state: [ 0.00540393 -0.00111087], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 891/2000, Reward: -14.347411196262414, done: True\n",
      "state: [ 0.00824802 -0.00677883], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 892/2000, Reward: -17.883319200693794, done: True\n",
      "state: [ 0.00138953 -0.00495345], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 893/2000, Reward: -15.34844460980016, done: True\n",
      "state: [ 0.00250861 -0.00319396], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 894/2000, Reward: -17.094852963506607, done: True\n",
      "state: [ 0.0030782  -0.00466413], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 895/2000, Reward: -14.460666726827979, done: True\n",
      "state: [ 0.00881099 -0.00731622], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 896/2000, Reward: -15.537585308386506, done: True\n",
      "state: [-0.00720305 -0.00391648], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 897/2000, Reward: -16.35675628685888, done: True\n",
      "state: [ 0.00285661 -0.00387028], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 898/2000, Reward: -16.768640166200278, done: True\n",
      "state: [ 0.00952775 -0.00732292], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 899/2000, Reward: -17.328223011235586, done: True\n",
      "state: [ 0.00898264 -0.00977102], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 900/2000, Reward: -15.663666069508835, done: True\n",
      "state: [ 0.00613257 -0.00561671], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 901/2000, Reward: -14.44146160054038, done: True\n",
      "state: [ 0.00691352 -0.00533685], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 902/2000, Reward: -16.569707942552252, done: True\n",
      "state: [ 0.00115578 -0.00593508], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 903/2000, Reward: -18.11445857601422, done: True\n",
      "state: [ 0.00735804 -0.00013865], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 904/2000, Reward: -14.785884980680956, done: True\n",
      "state: [ 0.00913087 -0.0066439 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 905/2000, Reward: -16.881288579174168, done: True\n",
      "state: [ 0.0055112  -0.00444156], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 906/2000, Reward: -15.220991161265118, done: True\n",
      "state: [ 0.00130623 -0.00592035], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 907/2000, Reward: -14.896150528530672, done: True\n",
      "state: [ 0.00198951 -0.00279498], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 908/2000, Reward: -17.65222830100856, done: True\n",
      "state: [ 0.00444265 -0.00620237], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 909/2000, Reward: -14.995272663955058, done: True\n",
      "state: [ 0.00888008 -0.00673235], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 910/2000, Reward: -16.004489255564643, done: True\n",
      "state: [ 0.00118546 -0.00516875], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 911/2000, Reward: -17.21402854298918, done: True\n",
      "state: [ 0.00506946 -0.00528027], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 912/2000, Reward: -14.978475826553264, done: True\n",
      "state: [ 0.00590829 -0.0063677 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 913/2000, Reward: -14.55785533565832, done: True\n",
      "state: [ 0.00279322 -0.00444886], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 914/2000, Reward: -14.673014616492093, done: True\n",
      "state: [ 0.00952791 -0.00711391], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 915/2000, Reward: -15.67483396174148, done: True\n",
      "state: [ 0.00936721 -0.00435753], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 916/2000, Reward: -14.994090408513443, done: True\n",
      "state: [ 0.00540058 -0.00684082], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 917/2000, Reward: -16.445710183215002, done: True\n",
      "state: [ 0.00828819 -0.0026807 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 918/2000, Reward: -15.54309336613706, done: True\n",
      "state: [ 0.00169938 -0.00487082], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 919/2000, Reward: -16.784343170227842, done: True\n",
      "state: [ 0.00369015 -0.0069168 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 920/2000, Reward: -14.883582967255576, done: True\n",
      "state: [ 0.00262992 -0.0051077 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 921/2000, Reward: -16.003259916940877, done: True\n",
      "state: [ 0.00124129 -0.00658344], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 922/2000, Reward: -16.093541788446352, done: True\n",
      "state: [ 0.00130656 -0.00590478], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 923/2000, Reward: -16.329555189909467, done: True\n",
      "state: [ 0.00223038 -0.00377003], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 924/2000, Reward: -15.761672527461114, done: True\n",
      "state: [ 0.00135039 -0.00598564], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 925/2000, Reward: -15.443896262350568, done: True\n",
      "state: [ 0.00388761 -0.00427576], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 926/2000, Reward: -14.569069758497875, done: True\n",
      "state: [ 0.00843826 -0.00707502], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 927/2000, Reward: -16.5498798199632, done: True\n",
      "state: [-0.00969869  0.00519499], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 928/2000, Reward: -14.762187015450161, done: True\n",
      "state: [ 0.00471854 -0.00384319], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 929/2000, Reward: -15.763660215528947, done: True\n",
      "state: [ 0.00505602 -0.00331145], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 930/2000, Reward: -14.879888757180879, done: True\n",
      "state: [ 0.00332229 -0.00519581], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 931/2000, Reward: -17.021118340539147, done: True\n",
      "state: [ 0.00870774 -0.00202708], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 932/2000, Reward: -15.668719833021422, done: True\n",
      "state: [ 0.0082066  -0.00246568], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 933/2000, Reward: -15.74194726072214, done: True\n",
      "state: [ 0.00132371 -0.00782536], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 934/2000, Reward: -14.460132696980462, done: True\n",
      "state: [ 0.00831346 -0.00818083], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 935/2000, Reward: -15.2468394215933, done: True\n",
      "state: [-6.93456333e-05 -4.48832065e-03], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 936/2000, Reward: -14.551730706548271, done: True\n",
      "state: [ 0.00818075 -0.00551909], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 937/2000, Reward: -15.534590729170398, done: True\n",
      "state: [ 0.00581944 -0.00539425], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 938/2000, Reward: -14.779198501637774, done: True\n",
      "state: [ 0.00118057 -0.00482481], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 939/2000, Reward: -15.688331626282746, done: True\n",
      "state: [ 0.00264688 -0.00481729], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 940/2000, Reward: -14.785665867603536, done: True\n",
      "state: [ 0.0075374  -0.00689769], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 941/2000, Reward: -15.20337817900502, done: True\n",
      "state: [ 0.00669721 -0.00762602], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 942/2000, Reward: -15.659912519590007, done: True\n",
      "state: [ 0.00761043 -0.00331179], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 943/2000, Reward: -14.782871562775096, done: True\n",
      "state: [ 0.00591865 -0.00192325], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 944/2000, Reward: -16.22006696527773, done: True\n",
      "state: [ 0.00588389 -0.00552173], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 945/2000, Reward: -15.681996473226476, done: True\n",
      "state: [ 0.00923671 -0.00864804], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 946/2000, Reward: -17.444790763911314, done: True\n",
      "state: [ 0.0011352  -0.00498806], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 947/2000, Reward: -16.334686968532573, done: True\n",
      "state: [ 0.00265285 -0.0057266 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 948/2000, Reward: -15.786093121574487, done: True\n",
      "state: [ 0.00586176 -0.00656321], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 949/2000, Reward: -15.426697734091933, done: True\n",
      "state: [ 0.00462496 -0.00513446], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 950/2000, Reward: -19.99331643888238, done: True\n",
      "state: [ 0.00205855 -0.00415638], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 951/2000, Reward: -14.895940920008622, done: True\n",
      "state: [ 0.00960089 -0.00670203], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 952/2000, Reward: -14.561557576390868, done: True\n",
      "state: [ 0.00525909 -0.00569095], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 953/2000, Reward: -15.561904956993834, done: True\n",
      "state: [ 0.0087928  -0.00730725], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 954/2000, Reward: -15.342833716344732, done: True\n",
      "state: [ 0.00799182 -0.00529426], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 955/2000, Reward: -15.668312442194406, done: True\n",
      "state: [ 0.00566241 -0.00704135], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 956/2000, Reward: -16.874522736870603, done: True\n",
      "state: [-0.0081401  -0.00331432], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 957/2000, Reward: -14.780649787067384, done: True\n",
      "state: [ 0.00119507 -0.00795588], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 958/2000, Reward: -16.11685648651127, done: True\n",
      "state: [ 0.00118163 -0.00305581], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 959/2000, Reward: -15.563069792975833, done: True\n",
      "state: [ 0.00632282 -0.00693299], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 960/2000, Reward: -15.539280757875314, done: True\n",
      "state: [ 0.00590903 -0.0068065 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 961/2000, Reward: -17.545993812691098, done: True\n",
      "state: [ 0.00944984 -0.00908345], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 962/2000, Reward: -17.987842566670405, done: True\n",
      "state: [ 0.00288096 -0.0048605 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 963/2000, Reward: -17.666020141810833, done: True\n",
      "state: [ 0.00741089 -0.00102095], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 964/2000, Reward: -15.657672612998097, done: True\n",
      "state: [ 0.00581716 -0.00460942], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 965/2000, Reward: -18.301859448875355, done: True\n",
      "state: [ 0.00555404 -0.00705737], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 966/2000, Reward: -16.650687807491483, done: True\n",
      "state: [ 0.00482015 -0.00713033], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 967/2000, Reward: -16.325396974492257, done: True\n",
      "state: [ 0.00115677 -0.00567741], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 968/2000, Reward: -16.2239645365209, done: True\n",
      "state: [ 0.00250218 -0.00475461], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 969/2000, Reward: -17.543426602500148, done: True\n",
      "state: [ 0.00687397 -0.00564357], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 970/2000, Reward: -16.759703845663317, done: True\n",
      "state: [ 0.00137041 -0.00441047], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 971/2000, Reward: -15.887529199673518, done: True\n",
      "state: [ 0.00383123 -0.00705704], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 972/2000, Reward: -15.763014005808397, done: True\n",
      "state: [ 0.00893032 -0.00897587], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 973/2000, Reward: -14.662811699286337, done: True\n",
      "state: [ 0.00679093 -0.00653217], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 974/2000, Reward: -17.234087580927167, done: True\n",
      "state: [ 0.00158263 -0.0037681 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 975/2000, Reward: -16.209793905857865, done: True\n",
      "state: [ 0.00713031 -0.00695673], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 976/2000, Reward: -16.88514999054453, done: True\n",
      "state: [ 0.00247783 -0.00460089], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 977/2000, Reward: -15.097979197990357, done: True\n",
      "state: [ 0.00577118 -0.00498742], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 978/2000, Reward: -16.32458328433224, done: True\n",
      "state: [ 0.00264096 -0.00581894], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 979/2000, Reward: -16.996915021320813, done: True\n",
      "state: [ 0.00773234 -0.00651618], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 980/2000, Reward: -15.546826068323229, done: True\n",
      "state: [ 0.001148   -0.00694769], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 981/2000, Reward: -18.653052128206692, done: True\n",
      "state: [-0.00705741  0.00183398], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 982/2000, Reward: -14.982268690386006, done: True\n",
      "state: [ 0.00123015 -0.00735063], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 983/2000, Reward: -16.10853196464353, done: True\n",
      "state: [ 0.00134226 -0.00421809], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 984/2000, Reward: -15.785276250043301, done: True\n",
      "state: [ 0.00189073 -0.00434005], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 985/2000, Reward: -16.44749119417908, done: True\n",
      "state: [ 0.00222084 -0.00480363], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 986/2000, Reward: -14.66107433717867, done: True\n",
      "state: [ 0.00639109 -0.00615115], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 987/2000, Reward: -17.310990357937115, done: True\n",
      "state: [ 0.00628047 -0.00669206], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 988/2000, Reward: -18.317702700570262, done: True\n",
      "state: [ 0.00449224 -0.00639568], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 989/2000, Reward: -16.213254344456736, done: True\n",
      "state: [ 0.00689647 -0.00497322], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 990/2000, Reward: -15.77017530936526, done: True\n",
      "state: [ 0.00799997 -0.00787939], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 991/2000, Reward: -16.223616369142974, done: True\n",
      "state: [ 0.00442325 -0.00655786], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 992/2000, Reward: -14.883712678122542, done: True\n",
      "state: [ 0.00502634 -0.00819664], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 993/2000, Reward: -15.326317574213311, done: True\n",
      "state: [ 0.00929167 -0.00760773], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 994/2000, Reward: -14.669158279674516, done: True\n",
      "state: [ 0.00422124 -0.00634841], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 995/2000, Reward: -16.335064538441593, done: True\n",
      "state: [ 0.00469313 -0.00617771], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 996/2000, Reward: -14.67069557041147, done: True\n",
      "state: [ 0.00275401 -0.00354994], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 997/2000, Reward: -14.785806117862437, done: True\n",
      "state: [ 0.00358984 -0.00641371], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 998/2000, Reward: -14.665684304133725, done: True\n",
      "state: [ 0.0059554  -0.00910318], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 999/2000, Reward: -14.345417246463883, done: True\n",
      "state: [ 0.00625452 -0.00603519], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1000/2000, Reward: -15.427476410002102, done: True\n",
      "state: [ 0.00234207 -0.00410437], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1001/2000, Reward: -16.641101132158273, done: True\n",
      "state: [ 0.00982693 -0.00714731], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1002/2000, Reward: -14.660794924161218, done: True\n",
      "state: [ 0.00116794 -0.00849548], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1003/2000, Reward: -14.541915893639391, done: True\n",
      "state: [-0.00830533 -0.00293988], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1004/2000, Reward: -16.331535497750828, done: True\n",
      "state: [ 0.00864826 -0.00874427], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1005/2000, Reward: -15.649885095298723, done: True\n",
      "state: [ 0.00914202 -0.00791545], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1006/2000, Reward: -15.426779961121905, done: True\n",
      "state: [ 0.00120993 -0.00498945], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1007/2000, Reward: -17.766034802638707, done: True\n",
      "state: [ 0.00230567 -0.00404929], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1008/2000, Reward: -14.548139812338235, done: True\n",
      "state: [-0.00701662 -0.00100694], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1009/2000, Reward: -15.538813156762238, done: True\n",
      "state: [ 0.00844344 -0.00861608], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1010/2000, Reward: -16.569545938448222, done: True\n",
      "state: [ 0.0025743  -0.00632491], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1011/2000, Reward: -15.541720222599533, done: True\n",
      "state: [ 0.00138357 -0.00637123], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1012/2000, Reward: -14.982612869293058, done: True\n",
      "state: [ 0.00447915 -0.00378035], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1013/2000, Reward: -15.959521741298232, done: True\n",
      "state: [ 0.00404899 -0.00230953], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1014/2000, Reward: -15.56303981222365, done: True\n",
      "state: [ 0.00384322 -0.00568483], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1015/2000, Reward: -15.317776985314525, done: True\n",
      "state: [-0.00139262  0.00260653], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1016/2000, Reward: -15.232167903807879, done: True\n",
      "state: [ 0.00137516 -0.00527208], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1017/2000, Reward: -16.32665144197221, done: True\n",
      "state: [ 0.00554183 -0.00729459], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1018/2000, Reward: -16.86247087820826, done: True\n",
      "state: [ 0.00322586 -0.00511898], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1019/2000, Reward: -15.970993092812371, done: True\n",
      "state: [ 0.00439426 -0.00384287], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1020/2000, Reward: -15.867981621851795, done: True\n",
      "state: [ 0.00550419 -0.0075306 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1021/2000, Reward: -16.333223685313612, done: True\n",
      "state: [ 0.00514123 -0.0017661 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1022/2000, Reward: -15.218174826704022, done: True\n",
      "state: [ 0.00128743 -0.00553139], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1023/2000, Reward: -17.55212093430552, done: True\n",
      "state: [ 0.00116177 -0.0064913 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1024/2000, Reward: -16.415578710846365, done: True\n",
      "state: [ 0.00112918 -0.00647903], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1025/2000, Reward: -14.872598095771671, done: True\n",
      "state: [ 0.00304612 -0.00012144], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1026/2000, Reward: -14.76487280362927, done: True\n",
      "state: [ 0.0042363  -0.00493437], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1027/2000, Reward: -15.544291448001719, done: True\n",
      "state: [ 0.00260375 -0.00083939], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1028/2000, Reward: -15.104470908907858, done: True\n",
      "state: [ 0.00705726 -0.00676681], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1029/2000, Reward: -15.65092454985374, done: True\n",
      "state: [ 0.00173756 -0.00492979], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1030/2000, Reward: -16.088102435747114, done: True\n",
      "state: [ 0.00632189 -0.00526792], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1031/2000, Reward: -18.87712907859324, done: True\n",
      "state: [ 0.00484758 -0.00500955], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1032/2000, Reward: -17.210626239051052, done: True\n",
      "state: [ 0.00221227 -0.00484559], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1033/2000, Reward: -15.960866712751498, done: True\n",
      "state: [ 0.001188   -0.00610982], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1034/2000, Reward: -14.865944655534928, done: True\n",
      "state: [ 0.00594791 -0.00669544], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1035/2000, Reward: -16.42382445606503, done: True\n",
      "state: [ 0.00658979 -0.00555652], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1036/2000, Reward: -15.54861246143839, done: True\n",
      "state: [ 0.00556215 -0.00365589], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1037/2000, Reward: -15.528680702889705, done: True\n",
      "state: [ 0.00744177 -0.00688535], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1038/2000, Reward: -14.867599495997833, done: True\n",
      "state: [ 0.00933257 -0.00893024], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1039/2000, Reward: -15.41953542941713, done: True\n",
      "state: [ 0.00131114 -0.00308534], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1040/2000, Reward: -16.976616083088235, done: True\n",
      "state: [-0.00193652  0.00014049], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1041/2000, Reward: -14.872523986569744, done: True\n",
      "state: [ 0.00114498 -0.00693351], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1042/2000, Reward: -14.877887290851902, done: True\n",
      "state: [ 0.00385072 -0.00495828], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1043/2000, Reward: -15.756995150344322, done: True\n",
      "state: [0.00663562 0.00010202], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1044/2000, Reward: -16.334274771413593, done: True\n",
      "state: [ 0.00743311 -0.00071243], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1045/2000, Reward: -15.98479764998957, done: True\n",
      "state: [-0.0012426   0.00138304], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1046/2000, Reward: -15.537386847547378, done: True\n",
      "state: [-0.0072269  -0.00166766], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1047/2000, Reward: -15.869543502072384, done: True\n",
      "state: [ 0.00677095 -0.00016539], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1048/2000, Reward: -14.552069579358367, done: True\n",
      "state: [ 0.00389493 -0.00234874], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1049/2000, Reward: -16.449421264298948, done: True\n",
      "state: [ 0.00681996 -0.0058198 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1050/2000, Reward: -16.31238038308393, done: True\n",
      "state: [ 0.00165418 -0.00476059], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1051/2000, Reward: -14.439794866672663, done: True\n",
      "state: [ 0.0033699  -0.00099932], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1052/2000, Reward: -14.665454629173569, done: True\n",
      "state: [0.00158958 0.00209916], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1053/2000, Reward: -15.996005005135798, done: True\n",
      "state: [-0.00298296 -0.000193  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1054/2000, Reward: -15.770746034022572, done: True\n",
      "state: [-0.00122942 -0.00118896], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1055/2000, Reward: -14.426553349968001, done: True\n",
      "state: [-0.00837185 -0.00108261], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1056/2000, Reward: -14.869151571584649, done: True\n",
      "state: [-0.00966774  0.00594733], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1057/2000, Reward: -14.976299631333541, done: True\n",
      "state: [0.00423887 0.00133969], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1058/2000, Reward: -14.656966224165036, done: True\n",
      "state: [-0.00696114 -0.0004659 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1059/2000, Reward: -15.972638094742022, done: True\n",
      "state: [-0.00995323 -0.00270126], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1060/2000, Reward: -17.427163401873642, done: True\n",
      "state: [-0.00131796 -0.00206732], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1061/2000, Reward: -14.443697818418297, done: True\n",
      "state: [ 0.00404365 -0.00593994], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1062/2000, Reward: -14.769388860495534, done: True\n",
      "state: [ 0.00402013 -0.00635931], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1063/2000, Reward: -15.307248565821704, done: True\n",
      "state: [-0.00127023  0.00273607], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1064/2000, Reward: -16.214369679235254, done: True\n",
      "state: [ 0.0012284  -0.00318751], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1065/2000, Reward: -14.677896298449348, done: True\n",
      "state: [ 0.00121915 -0.00420695], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1066/2000, Reward: -14.779165982648792, done: True\n",
      "state: [-0.00456698  0.00142409], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1067/2000, Reward: -14.739494479855122, done: True\n",
      "state: [ 0.00663488 -0.00139547], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1068/2000, Reward: -14.764172048788778, done: True\n",
      "state: [-0.00721863 -0.00060901], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1069/2000, Reward: -14.437332584227367, done: True\n",
      "state: [ 0.00318163 -0.00226229], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1070/2000, Reward: -15.85209721910727, done: True\n",
      "state: [ 0.00455159 -0.0005501 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1071/2000, Reward: -16.126428864727533, done: True\n",
      "state: [-0.00927504  0.00643511], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1072/2000, Reward: -14.56100414964459, done: True\n",
      "state: [0.00573978 0.00061055], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1073/2000, Reward: -17.072253022538273, done: True\n",
      "state: [-0.0013228  0.0008343], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1074/2000, Reward: -16.646413561404426, done: True\n",
      "state: [0.00526562 0.00341679], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1075/2000, Reward: -15.904555188613708, done: True\n",
      "state: [-0.00725384 -0.00109262], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1076/2000, Reward: -14.012868600436931, done: True\n",
      "state: [0.00397089 0.00356452], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1077/2000, Reward: -14.55224271801713, done: True\n",
      "state: [-0.00815689  0.00423395], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1078/2000, Reward: -14.561483311150166, done: True\n",
      "state: [ 0.00288653 -0.00276803], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1079/2000, Reward: -15.766802312143316, done: True\n",
      "state: [0.00239994 0.00357522], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1080/2000, Reward: -14.019527791805514, done: True\n",
      "state: [-0.0081873   0.00520092], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1081/2000, Reward: -14.917863449659231, done: True\n",
      "state: [0.00395576 0.00324283], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1082/2000, Reward: -15.345510916388438, done: True\n",
      "state: [-0.0092249  -0.00078325], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1083/2000, Reward: -14.118443334932243, done: True\n",
      "state: [ 0.00369548 -0.00211467], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1084/2000, Reward: -13.921454936053538, done: True\n",
      "state: [-0.00860417  0.00204663], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1085/2000, Reward: -13.927692908298082, done: True\n",
      "state: [ 0.00606839 -0.00010605], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1086/2000, Reward: -14.785840542123294, done: True\n",
      "state: [ 0.00609031 -0.0080843 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1087/2000, Reward: -13.914327544739757, done: True\n",
      "state: [ 0.00380664 -0.00321893], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1088/2000, Reward: -16.443810705307712, done: True\n",
      "state: [ 0.00114742 -0.00673076], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1089/2000, Reward: -14.113685028899184, done: True\n",
      "state: [ 0.00612327 -0.00073303], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1090/2000, Reward: -14.920920024166277, done: True\n",
      "state: [0.00312726 0.00394535], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1091/2000, Reward: -13.912542306526003, done: True\n",
      "state: [ 0.00333975 -0.00292944], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1092/2000, Reward: -16.471010139492005, done: True\n",
      "state: [-0.00800015  0.00728763], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1093/2000, Reward: -14.454359727107725, done: True\n",
      "state: [ 0.00709039 -0.00443088], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1094/2000, Reward: -15.010959479920885, done: True\n",
      "state: [ 0.00165674 -0.00147876], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1095/2000, Reward: -16.338580983447876, done: True\n",
      "state: [ 0.00574455 -0.00544942], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1096/2000, Reward: -13.696814649689008, done: True\n",
      "state: [ 0.00604659 -0.00508449], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1097/2000, Reward: -15.452257654134833, done: True\n",
      "state: [ 0.00272068 -0.0005793 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1098/2000, Reward: -13.703699172568564, done: True\n",
      "state: [ 0.00401406 -0.00320999], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1099/2000, Reward: -14.916205274324028, done: True\n",
      "state: [ 0.0043081  -0.00397289], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1100/2000, Reward: -13.91808741185929, done: True\n",
      "state: [ 0.00546227 -0.00230086], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1101/2000, Reward: -16.034228673816084, done: True\n",
      "state: [ 0.00768044 -0.00759239], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1102/2000, Reward: -14.695787674863585, done: True\n",
      "state: [ 0.00115066 -0.00586915], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1103/2000, Reward: -14.020315999577448, done: True\n",
      "state: [ 0.00450916 -0.00237784], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1104/2000, Reward: -17.76731343085583, done: True\n",
      "state: [-0.00590957  0.0014042 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1105/2000, Reward: -14.34885028562351, done: True\n",
      "state: [ 0.00772277 -0.00690974], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1106/2000, Reward: -16.552354134434054, done: True\n",
      "state: [ 0.00958289 -0.00687697], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1107/2000, Reward: -14.799454686027797, done: True\n",
      "state: [ 0.00956634 -0.00731686], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1108/2000, Reward: -14.770181155847157, done: True\n",
      "state: [ 0.0052336  -0.00454771], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1109/2000, Reward: -16.763815893526907, done: True\n",
      "state: [ 0.00969916 -0.00652771], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1110/2000, Reward: -16.0600579507698, done: True\n",
      "state: [ 0.00488426 -0.00205649], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1111/2000, Reward: -19.11120299771352, done: True\n",
      "state: [-0.00524901  0.003688  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1112/2000, Reward: -15.01578321002732, done: True\n",
      "state: [ 0.00211629 -0.00518054], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1113/2000, Reward: -14.782504759044443, done: True\n",
      "state: [ 0.00429733 -0.00499706], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1114/2000, Reward: -14.777857977021725, done: True\n",
      "state: [-0.00399532 -0.00434746], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1115/2000, Reward: -15.586737982900548, done: True\n",
      "state: [-0.00206939 -0.00224281], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1116/2000, Reward: -15.665440029831165, done: True\n",
      "state: [ 0.00602694 -0.00680544], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1117/2000, Reward: -14.224730798488206, done: True\n",
      "state: [ 0.00766761 -0.00349003], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1118/2000, Reward: -15.54661814659389, done: True\n",
      "state: [ 0.00231571 -0.00504629], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1119/2000, Reward: -14.230012642971221, done: True\n",
      "state: [ 0.00236552 -0.00205292], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1120/2000, Reward: -13.700506935306409, done: True\n",
      "state: [ 0.00648186 -0.00482095], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1121/2000, Reward: -15.31064408403912, done: True\n",
      "state: [-0.00589607 -0.00226875], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1122/2000, Reward: -15.218154692199352, done: True\n",
      "state: [ 0.00446287 -0.00422048], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1123/2000, Reward: -15.804256986345736, done: True\n",
      "state: [0.0046859 0.0021224], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1124/2000, Reward: -15.006302745856145, done: True\n",
      "state: [ 0.00182016 -0.00276468], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1125/2000, Reward: -14.750307859348748, done: True\n",
      "state: [ 0.00299338 -0.00496419], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1126/2000, Reward: -17.907272863352137, done: True\n",
      "state: [-0.00118822 -0.00436786], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1127/2000, Reward: -14.01454838450884, done: True\n",
      "state: [ 0.00444556 -0.00402294], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1128/2000, Reward: -14.02677155069268, done: True\n",
      "state: [-0.00927016 -0.00334898], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1129/2000, Reward: -15.847147884485342, done: True\n",
      "state: [ 0.00511322 -0.00478383], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1130/2000, Reward: -14.444676637611277, done: True\n",
      "state: [ 0.00873106 -0.00746893], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1131/2000, Reward: -18.041167251512626, done: True\n",
      "state: [-0.00121083 -0.00381768], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1132/2000, Reward: -16.077678086417553, done: True\n",
      "state: [ 0.00680808 -0.0069668 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1133/2000, Reward: -13.901246916389526, done: True\n",
      "state: [-0.00907137 -0.00332418], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1134/2000, Reward: -15.762531557365849, done: True\n",
      "state: [-0.00848225 -0.00612495], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1135/2000, Reward: -14.34474121713461, done: True\n",
      "state: [-0.00843906 -0.00560825], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1136/2000, Reward: -14.569474634320768, done: True\n",
      "state: [-0.00758848  0.00044596], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1137/2000, Reward: -14.98281675577189, done: True\n",
      "state: [ 0.0037949  -0.00737613], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1138/2000, Reward: -14.537014000194501, done: True\n",
      "state: [-0.00864102 -0.00645509], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1139/2000, Reward: -14.764933241412752, done: True\n",
      "state: [ 0.00480247 -0.00601844], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1140/2000, Reward: -14.112230364836174, done: True\n",
      "state: [-0.0087631  -0.00413618], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1141/2000, Reward: -16.008387587129643, done: True\n",
      "state: [-0.00285419 -0.00581844], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1142/2000, Reward: -15.764683378153334, done: True\n",
      "state: [0.00235924 0.00160159], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1143/2000, Reward: -14.771419303036092, done: True\n",
      "state: [-0.0034536  -0.00933243], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1144/2000, Reward: -15.759729942723874, done: True\n",
      "state: [-0.00712784 -0.00391485], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1145/2000, Reward: -14.879699569951049, done: True\n",
      "state: [ 0.0007816  -0.00910219], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1146/2000, Reward: -13.697918790262381, done: True\n",
      "state: [-0.00717124 -0.00667075], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1147/2000, Reward: -15.880698708416869, done: True\n",
      "state: [0.002583   0.00025539], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1148/2000, Reward: -15.555220348556142, done: True\n",
      "state: [-0.00709355 -0.00404964], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1149/2000, Reward: -14.80750156658395, done: True\n",
      "state: [-0.00962637 -0.00487539], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1150/2000, Reward: -16.874922377897448, done: True\n",
      "state: [ 0.00517152 -0.00753982], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1151/2000, Reward: -14.459192125157406, done: True\n",
      "state: [ 0.00571875 -0.00863111], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1152/2000, Reward: -15.712849962404066, done: True\n",
      "state: [-0.00120114 -0.00331912], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1153/2000, Reward: -14.991468610086654, done: True\n",
      "state: [ 0.0073151  -0.00376556], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1154/2000, Reward: -15.64481499190053, done: True\n",
      "state: [ 0.00291265 -0.00515765], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1155/2000, Reward: -14.860437221550686, done: True\n",
      "state: [ 0.00559471 -0.00791194], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1156/2000, Reward: -14.54596582086528, done: True\n",
      "state: [ 0.0026145  -0.00557054], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1157/2000, Reward: -17.542685789979657, done: True\n",
      "state: [ 0.00138906 -0.00653879], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1158/2000, Reward: -14.234326758440766, done: True\n",
      "state: [ 0.00374756 -0.00558113], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1159/2000, Reward: -15.534288129951992, done: True\n",
      "state: [ 0.00284435 -0.00471286], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1160/2000, Reward: -15.644817355034142, done: True\n",
      "state: [-0.00091796 -0.00928036], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1161/2000, Reward: -14.58431884070236, done: True\n",
      "state: [ 0.00121372 -0.00632525], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1162/2000, Reward: -15.337630973478575, done: True\n",
      "state: [ 0.00745242 -0.00691637], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1163/2000, Reward: -14.692593918831433, done: True\n",
      "state: [ 0.00966722 -0.00719268], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1164/2000, Reward: -15.337461927970262, done: True\n",
      "state: [ 0.00909202 -0.00578904], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1165/2000, Reward: -16.356987077900765, done: True\n",
      "state: [ 0.00193033 -0.0078051 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1166/2000, Reward: -15.5355749653212, done: True\n",
      "state: [ 0.00221167 -0.00796899], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1167/2000, Reward: -18.3170890101134, done: True\n",
      "state: [-0.00138908  0.00118898], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1168/2000, Reward: -15.41943767085723, done: True\n",
      "state: [ 0.00397383 -0.00298828], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1169/2000, Reward: -16.336896510074208, done: True\n",
      "state: [ 0.00320678 -0.00584434], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1170/2000, Reward: -15.009608470602554, done: True\n",
      "state: [ 0.00158153 -0.00547843], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1171/2000, Reward: -16.903060621094035, done: True\n",
      "state: [-0.00128306 -0.00022337], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1172/2000, Reward: -15.439208564016528, done: True\n",
      "state: [ 0.00610637 -0.00880529], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1173/2000, Reward: -16.74380537610604, done: True\n",
      "state: [ 0.00126477 -0.00646889], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1174/2000, Reward: -15.212760560996207, done: True\n",
      "state: [ 0.0028409  -0.00631492], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1175/2000, Reward: -15.640179521742986, done: True\n",
      "state: [ 0.00820207 -0.00635261], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1176/2000, Reward: -14.975965587607686, done: True\n",
      "state: [ 0.00817701 -0.0072471 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1177/2000, Reward: -16.105169313079728, done: True\n",
      "state: [ 0.00825101 -0.00889833], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1178/2000, Reward: -13.702927743353573, done: True\n",
      "state: [ 0.00653854 -0.00464774], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1179/2000, Reward: -13.795802297280066, done: True\n",
      "state: [ 0.0092081  -0.00899929], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1180/2000, Reward: -14.433518926450992, done: True\n",
      "state: [ 0.00214023 -0.0057558 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1181/2000, Reward: -16.88762345369307, done: True\n",
      "state: [ 0.00736626 -0.00896245], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1182/2000, Reward: -17.422795690621523, done: True\n",
      "state: [ 0.00884734 -0.00883646], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1183/2000, Reward: -14.445964106584322, done: True\n",
      "state: [ 0.00389166 -0.00731824], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1184/2000, Reward: -14.438225102171984, done: True\n",
      "state: [ 0.00640819 -0.00690539], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1185/2000, Reward: -14.241413492746773, done: True\n",
      "state: [-0.00027244 -0.00913606], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1186/2000, Reward: -14.96763824957621, done: True\n",
      "state: [ 0.0077531  -0.00561528], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1187/2000, Reward: -15.99454685934231, done: True\n",
      "state: [ 0.0046438  -0.00639917], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1188/2000, Reward: -15.14976751329178, done: True\n",
      "state: [ 0.00335667 -0.0061885 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1189/2000, Reward: -15.293840488653164, done: True\n",
      "state: [ 0.00245411 -0.00711333], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1190/2000, Reward: -15.551274564544077, done: True\n",
      "state: [ 0.00401963 -0.00891669], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1191/2000, Reward: -14.340424041144722, done: True\n",
      "state: [ 0.00332444 -0.00952512], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1192/2000, Reward: -14.589625138730277, done: True\n",
      "state: [ 0.00531933 -0.00699861], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1193/2000, Reward: -17.52237083165429, done: True\n",
      "state: [ 0.00480788 -0.00628159], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1194/2000, Reward: -14.422398033448196, done: True\n",
      "state: [ 0.0068215  -0.00805314], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1195/2000, Reward: -15.764962881144584, done: True\n",
      "state: [ 0.00661009 -0.00838155], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1196/2000, Reward: -13.698785282335233, done: True\n",
      "state: [ 0.00912392 -0.00652728], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1197/2000, Reward: -14.658473638322889, done: True\n",
      "state: [ 0.0059634  -0.00820554], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1198/2000, Reward: -15.336287113206211, done: True\n",
      "state: [ 0.0039613  -0.00526214], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1199/2000, Reward: -14.10611477563217, done: True\n",
      "state: [ 0.00959921 -0.00897054], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1200/2000, Reward: -14.34406885326045, done: True\n",
      "state: [ 0.00826481 -0.00862434], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1201/2000, Reward: -15.921742032247726, done: True\n",
      "state: [ 0.0049727  -0.00661164], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1202/2000, Reward: -16.104744821076284, done: True\n",
      "state: [0.00414143 0.00075744], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1203/2000, Reward: -14.753902703432018, done: True\n",
      "state: [-0.00771512 -0.00581618], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1204/2000, Reward: -14.98464497845225, done: True\n",
      "state: [ 0.00532022 -0.00572636], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1205/2000, Reward: -14.562517684990354, done: True\n",
      "state: [-0.00777409  0.0023123 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1206/2000, Reward: -15.354796342838316, done: True\n",
      "state: [ 0.00470203 -0.00644509], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1207/2000, Reward: -14.543342802192484, done: True\n",
      "state: [ 0.00718938 -0.00704365], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1208/2000, Reward: -14.798020350972894, done: True\n",
      "state: [ 0.00116283 -0.00558285], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1209/2000, Reward: -14.666973026064541, done: True\n",
      "state: [ 0.00946767 -0.00779894], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1210/2000, Reward: -14.868117222860903, done: True\n",
      "state: [ 0.00793582 -0.00582384], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1211/2000, Reward: -15.768115034077542, done: True\n",
      "state: [ 0.00640078 -0.00799108], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1212/2000, Reward: -15.103530977148928, done: True\n",
      "state: [ 0.00138283 -0.00471742], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1213/2000, Reward: -14.556931604511947, done: True\n",
      "state: [ 0.00384845 -0.00591516], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1214/2000, Reward: -15.218896746889252, done: True\n",
      "state: [ 0.00247852 -0.00596505], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1215/2000, Reward: -14.42880942505166, done: True\n",
      "state: [ 0.00831192 -0.00835899], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1216/2000, Reward: -14.99772723300583, done: True\n",
      "state: [ 0.00694796 -0.00634125], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1217/2000, Reward: -15.752700810052428, done: True\n",
      "state: [ 0.00136346 -0.0029412 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1218/2000, Reward: -14.760481948054437, done: True\n",
      "state: [ 0.000496   -0.00870572], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1219/2000, Reward: -14.88679637786545, done: True\n",
      "state: [ 0.00131095 -0.00661275], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1220/2000, Reward: -14.10935703425614, done: True\n",
      "state: [ 0.00609936 -0.00698487], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1221/2000, Reward: -14.439972622686868, done: True\n",
      "state: [ 0.00504669 -0.00677294], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1222/2000, Reward: -14.54438038627948, done: True\n",
      "state: [ 0.00375565 -0.00582733], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1223/2000, Reward: -14.647187637348976, done: True\n",
      "state: [ 0.00440714 -0.00526714], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1224/2000, Reward: -14.872808732649743, done: True\n",
      "state: [ 0.00427859 -0.00748824], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1225/2000, Reward: -15.207485339346189, done: True\n",
      "state: [ 0.0017922 -0.0063105], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1226/2000, Reward: -15.989167473423423, done: True\n",
      "state: [ 0.00392588 -0.00619857], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1227/2000, Reward: -16.309939367766585, done: True\n",
      "state: [ 0.00728454 -0.00522992], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1228/2000, Reward: -15.561087740224313, done: True\n",
      "state: [ 0.00270276 -0.00406169], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1229/2000, Reward: -16.222576893348386, done: True\n",
      "state: [ 0.00597594 -0.0070429 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1230/2000, Reward: -16.444150664697723, done: True\n",
      "state: [ 0.0058399  -0.00632749], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1231/2000, Reward: -16.101503280030396, done: True\n",
      "state: [ 0.00589015 -0.00698135], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1232/2000, Reward: -14.114413435398795, done: True\n",
      "state: [ 0.00287661 -0.00538763], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1233/2000, Reward: -14.32457079327674, done: True\n",
      "state: [ 0.00595672 -0.00879466], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1234/2000, Reward: -16.103479585394666, done: True\n",
      "state: [ 0.00195729 -0.00609891], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1235/2000, Reward: -15.950788433912377, done: True\n",
      "state: [ 0.00842809 -0.00811094], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1236/2000, Reward: -16.990463915238855, done: True\n",
      "state: [ 0.00179333 -0.00469665], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1237/2000, Reward: -15.326347662081755, done: True\n",
      "state: [ 0.00260223 -0.00588247], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1238/2000, Reward: -15.20593942037511, done: True\n",
      "state: [ 0.00677168 -0.00731862], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1239/2000, Reward: -15.21993344371352, done: True\n",
      "state: [ 0.00447489 -0.00537574], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1240/2000, Reward: -14.551145611040416, done: True\n",
      "state: [ 0.00662414 -0.00738942], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1241/2000, Reward: -15.547407918048858, done: True\n",
      "state: [ 0.00270908 -0.00154606], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1242/2000, Reward: -16.54990265679266, done: True\n",
      "state: [ 0.00278288 -0.00571607], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1243/2000, Reward: -17.55385216633263, done: True\n",
      "state: [ 0.00135637 -0.00654526], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1244/2000, Reward: -15.458238616562014, done: True\n",
      "state: [ 0.00378631 -0.00649263], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1245/2000, Reward: -14.900898919857875, done: True\n",
      "state: [ 0.00852024 -0.00426551], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1246/2000, Reward: -15.888097706153324, done: True\n",
      "state: [ 0.00413425 -0.00447879], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1247/2000, Reward: -15.108440001340666, done: True\n",
      "state: [ 0.00546269 -0.00478196], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1248/2000, Reward: -14.994085418043346, done: True\n",
      "state: [ 0.00408492 -0.00521641], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1249/2000, Reward: -14.435776487620767, done: True\n",
      "state: [ 0.00749081 -0.00695559], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1250/2000, Reward: -16.532200238376824, done: True\n",
      "state: [ 0.0054871  -0.00628725], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1251/2000, Reward: -15.545486830178048, done: True\n",
      "state: [ 0.00782511 -0.00560532], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1252/2000, Reward: -15.21568210773463, done: True\n",
      "state: [ 0.00176631 -0.00349827], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1253/2000, Reward: -14.986270281949535, done: True\n",
      "state: [ 0.00343714 -0.00498732], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1254/2000, Reward: -16.414171975512744, done: True\n",
      "state: [ 0.00420344 -0.00253016], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1255/2000, Reward: -14.641290832735946, done: True\n",
      "state: [ 0.00477983 -0.0062228 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1256/2000, Reward: -16.216825919372596, done: True\n",
      "state: [ 0.00198563 -0.00502077], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1257/2000, Reward: -14.306979836596176, done: True\n",
      "state: [ 0.00233222 -0.00590143], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1258/2000, Reward: -14.654340248663248, done: True\n",
      "state: [ 0.00650061 -0.00388022], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1259/2000, Reward: -14.99507647686525, done: True\n",
      "state: [ 0.00266448 -0.00417044], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1260/2000, Reward: -14.98311007261491, done: True\n",
      "state: [ 0.00784852 -0.00535458], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1261/2000, Reward: -15.106248763078481, done: True\n",
      "state: [ 0.00902642 -0.00438406], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1262/2000, Reward: -14.988543281616458, done: True\n",
      "state: [ 0.00117265 -0.00546282], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1263/2000, Reward: -14.48489965298831, done: True\n",
      "state: [ 0.00138902 -0.00631557], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1264/2000, Reward: -15.338722195794508, done: True\n",
      "state: [ 0.00687581 -0.00509305], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1265/2000, Reward: -14.999816728287163, done: True\n",
      "state: [ 0.00409289 -0.00517498], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1266/2000, Reward: -14.538204154079878, done: True\n",
      "state: [ 0.00711681 -0.00667923], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1267/2000, Reward: -14.446226122352146, done: True\n",
      "state: [ 0.00589474 -0.00567832], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1268/2000, Reward: -15.649893151698615, done: True\n",
      "state: [-0.00218088 -0.0063598 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1269/2000, Reward: -16.330646943465702, done: True\n",
      "state: [ 0.00294471 -0.00443836], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1270/2000, Reward: -15.752899461364969, done: True\n",
      "state: [ 0.00118135 -0.00143739], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1271/2000, Reward: -14.005252165814333, done: True\n",
      "state: [ 0.00938092 -0.00866738], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1272/2000, Reward: -14.327847555859947, done: True\n",
      "state: [ 0.00294917 -0.00351419], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1273/2000, Reward: -16.08942326138352, done: True\n",
      "state: [ 0.00867278 -0.00607662], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1274/2000, Reward: -16.207171987955153, done: True\n",
      "state: [-0.00815495  0.00565588], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1275/2000, Reward: -14.440712126763017, done: True\n",
      "state: [ 0.00598824 -0.00622543], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1276/2000, Reward: -14.882188473094457, done: True\n",
      "state: [ 0.00294977 -0.00493788], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1277/2000, Reward: -14.546538190496584, done: True\n",
      "state: [ 0.00414186 -0.0023358 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1278/2000, Reward: -19.417125734926273, done: True\n",
      "state: [-0.00839986  0.00554945], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1279/2000, Reward: -15.303308386038223, done: True\n",
      "state: [ 0.005411  -0.0017376], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1280/2000, Reward: -14.847007866066074, done: True\n",
      "state: [ 0.00840666 -0.00645548], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1281/2000, Reward: -14.23366580695792, done: True\n",
      "state: [ 0.00401373 -0.00678705], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1282/2000, Reward: -14.779610268808167, done: True\n",
      "state: [ 0.00139663 -0.00408936], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1283/2000, Reward: -15.089988396724362, done: True\n",
      "state: [ 0.00277106 -0.00550494], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1284/2000, Reward: -16.10776620842245, done: True\n",
      "state: [ 0.00170802 -0.00338621], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1285/2000, Reward: -15.224788709085091, done: True\n",
      "state: [ 0.00611744 -0.00536855], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1286/2000, Reward: -17.081733782625257, done: True\n",
      "state: [ 0.00739962 -0.00643893], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1287/2000, Reward: -15.318330839253772, done: True\n",
      "state: [ 0.00274066 -0.0032693 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1288/2000, Reward: -14.900768731167505, done: True\n",
      "state: [ 0.00927944 -0.00798215], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1289/2000, Reward: -14.223801400275942, done: True\n",
      "state: [ 0.00474966 -0.00086835], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1290/2000, Reward: -15.74650460202291, done: True\n",
      "state: [ 0.00678268 -0.00495187], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1291/2000, Reward: -16.89845330749643, done: True\n",
      "state: [ 0.00129561 -0.00054344], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1292/2000, Reward: -13.89903429402404, done: True\n",
      "state: [ 0.00439183 -0.00362397], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1293/2000, Reward: -17.762610018651678, done: True\n",
      "state: [ 0.00138027 -0.00361973], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1294/2000, Reward: -15.640489348410032, done: True\n",
      "state: [ 0.00934265 -0.00561881], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1295/2000, Reward: -16.978036106943495, done: True\n",
      "state: [ 0.00905513 -0.0045685 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1296/2000, Reward: -15.114501341012087, done: True\n",
      "state: [ 0.00790942 -0.00527765], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1297/2000, Reward: -16.191229338308972, done: True\n",
      "state: [ 0.00945004 -0.00708627], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1298/2000, Reward: -14.658360010844492, done: True\n",
      "state: [ 0.00587439 -0.00620024], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1299/2000, Reward: -15.089021085239331, done: True\n",
      "state: [ 0.00586174 -0.0062609 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1300/2000, Reward: -14.544346206344585, done: True\n",
      "state: [ 0.00616685 -0.00518042], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1301/2000, Reward: -14.978629691633076, done: True\n",
      "state: [ 0.00693018 -0.0066007 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1302/2000, Reward: -14.993141143671968, done: True\n",
      "state: [ 0.00917041 -0.00433118], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1303/2000, Reward: -14.873689982200345, done: True\n",
      "state: [ 0.00679053 -0.00579312], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1304/2000, Reward: -15.300399717537436, done: True\n",
      "state: [ 0.00757549 -0.00550246], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1305/2000, Reward: -16.664412060998373, done: True\n",
      "state: [-0.00906319 -0.00031553], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1306/2000, Reward: -15.521401614485352, done: True\n",
      "state: [ 0.00523689 -0.00595919], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1307/2000, Reward: -16.302360003163873, done: True\n",
      "state: [ 0.00164334 -0.00429269], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1308/2000, Reward: -16.064339279454984, done: True\n",
      "state: [ 0.0017885  -0.00314073], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1309/2000, Reward: -15.671674284277728, done: True\n",
      "state: [ 0.0022589  -0.00164325], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1310/2000, Reward: -16.732195031389896, done: True\n",
      "state: [ 0.0024624  -0.00562583], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1311/2000, Reward: -15.75783060545631, done: True\n",
      "state: [ 0.00139936 -0.00520714], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1312/2000, Reward: -16.61919150131201, done: True\n",
      "state: [-0.00554356 -0.00616473], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1313/2000, Reward: -14.99033195620023, done: True\n",
      "state: [ 0.00620023 -0.00577329], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1314/2000, Reward: -14.773919002661817, done: True\n",
      "state: [ 0.00428443 -0.00513159], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1315/2000, Reward: -17.191891833004064, done: True\n",
      "state: [ 0.00218376 -0.0018317 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1316/2000, Reward: -15.674684973980986, done: True\n",
      "state: [ 0.00377582 -0.00385527], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1317/2000, Reward: -15.860053283171093, done: True\n",
      "state: [ 0.00134332 -0.00400338], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1318/2000, Reward: -13.78165028236989, done: True\n",
      "state: [ 0.004745   -0.00477145], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1319/2000, Reward: -17.60710065289336, done: True\n",
      "state: [ 0.0040212  -0.00292857], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1320/2000, Reward: -15.417077588731454, done: True\n",
      "state: [ 0.00590037 -0.00480296], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1321/2000, Reward: -14.764645494012841, done: True\n",
      "state: [ 0.00864013 -0.00558591], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1322/2000, Reward: -16.108004462999574, done: True\n",
      "state: [ 0.00400487 -0.00642392], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1323/2000, Reward: -14.984548989438466, done: True\n",
      "state: [ 0.00656181 -0.00478148], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1324/2000, Reward: -16.736442229394378, done: True\n",
      "state: [ 0.001366   -0.00352196], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1325/2000, Reward: -15.636093249987368, done: True\n",
      "state: [ 0.00112887 -0.00494543], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1326/2000, Reward: -14.217192972440145, done: True\n",
      "state: [ 0.00627581 -0.00250121], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1327/2000, Reward: -15.74476793311646, done: True\n",
      "state: [ 0.00455069 -0.00593168], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1328/2000, Reward: -15.54031818608907, done: True\n",
      "state: [ 0.00599572 -0.00734912], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1329/2000, Reward: -14.746571447642955, done: True\n",
      "state: [-0.00968004 -0.00165609], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1330/2000, Reward: -16.941020591793347, done: True\n",
      "state: [-0.00383047 -0.0017937 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1331/2000, Reward: -16.62018629036545, done: True\n",
      "state: [ 6.52737452e-03 -9.06427909e-05], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1332/2000, Reward: -13.995835111265903, done: True\n",
      "state: [-0.00854331 -0.00577843], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1333/2000, Reward: -14.78600826123793, done: True\n",
      "state: [ 0.00124765 -0.00433986], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1334/2000, Reward: -18.86703331526287, done: True\n",
      "state: [-0.00342707 -0.00075865], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1335/2000, Reward: -16.95247217173794, done: True\n",
      "state: [ 0.00314596 -0.00038516], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1336/2000, Reward: -18.068525628315708, done: True\n",
      "state: [ 0.00823417 -0.00415721], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1337/2000, Reward: -15.842022967701467, done: True\n",
      "state: [0.00558166 0.00043861], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1338/2000, Reward: -15.42049563723213, done: True\n",
      "state: [ 0.00272413 -0.00400277], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1339/2000, Reward: -16.305831341449455, done: True\n",
      "state: [ 0.00123344 -0.00528405], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1340/2000, Reward: -16.828920413335034, done: True\n",
      "state: [ 0.00845526 -0.00554437], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1341/2000, Reward: -15.201319917931922, done: True\n",
      "state: [-0.00831371 -0.00024158], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1342/2000, Reward: -16.06142601522507, done: True\n",
      "state: [-0.0072779  -0.00168442], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1343/2000, Reward: -14.87068899447047, done: True\n",
      "state: [ 0.0071451 -0.0053204], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1344/2000, Reward: -16.547904598044582, done: True\n",
      "state: [-0.0015995   0.00247379], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1345/2000, Reward: -15.525684670498118, done: True\n",
      "state: [ 0.00171382 -0.00389195], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1346/2000, Reward: -15.533101114975562, done: True\n",
      "state: [ 0.005238   -0.00654586], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1347/2000, Reward: -17.208875185625875, done: True\n",
      "state: [-0.00183798 -0.00204501], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1348/2000, Reward: -16.529822527403915, done: True\n",
      "state: [ 0.00703353 -0.00439618], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1349/2000, Reward: -16.72542781482809, done: True\n",
      "state: [ 0.005531  -0.0068686], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1350/2000, Reward: -14.408188323167936, done: True\n",
      "state: [ 0.00511063 -0.00299125], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 1351/2000, Reward: -16.182633482500552, done: True\n",
      "state: [ 0.00469978 -0.0071578 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1352/2000, Reward: -15.846876052400356, done: True\n",
      "state: [ 0.00811098 -0.00885616], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1353/2000, Reward: -16.8311709361992, done: True\n",
      "state: [ 0.00113099 -0.00485425], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1354/2000, Reward: -15.526736142140036, done: True\n",
      "state: [ 0.00939128 -0.00529733], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1355/2000, Reward: -15.430289216369, done: True\n",
      "state: [ 0.00172494 -0.00539845], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1356/2000, Reward: -17.40842126492144, done: True\n",
      "state: [ 0.00477633 -0.0049279 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1357/2000, Reward: -14.437005817049197, done: True\n",
      "state: [ 0.00709384 -0.00602144], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1358/2000, Reward: -16.602036649631334, done: True\n",
      "state: [ 0.00214967 -0.00449645], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1359/2000, Reward: -15.66895038211749, done: True\n",
      "state: [-0.00925295  0.00297077], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1360/2000, Reward: -16.398172948999356, done: True\n",
      "state: [ 0.00118531 -0.00450311], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1361/2000, Reward: -15.222756930867758, done: True\n",
      "state: [ 0.00191899 -0.00450715], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1362/2000, Reward: -15.08516359171705, done: True\n",
      "state: [ 0.00200403 -0.0055699 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1363/2000, Reward: -14.122931400427943, done: True\n",
      "state: [ 0.00613613 -0.00749184], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1364/2000, Reward: -16.649722419560977, done: True\n",
      "state: [ 0.00501343 -0.00659712], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1365/2000, Reward: -14.755809662675599, done: True\n",
      "state: [ 0.00871992 -0.00638142], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1366/2000, Reward: -14.539204870430934, done: True\n",
      "state: [ 0.00636584 -0.00678101], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1367/2000, Reward: -15.135718613955305, done: True\n",
      "state: [ 0.00162033 -0.00332963], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1368/2000, Reward: -17.382688115432728, done: True\n",
      "state: [ 0.00403206 -0.00802034], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1369/2000, Reward: -15.632890654396991, done: True\n",
      "state: [ 0.00961527 -0.00681261], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1370/2000, Reward: -15.944751295353026, done: True\n",
      "state: [ 0.00127188 -0.00569789], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1371/2000, Reward: -13.573546904404019, done: True\n",
      "state: [ 0.0071492  -0.00681573], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1372/2000, Reward: -17.170885952571858, done: True\n",
      "state: [ 0.00380763 -0.00480977], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1373/2000, Reward: -16.383244271448486, done: True\n",
      "state: [ 0.00615856 -0.00511711], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1374/2000, Reward: -15.437257083443622, done: True\n",
      "state: [ 0.0030138  -0.00243571], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1375/2000, Reward: -16.096822775660343, done: True\n",
      "state: [ 0.00113572 -0.0037196 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1376/2000, Reward: -15.766339217778528, done: True\n",
      "state: [ 0.00545964 -0.00532251], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1377/2000, Reward: -17.044010168195207, done: True\n",
      "state: [ 0.00225841 -0.00552741], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1378/2000, Reward: -15.198704476650548, done: True\n",
      "state: [ 0.00481042 -0.00414152], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1379/2000, Reward: -16.10315092871833, done: True\n",
      "state: [ 0.00121759 -0.00454608], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1380/2000, Reward: -15.390679018654772, done: True\n",
      "state: [ 0.00808891 -0.00588877], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1381/2000, Reward: -18.39178173929907, done: True\n",
      "state: [ 0.00612586 -0.00657064], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1382/2000, Reward: -15.778960953202791, done: True\n",
      "state: [ 0.00397846 -0.00508585], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1383/2000, Reward: -15.604782708393904, done: True\n",
      "state: [ 0.00713757 -0.00816674], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1384/2000, Reward: -16.155908499321463, done: True\n",
      "state: [ 0.00954411 -0.00888647], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1385/2000, Reward: -16.38474241993444, done: True\n",
      "state: [ 0.00514208 -0.00597465], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1386/2000, Reward: -16.19985451598132, done: True\n",
      "state: [ 0.00114784 -0.00706484], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1387/2000, Reward: -16.942407526063704, done: True\n",
      "state: [ 0.00578023 -0.00666465], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1388/2000, Reward: -15.607066312718606, done: True\n",
      "state: [ 0.00130277 -0.00624138], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1389/2000, Reward: -16.049240279787384, done: True\n",
      "state: [ 0.002076   -0.00438893], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1390/2000, Reward: -15.191022700844835, done: True\n",
      "state: [ 0.00939405 -0.00594241], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1391/2000, Reward: -18.85127514949019, done: True\n",
      "state: [ 0.00120458 -0.00255713], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1392/2000, Reward: -14.426335556641767, done: True\n",
      "state: [ 0.00432419 -0.00430377], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1393/2000, Reward: -16.482946020321712, done: True\n",
      "state: [ 0.00225259 -0.00466234], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1394/2000, Reward: -21.833653804952267, done: True\n",
      "state: [-0.00752751  0.00179069], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1395/2000, Reward: -14.670895026002277, done: True\n",
      "state: [ 0.0049348  -0.00458224], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1396/2000, Reward: -15.303600103498606, done: True\n",
      "state: [ 0.00671639 -0.00453864], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1397/2000, Reward: -15.172559875844456, done: True\n",
      "state: [ 0.00863306 -0.00301238], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1398/2000, Reward: -18.710612058106367, done: True\n",
      "state: [ 0.00562765 -0.00331051], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1399/2000, Reward: -15.935375143871704, done: True\n",
      "state: [ 0.00644075 -0.00649678], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1400/2000, Reward: -14.869068407196169, done: True\n",
      "state: [ 0.00939541 -0.00799794], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1401/2000, Reward: -14.84961567541071, done: True\n",
      "state: [ 0.00586369 -0.00532017], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1402/2000, Reward: -15.973506016668708, done: True\n",
      "state: [ 0.0011906  -0.00576984], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1403/2000, Reward: -15.413316294367869, done: True\n",
      "state: [ 0.00450718 -0.00448243], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1404/2000, Reward: -16.576416509477674, done: True\n",
      "state: [ 0.00422927 -0.00514523], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1405/2000, Reward: -15.10181831664795, done: True\n",
      "state: [ 0.00137449 -0.00528008], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1406/2000, Reward: -15.522345865239409, done: True\n",
      "state: [ 0.00626923 -0.00469617], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1407/2000, Reward: -14.678744172554683, done: True\n",
      "state: [ 0.00418697 -0.00511621], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1408/2000, Reward: -17.945487903266997, done: True\n",
      "state: [ 0.00214503 -0.00363311], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1409/2000, Reward: -14.688602135051434, done: True\n",
      "state: [ 0.00249235 -0.00107984], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1410/2000, Reward: -16.537064196935138, done: True\n",
      "state: [ 0.00135777 -0.00578294], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1411/2000, Reward: -16.926227380566992, done: True\n",
      "state: [ 0.00801746 -0.00376395], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1412/2000, Reward: -14.423352722172192, done: True\n",
      "state: [ 0.00336965 -0.00449479], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1413/2000, Reward: -15.595090441944661, done: True\n",
      "state: [ 0.00112735 -0.004557  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1414/2000, Reward: -15.82423393017838, done: True\n",
      "state: [ 0.0055155  -0.00595388], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1415/2000, Reward: -15.9733037344169, done: True\n",
      "state: [ 0.00744204 -0.00715621], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1416/2000, Reward: -15.492228109572158, done: True\n",
      "state: [ 0.00490608 -0.00241094], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1417/2000, Reward: -16.431264143440362, done: True\n",
      "state: [ 0.00123823 -0.0048867 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1418/2000, Reward: -16.755314958382968, done: True\n",
      "state: [ 0.00120029 -0.00194022], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1419/2000, Reward: -16.487205644265778, done: True\n",
      "state: [ 0.0087264  -0.00788607], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1420/2000, Reward: -17.49787364711309, done: True\n",
      "state: [ 0.00229973 -0.00539318], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1421/2000, Reward: -14.542420698572688, done: True\n",
      "state: [ 0.00767604 -0.00690615], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1422/2000, Reward: -17.503865898793027, done: True\n",
      "state: [ 0.00135168 -0.00486786], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1423/2000, Reward: -16.732775764318095, done: True\n",
      "state: [ 0.00126803 -0.0016529 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1424/2000, Reward: -15.279913598579773, done: True\n",
      "state: [ 0.00561665 -0.00863012], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1425/2000, Reward: -14.773244929976162, done: True\n",
      "state: [ 0.00428317 -0.00695761], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1426/2000, Reward: -16.262030948935013, done: True\n",
      "state: [ 0.00494614 -0.00523772], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1427/2000, Reward: -18.160927834018768, done: True\n",
      "state: [-0.00779309  0.00287174], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1428/2000, Reward: -15.091303690852053, done: True\n",
      "state: [ 0.00726195 -0.00694118], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1429/2000, Reward: -17.42377931080269, done: True\n",
      "state: [-0.00114747  0.00034492], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1430/2000, Reward: -17.263213149891403, done: True\n",
      "state: [ 0.00906033 -0.00834725], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1431/2000, Reward: -18.610374510298147, done: True\n",
      "state: [-0.0013564   0.00295906], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1432/2000, Reward: -16.5920690384975, done: True\n",
      "state: [ 0.00952282 -0.0069875 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1433/2000, Reward: -17.035268138102737, done: True\n",
      "state: [ 0.00780469 -0.0077313 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1434/2000, Reward: -17.271345813365464, done: True\n",
      "state: [ 0.00248217 -0.0015729 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1435/2000, Reward: -14.53916796892086, done: True\n",
      "state: [ 0.00135581 -0.00386819], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1436/2000, Reward: -15.809453579482554, done: True\n",
      "state: [ 0.00783172 -0.00452517], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1437/2000, Reward: -16.341497408412053, done: True\n",
      "state: [ 0.00464485 -0.00790628], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1438/2000, Reward: -16.635496645987015, done: True\n",
      "state: [ 0.00584665 -0.00736473], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1439/2000, Reward: -16.581142237676776, done: True\n",
      "state: [ 0.00383857 -0.00388145], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1440/2000, Reward: -15.071570495418793, done: True\n",
      "state: [ 0.00122664 -0.00825741], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1441/2000, Reward: -15.947296668114783, done: True\n",
      "state: [ 0.00777851 -0.00702563], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1442/2000, Reward: -15.599420662887745, done: True\n",
      "state: [ 0.00398293 -0.00822223], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1443/2000, Reward: -15.30004956609908, done: True\n",
      "state: [-0.00782557 -0.00420256], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1444/2000, Reward: -15.262745565703904, done: True\n",
      "state: [ 0.00424156 -0.00410569], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1445/2000, Reward: -14.436748880904869, done: True\n",
      "state: [ 0.00938718 -0.00622529], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1446/2000, Reward: -17.52000705331051, done: True\n",
      "state: [ 0.00816819 -0.00653457], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1447/2000, Reward: -14.768877400862674, done: True\n",
      "state: [ 0.00125923 -0.00500675], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1448/2000, Reward: -16.593311760896498, done: True\n",
      "state: [-0.00725733 -0.00255554], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1449/2000, Reward: -17.71795148392306, done: True\n",
      "state: [ 0.00894477 -0.00706545], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1450/2000, Reward: -16.16192910651567, done: True\n",
      "state: [ 0.000692  -0.0090273], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1451/2000, Reward: -16.81169558184588, done: True\n",
      "state: [ 0.00735903 -0.00753587], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1452/2000, Reward: -14.875206896618169, done: True\n",
      "state: [ 0.0029121  -0.00484413], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1453/2000, Reward: -16.269206457509185, done: True\n",
      "state: [ 0.00858204 -0.00536304], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1454/2000, Reward: -17.276376365018443, done: True\n",
      "state: [ 0.00535569 -0.00731415], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1455/2000, Reward: -17.591080793210345, done: True\n",
      "state: [ 0.00135498 -0.00546904], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1456/2000, Reward: -18.056392401368228, done: True\n",
      "state: [ 0.00116394 -0.00412429], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1457/2000, Reward: -17.032335380358084, done: True\n",
      "state: [-0.00166343 -0.00911302], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1458/2000, Reward: -16.180411330517455, done: True\n",
      "state: [ 0.00434166 -0.00694646], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1459/2000, Reward: -14.230143728670125, done: True\n",
      "state: [ 0.00555429 -0.0092643 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1460/2000, Reward: -15.311792863152405, done: True\n",
      "state: [ 0.00191631 -0.00550502], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1461/2000, Reward: -16.160302015392496, done: True\n",
      "state: [ 0.00205836 -0.00539763], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1462/2000, Reward: -18.13924018302929, done: True\n",
      "state: [ 0.00288561 -0.00557861], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1463/2000, Reward: -17.26894861517359, done: True\n",
      "state: [ 0.00867768 -0.0053757 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1464/2000, Reward: -14.994622103619857, done: True\n",
      "state: [ 0.00791623 -0.00221243], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1465/2000, Reward: -17.02385380126287, done: True\n",
      "state: [ 0.0085596  -0.00648276], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1466/2000, Reward: -15.956253555098767, done: True\n",
      "state: [ 0.00429563 -0.00460178], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1467/2000, Reward: -14.887227599405149, done: True\n",
      "state: [ 0.00573946 -0.00414066], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1468/2000, Reward: -15.960272455959043, done: True\n",
      "state: [ 0.00122372 -0.00408986], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1469/2000, Reward: -17.07188776762505, done: True\n",
      "state: [ 0.00703999 -0.00705458], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1470/2000, Reward: -15.922292069209009, done: True\n",
      "state: [-0.00806886  0.00239986], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1471/2000, Reward: -15.3042009052127, done: True\n",
      "state: [ 0.00834875 -0.00817372], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1472/2000, Reward: -17.8099646641775, done: True\n",
      "state: [ 0.00375547 -0.00331262], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1473/2000, Reward: -15.289762844286921, done: True\n",
      "state: [ 0.00900063 -0.00578593], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1474/2000, Reward: -15.605215813855581, done: True\n",
      "state: [ 0.00639765 -0.00631032], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1475/2000, Reward: -14.757007988294287, done: True\n",
      "state: [ 0.00338837 -0.00487029], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1476/2000, Reward: -16.13814931378392, done: True\n",
      "state: [ 0.00942909 -0.00386294], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1477/2000, Reward: -17.098097805011484, done: True\n",
      "state: [ 0.00263924 -0.00410052], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1478/2000, Reward: -16.2014091672538, done: True\n",
      "state: [ 0.0044286  -0.00052282], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1479/2000, Reward: -18.699270614947256, done: True\n",
      "state: [ 0.00924825 -0.00817285], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1480/2000, Reward: -15.012790587369018, done: True\n",
      "state: [ 0.00922578 -0.00902689], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1481/2000, Reward: -15.627553574500455, done: True\n",
      "state: [ 0.0072966  -0.00846312], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1482/2000, Reward: -15.73268816008526, done: True\n",
      "state: [ 0.00669864 -0.00713547], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1483/2000, Reward: -14.641845298365528, done: True\n",
      "state: [ 0.0067515  -0.00778898], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1484/2000, Reward: -14.738761511521332, done: True\n",
      "state: [ 0.00945307 -0.0087712 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1485/2000, Reward: -14.990415774396286, done: True\n",
      "state: [ 0.00968145 -0.00895118], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1486/2000, Reward: -14.205402190018777, done: True\n",
      "state: [ 0.00739202 -0.00618567], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1487/2000, Reward: -14.788038102653918, done: True\n",
      "state: [ 0.00440514 -0.00563925], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1488/2000, Reward: -15.672405211483747, done: True\n",
      "state: [-0.00212405 -0.0008249 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1489/2000, Reward: -14.639166281943686, done: True\n",
      "state: [ 0.00527176 -0.00728821], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1490/2000, Reward: -14.314004537848414, done: True\n",
      "state: [ 0.00670686 -0.00600955], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1491/2000, Reward: -14.554543451593752, done: True\n",
      "state: [ 0.00129556 -0.00674493], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1492/2000, Reward: -15.855709770919661, done: True\n",
      "state: [ 0.00140366 -0.00714495], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1493/2000, Reward: -13.802299465090083, done: True\n",
      "state: [ 0.0069205  -0.00452018], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1494/2000, Reward: -13.923376005238085, done: True\n",
      "state: [ 0.00763328 -0.00857943], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1495/2000, Reward: -15.222125759649217, done: True\n",
      "state: [ 0.009279   -0.00714548], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1496/2000, Reward: -14.890023002075203, done: True\n",
      "state: [ 0.00820383 -0.00807535], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1497/2000, Reward: -15.342383674559194, done: True\n",
      "state: [ 0.00133726 -0.00775994], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1498/2000, Reward: -15.82050754821326, done: True\n",
      "state: [ 0.00318118 -0.00625497], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1499/2000, Reward: -16.31684286786859, done: True\n",
      "state: [ 0.00251493 -0.00402069], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1500/2000, Reward: -16.070290112080816, done: True\n",
      "state: [ 0.00728004 -0.00693412], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1501/2000, Reward: -14.427088248233126, done: True\n",
      "state: [ 0.00755489 -0.00758758], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1502/2000, Reward: -17.328470142373938, done: True\n",
      "state: [ 0.00121931 -0.0023777 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1503/2000, Reward: -17.09550497917071, done: True\n",
      "state: [ 0.00497423 -0.00479757], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1504/2000, Reward: -16.491498527784554, done: True\n",
      "state: [ 0.00452588 -0.00609662], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1505/2000, Reward: -15.213057646418436, done: True\n",
      "state: [ 0.00113285 -0.00446506], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1506/2000, Reward: -15.858160263150758, done: True\n",
      "state: [ 0.00176756 -0.00608123], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1507/2000, Reward: -16.449438828299566, done: True\n",
      "state: [ 0.00175492 -0.00347512], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1508/2000, Reward: -15.36587874470246, done: True\n",
      "state: [ 0.00237934 -0.00305075], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1509/2000, Reward: -15.53697437087606, done: True\n",
      "state: [ 0.00129731 -0.00376782], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1510/2000, Reward: -15.49680013690846, done: True\n",
      "state: [ 0.00122722 -0.00557497], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1511/2000, Reward: -16.310953768445568, done: True\n",
      "state: [ 0.00856604 -0.00110548], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1512/2000, Reward: -15.223433710969934, done: True\n",
      "state: [ 0.00192227 -0.00519223], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1513/2000, Reward: -14.77998646601461, done: True\n",
      "state: [ 0.00464494 -0.00290952], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1514/2000, Reward: -16.814384831288223, done: True\n",
      "state: [ 0.00829739 -0.00796496], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1515/2000, Reward: -15.144755605269753, done: True\n",
      "state: [ 0.00167763 -0.00422502], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1516/2000, Reward: -14.226235622260177, done: True\n",
      "state: [ 0.00853672 -0.0085109 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1517/2000, Reward: -15.58156453979689, done: True\n",
      "state: [ 0.00440525 -0.00556638], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1518/2000, Reward: -16.913996258814144, done: True\n",
      "state: [ 0.00573783 -0.00645914], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1519/2000, Reward: -16.35115110723491, done: True\n",
      "state: [ 0.00235528 -0.00355126], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1520/2000, Reward: -16.600688347408525, done: True\n",
      "state: [ 0.00824296 -0.00579365], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1521/2000, Reward: -15.745078942866964, done: True\n",
      "state: [ 0.00932592 -0.00847137], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1522/2000, Reward: -14.784256593725614, done: True\n",
      "state: [ 0.00755535 -0.00768913], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1523/2000, Reward: -14.6979556945566, done: True\n",
      "state: [ 0.00125328 -0.00581574], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1524/2000, Reward: -15.657273893517567, done: True\n",
      "state: [ 0.00135649 -0.0058282 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1525/2000, Reward: -14.459594589928713, done: True\n",
      "state: [ 0.00495913 -0.00713363], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1526/2000, Reward: -14.837612451209452, done: True\n",
      "state: [ 0.00873551 -0.00711288], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1527/2000, Reward: -15.979972687156408, done: True\n",
      "state: [ 0.00755453 -0.00780695], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1528/2000, Reward: -15.5614947376383, done: True\n",
      "state: [ 0.00118346 -0.0067486 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1529/2000, Reward: -16.320205464905005, done: True\n",
      "state: [ 0.00662261 -0.00622603], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1530/2000, Reward: -15.539947098473522, done: True\n",
      "state: [ 0.00556542 -0.00568067], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1531/2000, Reward: -15.252296173482646, done: True\n",
      "state: [ 0.00673633 -0.00534037], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1532/2000, Reward: -14.438026731992899, done: True\n",
      "state: [ 0.00873198 -0.00841789], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1533/2000, Reward: -15.329519016391739, done: True\n",
      "state: [ 0.0091621  -0.00515515], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1534/2000, Reward: -16.95021711315481, done: True\n",
      "state: [ 0.00231227 -0.00514154], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1535/2000, Reward: -14.565689010287945, done: True\n",
      "state: [ 0.00115025 -0.00695203], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1536/2000, Reward: -16.078154503717343, done: True\n",
      "state: [ 0.00571185 -0.00667683], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1537/2000, Reward: -13.893878037051554, done: True\n",
      "state: [ 0.00939697 -0.00725297], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1538/2000, Reward: -15.044980585837283, done: True\n",
      "state: [ 0.00621818 -0.00624281], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1539/2000, Reward: -15.230113889978728, done: True\n",
      "state: [ 0.00899292 -0.00697037], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1540/2000, Reward: -13.81113499133021, done: True\n",
      "state: [ 0.00696922 -0.00640497], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1541/2000, Reward: -15.42055587139607, done: True\n",
      "state: [ 0.00865471 -0.00816416], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 1542/2000, Reward: -15.138461498385865, done: True\n",
      "state: [ 0.00343251 -0.00568458], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1543/2000, Reward: -14.567547905207343, done: True\n",
      "state: [ 0.00689922 -0.00753962], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1544/2000, Reward: -16.780358506811798, done: True\n",
      "state: [ 0.00548506 -0.00550549], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1545/2000, Reward: -15.975617180732987, done: True\n",
      "state: [ 0.0058808  -0.00562972], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1546/2000, Reward: -14.917218404845551, done: True\n",
      "state: [ 0.00131506 -0.00320682], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1547/2000, Reward: -14.90485032876889, done: True\n",
      "state: [ 0.00528139 -0.00340052], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1548/2000, Reward: -15.76862193095835, done: True\n",
      "state: [ 0.00489113 -0.00589602], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1549/2000, Reward: -13.792392181369541, done: True\n",
      "state: [ 0.00884299 -0.00691692], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1550/2000, Reward: -15.135177625563836, done: True\n",
      "state: [ 0.00140047 -0.00648122], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1551/2000, Reward: -15.126380862767954, done: True\n",
      "state: [ 0.00410722 -0.00576318], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1552/2000, Reward: -13.927432948992092, done: True\n",
      "state: [ 0.0011886  -0.00711044], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1553/2000, Reward: -15.779527248119157, done: True\n",
      "state: [ 0.00549167 -0.00455624], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1554/2000, Reward: -17.649388393213883, done: True\n",
      "state: [ 0.00495191 -0.00382869], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1555/2000, Reward: -16.447824135055864, done: True\n",
      "state: [ 0.00318069 -0.00449193], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1556/2000, Reward: -14.769036108547596, done: True\n",
      "state: [ 0.00139042 -0.00730227], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1557/2000, Reward: -16.47163291554832, done: True\n",
      "state: [ 0.00741709 -0.00667238], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1558/2000, Reward: -15.923202002842283, done: True\n",
      "state: [ 0.00174255 -0.00362222], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1559/2000, Reward: -14.580936172490762, done: True\n",
      "state: [ 0.00918912 -0.00548234], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1560/2000, Reward: -15.931458260174402, done: True\n",
      "state: [ 0.0011523  -0.00316459], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1561/2000, Reward: -14.111595742772833, done: True\n",
      "state: [ 0.00131652 -0.00502864], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1562/2000, Reward: -15.34375031327929, done: True\n",
      "state: [ 0.00810211 -0.00729842], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1563/2000, Reward: -13.798447857085263, done: True\n",
      "state: [ 0.00742159 -0.0061723 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1564/2000, Reward: -15.528834252379808, done: True\n",
      "state: [ 0.00555272 -0.00598904], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1565/2000, Reward: -15.02728892927009, done: True\n",
      "state: [ 0.00883053 -0.0068277 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1566/2000, Reward: -14.351469076510579, done: True\n",
      "state: [ 0.00800104 -0.00602995], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1567/2000, Reward: -14.022325549799303, done: True\n",
      "state: [ 0.00133597 -0.00666625], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1568/2000, Reward: -15.820398540234251, done: True\n",
      "state: [ 0.00117548 -0.00341995], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1569/2000, Reward: -15.105994151745112, done: True\n",
      "state: [ 0.00928658 -0.00277988], action: [0.33333333333333326, 0.0167]\n",
      "Episode: 1570/2000, Reward: -14.797166819441323, done: True\n",
      "state: [ 0.00681486 -0.00228794], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1571/2000, Reward: -16.85233989464733, done: True\n",
      "state: [ 0.00940453 -0.00703587], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1572/2000, Reward: -15.015740539480083, done: True\n",
      "state: [ 0.00255354 -0.00510556], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1573/2000, Reward: -14.360647463932322, done: True\n",
      "state: [ 0.00369331 -0.00525279], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1574/2000, Reward: -15.534868240012328, done: True\n",
      "state: [ 0.00684633 -0.00237248], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1575/2000, Reward: -14.546704030166529, done: True\n",
      "state: [ 0.00958213 -0.00723408], action: [0.33333333333333326, -0.005566666666666666]\n",
      "Episode: 1576/2000, Reward: -14.995042195431845, done: True\n",
      "state: [ 0.00120454 -0.00804967], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1577/2000, Reward: -14.44864258975639, done: True\n",
      "state: [ 0.00123394 -0.00614745], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1578/2000, Reward: -14.79027275146565, done: True\n",
      "state: [ 0.00379661 -0.00620667], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1579/2000, Reward: -13.697143082811396, done: True\n",
      "state: [ 0.00928233 -0.00481031], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1580/2000, Reward: -15.918811394964994, done: True\n",
      "state: [ 0.00924011 -0.00650116], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1581/2000, Reward: -15.02649922481549, done: True\n",
      "state: [ 0.00246807 -0.00356671], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1582/2000, Reward: -16.008751686826628, done: True\n",
      "state: [ 0.00731255 -0.00764669], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1583/2000, Reward: -15.344862076091644, done: True\n",
      "state: [ 0.00134425 -0.00281018], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1584/2000, Reward: -14.224966737121534, done: True\n",
      "state: [ 0.00911191 -0.00768233], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1585/2000, Reward: -17.326413360519744, done: True\n",
      "state: [ 0.00171286 -0.00109931], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1586/2000, Reward: -17.360305888715203, done: True\n",
      "state: [ 0.00414079 -0.0013377 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1587/2000, Reward: -15.900221239313591, done: True\n",
      "state: [-0.00740542 -0.00116104], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1588/2000, Reward: -15.557040249028166, done: True\n",
      "state: [ 0.00457499 -0.00358074], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1589/2000, Reward: -16.459252678473664, done: True\n",
      "state: [ 0.00207649 -0.00386597], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1590/2000, Reward: -16.134303026267684, done: True\n",
      "state: [0.00217578 0.00072972], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1591/2000, Reward: -15.899854850402004, done: True\n",
      "state: [ 0.00859513 -0.002927  ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1592/2000, Reward: -14.255853302215701, done: True\n",
      "state: [ 0.00723191 -0.00696929], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1593/2000, Reward: -14.671986739282154, done: True\n",
      "state: [ 0.00564598 -0.00538096], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1594/2000, Reward: -15.564769922874142, done: True\n",
      "state: [ 0.00674533 -0.00516884], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1595/2000, Reward: -14.783707083537236, done: True\n",
      "state: [ 0.00735256 -0.00510167], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1596/2000, Reward: -13.902578859071436, done: True\n",
      "state: [ 0.00780552 -0.00649325], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1597/2000, Reward: -15.689278101291409, done: True\n",
      "state: [ 0.00390281 -0.00523438], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1598/2000, Reward: -16.226518791348575, done: True\n",
      "state: [ 0.00132981 -0.00182757], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1599/2000, Reward: -14.79653919151515, done: True\n",
      "state: [ 0.00651893 -0.0041228 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1600/2000, Reward: -17.215829258078116, done: True\n",
      "state: [-0.00829216 -0.00120933], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1601/2000, Reward: -16.453597698750777, done: True\n",
      "state: [ 0.00335418 -0.00321889], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1602/2000, Reward: -14.672207003829746, done: True\n",
      "state: [ 0.00380122 -0.0031246 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1603/2000, Reward: -17.982019146168252, done: True\n",
      "state: [ 0.00528714 -0.00110568], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1604/2000, Reward: -14.03062197166659, done: True\n",
      "state: [ 0.00769039 -0.00453559], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1605/2000, Reward: -14.578741953669494, done: True\n",
      "state: [ 0.00358446 -0.00486265], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1606/2000, Reward: -15.54906051951274, done: True\n",
      "state: [ 0.00858789 -0.0061685 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1607/2000, Reward: -15.569245622687413, done: True\n",
      "state: [ 0.00598056 -0.00699938], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1608/2000, Reward: -14.56521637379253, done: True\n",
      "state: [ 0.00905724 -0.00577396], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1609/2000, Reward: -15.671752503759857, done: True\n",
      "state: [ 0.00493784 -0.00584807], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1610/2000, Reward: -15.448310024669048, done: True\n",
      "state: [ 0.00433694 -0.00417431], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1611/2000, Reward: -15.459194052766604, done: True\n",
      "state: [ 0.00482038 -0.00205358], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1612/2000, Reward: -15.01228580018284, done: True\n",
      "state: [ 0.00324899 -0.00586528], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1613/2000, Reward: -14.576828490319635, done: True\n",
      "state: [ 0.00139004 -0.00599641], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1614/2000, Reward: -17.029224690186787, done: True\n",
      "state: [ 0.00477359 -0.00714427], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1615/2000, Reward: -15.321652965010005, done: True\n",
      "state: [ 0.0012355  -0.00540831], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1616/2000, Reward: -14.469956258926723, done: True\n",
      "state: [ 0.00832929 -0.00444378], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1617/2000, Reward: -15.652487482989827, done: True\n",
      "state: [ 0.00245582 -0.00361617], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1618/2000, Reward: -15.452701377958796, done: True\n",
      "state: [ 0.00122132 -0.00317219], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1619/2000, Reward: -14.570696800075428, done: True\n",
      "state: [ 0.00947098 -0.00584887], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1620/2000, Reward: -14.799143543321673, done: True\n",
      "state: [ 0.00596509 -0.00617703], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1621/2000, Reward: -14.89985250310722, done: True\n",
      "state: [ 0.00385919 -0.00559571], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1622/2000, Reward: -16.47758107637069, done: True\n",
      "state: [ 0.00113145 -0.00543892], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1623/2000, Reward: -14.546008161675674, done: True\n",
      "state: [ 0.00430083 -0.00125183], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1624/2000, Reward: -14.890308604457266, done: True\n",
      "state: [ 0.0061622 -0.0045241], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1625/2000, Reward: -15.35257340699974, done: True\n",
      "state: [ 0.00840543 -0.00289659], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1626/2000, Reward: -15.674751291642597, done: True\n",
      "state: [ 0.00482382 -0.00514872], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1627/2000, Reward: -15.786856702552283, done: True\n",
      "state: [ 0.00318756 -0.00289211], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1628/2000, Reward: -14.32195472954688, done: True\n",
      "state: [ 0.00705681 -0.00619519], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1629/2000, Reward: -16.36951356930863, done: True\n",
      "state: [ 0.00391826 -0.00466449], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1630/2000, Reward: -15.674322263407031, done: True\n",
      "state: [ 0.00401887 -0.0051933 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1631/2000, Reward: -14.345077772277062, done: True\n",
      "state: [ 0.00766533 -0.00511536], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1632/2000, Reward: -15.813510205160927, done: True\n",
      "state: [ 0.00193614 -0.00439046], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1633/2000, Reward: -14.25585725157034, done: True\n",
      "state: [ 0.0091281 -0.0064473], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1634/2000, Reward: -17.45793401398775, done: True\n",
      "state: [ 0.00315749 -0.00161864], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1635/2000, Reward: -16.327042433728973, done: True\n",
      "state: [ 0.00157561 -0.00434856], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1636/2000, Reward: -15.237707635586812, done: True\n",
      "state: [ 0.00641657 -0.00503501], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1637/2000, Reward: -16.334929435698367, done: True\n",
      "state: [ 0.00731503 -0.00510763], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1638/2000, Reward: -14.811521904396571, done: True\n",
      "state: [ 0.00235108 -0.00427117], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1639/2000, Reward: -14.556176513166488, done: True\n",
      "state: [ 0.00879273 -0.00642696], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1640/2000, Reward: -14.980128017365343, done: True\n",
      "state: [ 0.00121682 -0.00630712], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1641/2000, Reward: -16.245557772961337, done: True\n",
      "state: [ 0.00199091 -0.00478384], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1642/2000, Reward: -16.017799475022727, done: True\n",
      "state: [ 0.00115178 -0.00417788], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1643/2000, Reward: -14.921565214216466, done: True\n",
      "state: [ 0.00287932 -0.00083534], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1644/2000, Reward: -15.128471000725431, done: True\n",
      "state: [ 0.00195658 -0.00375538], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1645/2000, Reward: -14.683085663645544, done: True\n",
      "state: [ 0.00783311 -0.00671028], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1646/2000, Reward: -14.876944629453808, done: True\n",
      "state: [ 0.00654473 -0.00806809], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1647/2000, Reward: -17.970661495279902, done: True\n",
      "state: [ 0.00696026 -0.00696622], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1648/2000, Reward: -18.848667068129494, done: True\n",
      "state: [ 0.00336656 -0.00148989], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1649/2000, Reward: -17.561057460359514, done: True\n",
      "state: [0.00281793 0.00164326], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1650/2000, Reward: -15.986241516702453, done: True\n",
      "state: [ 0.00138986 -0.00546605], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1651/2000, Reward: -16.98723352894371, done: True\n",
      "state: [ 0.00392822 -0.00269474], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1652/2000, Reward: -15.446254189467478, done: True\n",
      "state: [ 0.00958263 -0.00729114], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1653/2000, Reward: -14.459304036295519, done: True\n",
      "state: [ 0.00859607 -0.00463454], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1654/2000, Reward: -16.11316463391971, done: True\n",
      "state: [ 0.00648412 -0.00348822], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1655/2000, Reward: -14.585221817362, done: True\n",
      "state: [ 0.00413857 -0.00544643], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1656/2000, Reward: -16.00568589502537, done: True\n",
      "state: [ 0.00308583 -0.00389389], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1657/2000, Reward: -15.106250192093086, done: True\n",
      "state: [ 0.00512902 -0.00609197], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1658/2000, Reward: -14.990413366957302, done: True\n",
      "state: [ 0.0042674  -0.00564446], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1659/2000, Reward: -15.235622546785889, done: True\n",
      "state: [ 0.00611472 -0.00571832], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1660/2000, Reward: -16.307593569857847, done: True\n",
      "state: [ 0.00992655 -0.00362849], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1661/2000, Reward: -16.33625026448433, done: True\n",
      "state: [-0.00908594 -0.00033536], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1662/2000, Reward: -17.459234984545247, done: True\n",
      "state: [ 0.00585253 -0.00400344], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1663/2000, Reward: -15.228123509753805, done: True\n",
      "state: [ 0.00309339 -0.00447206], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1664/2000, Reward: -15.74795338547064, done: True\n",
      "state: [ 0.0029944  -0.00407882], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1665/2000, Reward: -16.137320396541348, done: True\n",
      "state: [-0.00723511 -0.00112421], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1666/2000, Reward: -15.575912489154788, done: True\n",
      "state: [ 0.0011537 -0.0047491], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1667/2000, Reward: -18.212005497900805, done: True\n",
      "state: [ 0.00178117 -0.00612683], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1668/2000, Reward: -14.655670620583608, done: True\n",
      "state: [ 0.0056291  -0.00638971], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1669/2000, Reward: -15.07204368492708, done: True\n",
      "state: [ 0.00750997 -0.00666932], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1670/2000, Reward: -16.584138488359166, done: True\n",
      "state: [ 0.00118778 -0.00537538], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1671/2000, Reward: -16.680767788628458, done: True\n",
      "state: [ 0.00135517 -0.00412174], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1672/2000, Reward: -14.017975427189091, done: True\n",
      "state: [ 0.00823166 -0.00457115], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1673/2000, Reward: -16.19209793902219, done: True\n",
      "state: [ 0.00120685 -0.00511061], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1674/2000, Reward: -15.341023991722595, done: True\n",
      "state: [ 0.00351644 -0.00232816], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1675/2000, Reward: -16.669582763479383, done: True\n",
      "state: [ 0.00894666 -0.00462436], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1676/2000, Reward: -14.584557635421543, done: True\n",
      "state: [ 0.00779152 -0.00520857], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1677/2000, Reward: -15.592758368940574, done: True\n",
      "state: [ 0.00953566 -0.0048232 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1678/2000, Reward: -16.569007523208313, done: True\n",
      "state: [ 0.00261764 -0.00144638], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1679/2000, Reward: -14.124062392393334, done: True\n",
      "state: [ 0.00109999 -0.00902299], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1680/2000, Reward: -14.678925008462974, done: True\n",
      "state: [-0.00300247 -0.00925809], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1681/2000, Reward: -16.502764635310427, done: True\n",
      "state: [ 0.00139641 -0.00115957], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1682/2000, Reward: -15.42809624160869, done: True\n",
      "state: [ 0.00803885 -0.00589719], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1683/2000, Reward: -15.97239423026187, done: True\n",
      "state: [ 0.00370767 -0.00551905], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1684/2000, Reward: -14.254959440065075, done: True\n",
      "state: [ 0.00113686 -0.00792843], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1685/2000, Reward: -13.91647631490513, done: True\n",
      "state: [ 0.00450416 -0.00748511], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1686/2000, Reward: -14.79470693016442, done: True\n",
      "state: [ 0.00900663 -0.00494646], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1687/2000, Reward: -17.234978431159767, done: True\n",
      "state: [ 0.0014017  -0.00270037], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1688/2000, Reward: -14.36986115834377, done: True\n",
      "state: [ 0.00458904 -0.00606634], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1689/2000, Reward: -16.552411413233642, done: True\n",
      "state: [ 0.0019317  -0.00192895], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1690/2000, Reward: -14.701039568335897, done: True\n",
      "state: [ 0.0060035  -0.00233223], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1691/2000, Reward: -15.138424613355255, done: True\n",
      "state: [ 0.00212932 -0.00180221], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1692/2000, Reward: -14.563661928968903, done: True\n",
      "state: [ 0.00657372 -0.00500106], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1693/2000, Reward: -14.567478087146084, done: True\n",
      "state: [ 0.00381512 -0.00524831], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1694/2000, Reward: -15.59101374719953, done: True\n",
      "state: [ 0.00136556 -0.00356471], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1695/2000, Reward: -14.677745360186515, done: True\n",
      "state: [ 0.00115549 -0.00466559], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1696/2000, Reward: -15.45482334646349, done: True\n",
      "state: [ 0.00119527 -0.00185454], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1697/2000, Reward: -15.196422251829508, done: True\n",
      "state: [ 0.00646382 -0.00407445], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1698/2000, Reward: -14.025037826696776, done: True\n",
      "state: [ 0.00762482 -0.00538304], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1699/2000, Reward: -14.002728183133431, done: True\n",
      "state: [ 0.00645575 -0.00477384], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1700/2000, Reward: -14.916322478043753, done: True\n",
      "state: [ 0.00567192 -0.00096619], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1701/2000, Reward: -15.354383405973232, done: True\n",
      "state: [ 0.00235975 -0.00352676], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1702/2000, Reward: -16.668943478841296, done: True\n",
      "state: [ 0.00462349 -0.00745009], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1703/2000, Reward: -14.796332250626396, done: True\n",
      "state: [ 0.00213434 -0.0040892 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1704/2000, Reward: -14.125382327588177, done: True\n",
      "state: [ 0.00132249 -0.00343706], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1705/2000, Reward: -13.698262701015507, done: True\n",
      "state: [ 0.0058119  -0.00611228], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1706/2000, Reward: -14.890738225283247, done: True\n",
      "state: [ 0.0071254  -0.00459502], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1707/2000, Reward: -15.479125043274252, done: True\n",
      "state: [0.0012247  0.00057922], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1708/2000, Reward: -15.920447365432208, done: True\n",
      "state: [0.00227554 0.00073826], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1709/2000, Reward: -14.476517261106018, done: True\n",
      "state: [ 0.00923263 -0.00910558], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1710/2000, Reward: -15.573822152855003, done: True\n",
      "state: [ 0.00821831 -0.00509026], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1711/2000, Reward: -14.555922221895504, done: True\n",
      "state: [ 0.00742246 -0.00461206], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1712/2000, Reward: -15.221332971243642, done: True\n",
      "state: [ 0.00774885 -0.00500667], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1713/2000, Reward: -14.024243369986415, done: True\n",
      "state: [ 0.0094517  -0.00611848], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1714/2000, Reward: -14.346738987305514, done: True\n",
      "state: [ 0.00301156 -0.0041397 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1715/2000, Reward: -14.89463085872946, done: True\n",
      "state: [ 0.0085353  -0.00465826], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1716/2000, Reward: -16.670390308982327, done: True\n",
      "state: [0.00370644 0.00139486], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1717/2000, Reward: -15.436296844136601, done: True\n",
      "state: [ 0.00134824 -0.00318095], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1718/2000, Reward: -16.7849128528287, done: True\n",
      "state: [ 0.00122714 -0.00249338], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1719/2000, Reward: -14.346140603987084, done: True\n",
      "state: [ 0.00370611 -0.00570434], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1720/2000, Reward: -17.915433512349832, done: True\n",
      "state: [ 0.00116483 -0.00631137], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1721/2000, Reward: -14.446856898301908, done: True\n",
      "state: [ 0.00948013 -0.00406375], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1722/2000, Reward: -16.33203391493108, done: True\n",
      "state: [ 0.00157481 -0.0062571 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1723/2000, Reward: -17.418582306492034, done: True\n",
      "state: [ 0.00194121 -0.0027244 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1724/2000, Reward: -14.54586034884124, done: True\n",
      "state: [ 0.00585074 -0.00496775], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1725/2000, Reward: -14.026791819703698, done: True\n",
      "state: [ 0.00403446 -0.00792863], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1726/2000, Reward: -15.029014480034556, done: True\n",
      "state: [ 0.00681547 -0.00887982], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1727/2000, Reward: -15.556869545456433, done: True\n",
      "state: [ 0.002818   -0.00680248], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1728/2000, Reward: -14.01605005061956, done: True\n",
      "state: [ 0.00360334 -0.00525967], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1729/2000, Reward: -16.73850424437476, done: True\n",
      "state: [ 0.00124507 -0.00598734], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1730/2000, Reward: -14.467094336027046, done: True\n",
      "state: [ 0.00698645 -0.00734446], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1731/2000, Reward: -18.325992104637447, done: True\n",
      "state: [ 0.00124118 -0.00190956], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1732/2000, Reward: -14.807178924298311, done: True\n",
      "state: [ 0.00745571 -0.00678067], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1733/2000, Reward: -16.811812568273545, done: True\n",
      "state: [ 0.00370778 -0.00591614], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1734/2000, Reward: -14.349235111668994, done: True\n",
      "state: [ 0.00912969 -0.00612844], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1735/2000, Reward: -16.139801648555604, done: True\n",
      "state: [0.00334474 0.0007309 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1736/2000, Reward: -16.324641999012442, done: True\n",
      "state: [ 0.00227287 -0.00469119], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1737/2000, Reward: -13.702725556457466, done: True\n",
      "state: [ 0.009325   -0.00840949], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1738/2000, Reward: -18.202354478159705, done: True\n",
      "state: [ 0.00133703 -0.00401945], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1739/2000, Reward: -17.02648304184223, done: True\n",
      "state: [ 7.74274302e-03 -5.28634431e-06], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1740/2000, Reward: -16.148496232453482, done: True\n",
      "state: [ 0.00656602 -0.00362083], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1741/2000, Reward: -18.69598922244483, done: True\n",
      "state: [ 0.0018265  -0.00230563], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1742/2000, Reward: -16.33548137897456, done: True\n",
      "state: [ 0.00785822 -0.00739166], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1743/2000, Reward: -14.809569351397823, done: True\n",
      "state: [ 0.00922637 -0.00783739], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1744/2000, Reward: -15.694393343838442, done: True\n",
      "state: [-0.00068209 -0.00890579], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1745/2000, Reward: -13.697715303083056, done: True\n",
      "state: [ 0.00911327 -0.00853165], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1746/2000, Reward: -15.127678900692766, done: True\n",
      "state: [ 0.00139827 -0.00549869], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1747/2000, Reward: -14.020017476629228, done: True\n",
      "state: [ 0.00634181 -0.00930175], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1748/2000, Reward: -15.133850692679815, done: True\n",
      "state: [ 0.00940328 -0.00775231], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1749/2000, Reward: -16.9103304940928, done: True\n",
      "state: [ 0.00123495 -0.00256842], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1750/2000, Reward: -16.56572100665151, done: True\n",
      "state: [ 0.00951897 -0.00430775], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1751/2000, Reward: -16.547353337980947, done: True\n",
      "state: [ 0.00908    -0.00417648], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1752/2000, Reward: -17.10573020015915, done: True\n",
      "state: [ 0.00573821 -0.00541244], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1753/2000, Reward: -15.465916972169532, done: True\n",
      "state: [ 0.00642754 -0.00133895], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1754/2000, Reward: -15.569412466233212, done: True\n",
      "state: [ 0.0071094  -0.00256333], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1755/2000, Reward: -15.014893713537294, done: True\n",
      "state: [ 0.00078012 -0.00906129], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1756/2000, Reward: -15.354753356386963, done: True\n",
      "state: [ 0.00383461 -0.00130656], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1757/2000, Reward: -17.797204534764283, done: True\n",
      "state: [ 0.00177709 -0.0020878 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1758/2000, Reward: -16.247554942370538, done: True\n",
      "state: [-0.00029723 -0.00902519], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1759/2000, Reward: -15.694471315043131, done: True\n",
      "state: [ 0.00227481 -0.00464906], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1760/2000, Reward: -15.917810710646176, done: True\n",
      "state: [ 0.00412725 -0.00819378], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1761/2000, Reward: -15.015094725861857, done: True\n",
      "state: [ 0.00072043 -0.00888475], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1762/2000, Reward: -15.801280449178442, done: True\n",
      "state: [ 0.0013268 -0.0079521], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1763/2000, Reward: -15.370310912233457, done: True\n",
      "state: [ 0.00641267 -0.00625415], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1764/2000, Reward: -15.463189699054244, done: True\n",
      "state: [ 0.00122785 -0.00801612], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 1765/2000, Reward: -17.240685777384538, done: True\n",
      "state: [ 0.00131494 -0.0056566 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1766/2000, Reward: -15.57693771105497, done: True\n",
      "state: [ 0.00223161 -0.00941468], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1767/2000, Reward: -18.579252917543883, done: True\n",
      "state: [ 0.00834769 -0.00271345], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1768/2000, Reward: -16.770134651051798, done: True\n",
      "state: [ 0.00117664 -0.00473594], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1769/2000, Reward: -16.801471363546508, done: True\n",
      "state: [ 0.00123887 -0.00516471], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1770/2000, Reward: -16.360442217476585, done: True\n",
      "state: [ 0.00140042 -0.00589281], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1771/2000, Reward: -16.224959084668864, done: True\n",
      "state: [ 0.00914578 -0.00905564], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1772/2000, Reward: -17.79825850305288, done: True\n",
      "state: [ 0.00241097 -0.00543591], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1773/2000, Reward: -15.012870084046074, done: True\n",
      "state: [ 0.00549774 -0.00859146], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1774/2000, Reward: -16.579938093753245, done: True\n",
      "state: [ 0.00349791 -0.00446441], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1775/2000, Reward: -15.457217543143754, done: True\n",
      "state: [-0.0001898  -0.00896686], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1776/2000, Reward: -16.105035170593567, done: True\n",
      "state: [ 0.00368412 -0.00634459], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1777/2000, Reward: -16.23646196934601, done: True\n",
      "state: [ 0.00481089 -0.00623623], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1778/2000, Reward: -14.764004404385066, done: True\n",
      "state: [ 0.00866116 -0.00922981], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1779/2000, Reward: -17.110774316719294, done: True\n",
      "state: [0.00131768 0.00133936], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1780/2000, Reward: -17.565982881801652, done: True\n",
      "state: [ 0.00603574 -0.00438099], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1781/2000, Reward: -19.20252667674796, done: True\n",
      "state: [ 0.00549101 -0.00041984], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1782/2000, Reward: -17.682293681258923, done: True\n",
      "state: [ 0.0095764  -0.00161669], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1783/2000, Reward: -16.890603736178154, done: True\n",
      "state: [ 0.00132689 -0.00297966], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1784/2000, Reward: -16.898185802405397, done: True\n",
      "state: [ 0.00679832 -0.0054311 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1785/2000, Reward: -19.12345621719201, done: True\n",
      "state: [ 0.00189643 -0.00250991], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1786/2000, Reward: -18.90372755477202, done: True\n",
      "state: [0.0013448  0.00270945], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1787/2000, Reward: -15.76942584367506, done: True\n",
      "state: [ 0.00934945 -0.00851945], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1788/2000, Reward: -18.12584218277732, done: True\n",
      "state: [ 0.00339761 -0.00262677], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1789/2000, Reward: -16.458243864894122, done: True\n",
      "state: [ 0.00259787 -0.00526879], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1790/2000, Reward: -16.014746884325348, done: True\n",
      "state: [ 0.00133079 -0.00884178], action: [-0.33333333333333337, 0.005566666666666668]\n",
      "Episode: 1791/2000, Reward: -16.35348179843001, done: True\n",
      "state: [ 0.0068506  -0.00805788], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1792/2000, Reward: -16.232680752701107, done: True\n",
      "state: [ 0.0081631  -0.00587557], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1793/2000, Reward: -20.248420235443383, done: True\n",
      "state: [0.00121949 0.0010727 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1794/2000, Reward: -16.88065406072041, done: True\n",
      "state: [ 0.00783324 -0.00779575], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1795/2000, Reward: -19.244261101600188, done: True\n",
      "state: [ 0.00267856 -0.00079667], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1796/2000, Reward: -15.865603248791297, done: True\n",
      "state: [ 0.00764339 -0.00639021], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1797/2000, Reward: -17.461328717057462, done: True\n",
      "state: [ 7.70347201e-05 -8.73531400e-03], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 1798/2000, Reward: -19.671850858140324, done: True\n",
      "state: [ 0.00129177 -0.00099056], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1799/2000, Reward: -17.232459406703185, done: True\n",
      "state: [-0.00082926 -0.00923463], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 1800/2000, Reward: -14.684875825036267, done: True\n",
      "state: [ 0.00329494 -0.00964674], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1801/2000, Reward: -16.86914529489672, done: True\n",
      "state: [ 0.00701488 -0.00717556], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1802/2000, Reward: -17.56090950606659, done: True\n",
      "state: [ 0.00084587 -0.00983937], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1803/2000, Reward: -16.466997948002792, done: True\n",
      "state: [ 0.00138718 -0.00885498], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1804/2000, Reward: -19.233670175453195, done: True\n",
      "state: [ 0.00117753 -0.00256395], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1805/2000, Reward: -18.694617551523393, done: True\n",
      "state: [-0.00247015 -0.00915005], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1806/2000, Reward: -21.459256442737008, done: True\n",
      "state: [ 0.0012071  -0.00525722], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1807/2000, Reward: -21.11908396709203, done: True\n",
      "state: [ 0.00222575 -0.00452301], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1808/2000, Reward: -18.794558135932082, done: True\n",
      "state: [ 0.00134043 -0.00589509], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1809/2000, Reward: -16.68218762340241, done: True\n",
      "state: [ 0.00275225 -0.00971908], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1810/2000, Reward: -16.543407350131062, done: True\n",
      "state: [ 0.00328748 -0.00953039], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1811/2000, Reward: -17.36178163623887, done: True\n",
      "state: [-0.00807764 -0.00909586], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1812/2000, Reward: -16.785496874046906, done: True\n",
      "state: [ 6.72178307e-06 -9.19323024e-03], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1813/2000, Reward: -17.342658883260516, done: True\n",
      "state: [ 0.00502748 -0.00620185], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1814/2000, Reward: -18.018721992971287, done: True\n",
      "state: [-0.0048623  -0.00949351], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1815/2000, Reward: -16.58465086741088, done: True\n",
      "state: [-0.00396108 -0.00954445], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1816/2000, Reward: -17.667743809484225, done: True\n",
      "state: [-0.00437285 -0.00957794], action: [-0.33333333333333337, -0.0167]\n",
      "Episode: 1817/2000, Reward: -16.244070888047673, done: True\n",
      "state: [ 0.00585651 -0.0089822 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1818/2000, Reward: -18.239462151639827, done: True\n",
      "state: [-0.00034509 -0.00898923], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1819/2000, Reward: -19.400741152107983, done: True\n",
      "state: [ 0.00072116 -0.00865444], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1820/2000, Reward: -17.131043230991573, done: True\n",
      "state: [-0.00113991 -0.00893612], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1821/2000, Reward: -17.591506053358522, done: True\n",
      "state: [ 0.00453833 -0.00772483], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1822/2000, Reward: -17.79326267224982, done: True\n",
      "state: [ 0.00893157 -0.00917309], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1823/2000, Reward: -18.89523640799796, done: True\n",
      "state: [-0.0010297 -0.0089525], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1824/2000, Reward: -18.65347892281757, done: True\n",
      "state: [ 0.00031613 -0.00882445], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1825/2000, Reward: -20.128210434538254, done: True\n",
      "state: [ 0.00803349 -0.00114719], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1826/2000, Reward: -20.00199297222881, done: True\n",
      "state: [-0.00290175 -0.00930892], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1827/2000, Reward: -18.770906814250523, done: True\n",
      "state: [-0.00153529 -0.00923279], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1828/2000, Reward: -18.66194518628673, done: True\n",
      "state: [ 0.00197306 -0.00813122], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1829/2000, Reward: -19.330270981474612, done: True\n",
      "state: [ 0.00117806 -0.00585418], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1830/2000, Reward: -17.34662618348438, done: True\n",
      "state: [-0.00354624 -0.00949303], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1831/2000, Reward: -20.237314126336077, done: True\n",
      "state: [ 0.00469616 -0.00897968], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1832/2000, Reward: -18.1319359255501, done: True\n",
      "state: [ 0.00253857 -0.00642102], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1833/2000, Reward: -21.914381187346578, done: True\n",
      "state: [ 0.00198245 -0.00817414], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1834/2000, Reward: -20.444701238922356, done: True\n",
      "state: [ 0.00571584 -0.00944701], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1835/2000, Reward: -21.24048022678023, done: True\n",
      "state: [ 0.00773862 -0.00931948], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1836/2000, Reward: -20.881242402772312, done: True\n",
      "state: [-0.00628487 -0.00969221], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1837/2000, Reward: -18.56772007601031, done: True\n",
      "state: [ 0.00102984 -0.00912748], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1838/2000, Reward: -18.899736571063723, done: True\n",
      "state: [ 0.00137158 -0.00318269], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1839/2000, Reward: -20.901772695495406, done: True\n",
      "state: [ 0.0020707  -0.00943034], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1840/2000, Reward: -18.462918309956745, done: True\n",
      "state: [ 0.00694767 -0.00702893], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1841/2000, Reward: -19.352502574096516, done: True\n",
      "state: [-0.00884078 -0.00928871], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1842/2000, Reward: -20.132944036876935, done: True\n",
      "state: [ 0.00256232 -0.00800036], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1843/2000, Reward: -20.783726117061207, done: True\n",
      "state: [-0.00236232 -0.00942373], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1844/2000, Reward: -20.791495351641192, done: True\n",
      "state: [-0.0038085  -0.00929921], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1845/2000, Reward: -22.125141656323486, done: True\n",
      "state: [ 0.00851341 -0.00910197], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1846/2000, Reward: -17.898886215619505, done: True\n",
      "state: [ 0.00660759 -0.0093805 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1847/2000, Reward: -19.783816175240574, done: True\n",
      "state: [-0.00338528 -0.00919675], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1848/2000, Reward: -18.121342722476744, done: True\n",
      "state: [ 0.00079617 -0.009082  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1849/2000, Reward: -18.216950778307826, done: True\n",
      "state: [-0.00325835 -0.00946225], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1850/2000, Reward: -17.568886496469638, done: True\n",
      "state: [-0.00049707 -0.00910267], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1851/2000, Reward: -17.452829253972702, done: True\n",
      "state: [-0.00187254 -0.00923591], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1852/2000, Reward: -17.767472314868623, done: True\n",
      "state: [ 0.00126362 -0.00722923], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1853/2000, Reward: -17.573496323342457, done: True\n",
      "state: [ 0.00625738 -0.00751635], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1854/2000, Reward: -17.56023431727074, done: True\n",
      "state: [-0.0042252  -0.00941125], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1855/2000, Reward: -19.341571286773323, done: True\n",
      "state: [ 0.00563552 -0.00577326], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1856/2000, Reward: -19.789934459643323, done: True\n",
      "state: [ 0.0090487  -0.00256293], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1857/2000, Reward: -16.77291646989356, done: True\n",
      "state: [ 0.00632235 -0.00807423], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1858/2000, Reward: -18.13917986451026, done: True\n",
      "state: [-0.00164508 -0.00936862], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1859/2000, Reward: -19.701994057533373, done: True\n",
      "state: [-0.0049517  -0.00951189], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1860/2000, Reward: -17.794383957272675, done: True\n",
      "state: [ 0.00122999 -0.00785642], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1861/2000, Reward: -20.690063244420774, done: True\n",
      "state: [ 0.00470002 -0.00566617], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1862/2000, Reward: -18.571522326922103, done: True\n",
      "state: [ 0.00246936 -0.00821944], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1863/2000, Reward: -18.567853512449812, done: True\n",
      "state: [-0.00180618 -0.00897545], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1864/2000, Reward: -17.642330929804785, done: True\n",
      "state: [ 0.00098038 -0.00876056], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1865/2000, Reward: -20.729041779860527, done: True\n",
      "state: [ 0.00488293 -0.00540258], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1866/2000, Reward: -19.422290969740814, done: True\n",
      "state: [-0.00244464 -0.00922488], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1867/2000, Reward: -19.240152750519414, done: True\n",
      "state: [ 0.00114707 -0.00165363], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1868/2000, Reward: -18.809606326660035, done: True\n",
      "state: [-0.00285042 -0.00930527], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1869/2000, Reward: -19.023732458624576, done: True\n",
      "state: [ 0.00785733 -0.0092999 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1870/2000, Reward: -17.898083492660316, done: True\n",
      "state: [ 0.00487496 -0.0071953 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1871/2000, Reward: -18.89941216293846, done: True\n",
      "state: [ 0.00122429 -0.00216118], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1872/2000, Reward: -18.122351997371382, done: True\n",
      "state: [ 0.00402786 -0.00881514], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1873/2000, Reward: -20.900414017011926, done: True\n",
      "state: [ 0.00319206 -0.00824148], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1874/2000, Reward: -18.65571361744172, done: True\n",
      "state: [ 0.00338698 -0.00238776], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1875/2000, Reward: -18.234894229999217, done: True\n",
      "state: [-0.00226223 -0.0094389 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1876/2000, Reward: -20.110862910666373, done: True\n",
      "state: [-0.00014721 -0.00909878], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1877/2000, Reward: -19.23333238055773, done: True\n",
      "state: [-0.00354309 -0.00943562], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1878/2000, Reward: -16.810454713988754, done: True\n",
      "state: [ 0.003687   -0.00894517], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1879/2000, Reward: -23.570729541533503, done: True\n",
      "state: [-0.00663225 -0.00961187], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1880/2000, Reward: -19.015567590317104, done: True\n",
      "state: [ 0.00880687 -0.00907845], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1881/2000, Reward: -17.90948849317025, done: True\n",
      "state: [ 0.00613323 -0.00191834], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1882/2000, Reward: -19.881042392473905, done: True\n",
      "state: [ 0.0072808  -0.00682538], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1883/2000, Reward: -17.96418655145129, done: True\n",
      "state: [-0.00504148 -0.00945833], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1884/2000, Reward: -20.85156713126425, done: True\n",
      "state: [ 0.00523662 -0.00948574], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1885/2000, Reward: -20.320424362454386, done: True\n",
      "state: [ 0.00174193 -0.00736355], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1886/2000, Reward: -20.79164327005907, done: True\n",
      "state: [-0.00281073 -0.009275  ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1887/2000, Reward: -18.776294845591835, done: True\n",
      "state: [-0.00293722 -0.0092482 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1888/2000, Reward: -20.33326736244532, done: True\n",
      "state: [-0.00077562 -0.00924661], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1889/2000, Reward: -22.636456866151022, done: True\n",
      "state: [ 0.00129351 -0.00407723], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1890/2000, Reward: -19.759928014097625, done: True\n",
      "state: [-0.00512855 -0.00941153], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1891/2000, Reward: -18.557557169121075, done: True\n",
      "state: [ 0.00695856 -0.0093663 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1892/2000, Reward: -20.55637675133315, done: True\n",
      "state: [-0.00395623 -0.00925246], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1893/2000, Reward: -17.221938428465396, done: True\n",
      "state: [ 0.00671766 -0.00841246], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1894/2000, Reward: -18.63160187684877, done: True\n",
      "state: [ 0.00947623 -0.00917393], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1895/2000, Reward: -16.985069777425828, done: True\n",
      "state: [ 0.00090394 -0.00909794], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1896/2000, Reward: -18.9964101349287, done: True\n",
      "state: [ 0.00589223 -0.00463764], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1897/2000, Reward: -18.34767176997935, done: True\n",
      "state: [ 0.00549191 -0.00666875], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1898/2000, Reward: -21.996220221515948, done: True\n",
      "state: [0.00123518 0.00203455], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1899/2000, Reward: -18.338083473969576, done: True\n",
      "state: [-0.00059954 -0.00881674], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1900/2000, Reward: -22.23419511855004, done: True\n",
      "state: [-0.00365657 -0.00930532], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1901/2000, Reward: -20.72791285629845, done: True\n",
      "state: [-0.0033926  -0.00938735], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1902/2000, Reward: -19.110645352223138, done: True\n",
      "state: [ 0.00493432 -0.00603174], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1903/2000, Reward: -19.667752354094375, done: True\n",
      "state: [-0.00270321 -0.00944159], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1904/2000, Reward: -17.207119480306265, done: True\n",
      "state: [ 0.00582876 -0.00909675], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1905/2000, Reward: -16.69130681343654, done: True\n",
      "state: [ 0.00684604 -0.00569861], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1906/2000, Reward: -18.606521141783624, done: True\n",
      "state: [ 0.0047888  -0.00712056], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1907/2000, Reward: -17.610910600441194, done: True\n",
      "state: [-0.0026554  -0.00922902], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1908/2000, Reward: -17.64548336281897, done: True\n",
      "state: [-0.00541941 -0.00957808], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1909/2000, Reward: -19.744210457617058, done: True\n",
      "state: [ 0.00601216 -0.00496736], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1910/2000, Reward: -22.79748604415553, done: True\n",
      "state: [ 0.00837393 -0.00920024], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1911/2000, Reward: -19.053087685789848, done: True\n",
      "state: [-0.00647058 -0.00967211], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1912/2000, Reward: -18.86128661769419, done: True\n",
      "state: [-0.0053948  -0.00953732], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1913/2000, Reward: -18.328789564482207, done: True\n",
      "state: [-0.00065866 -0.00922833], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1914/2000, Reward: -21.500747932646483, done: True\n",
      "state: [-0.00371311 -0.00941105], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1915/2000, Reward: -21.555046537992393, done: True\n",
      "state: [-0.00349824 -0.00940202], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1916/2000, Reward: -18.577112383244533, done: True\n",
      "state: [-0.00125844 -0.00908282], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1917/2000, Reward: -20.879612684061556, done: True\n",
      "state: [ 0.00010849 -0.00908568], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1918/2000, Reward: -20.65349975428344, done: True\n",
      "state: [-0.00458853 -0.00945074], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1919/2000, Reward: -17.41078511979534, done: True\n",
      "state: [-0.00476379 -0.00959792], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1920/2000, Reward: -18.896034504322056, done: True\n",
      "state: [ 0.00821886 -0.00857801], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1921/2000, Reward: -17.331540874362044, done: True\n",
      "state: [-0.00142677 -0.00921916], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1922/2000, Reward: -19.213173430983378, done: True\n",
      "state: [-0.00470017 -0.00957016], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1923/2000, Reward: -18.31375423868159, done: True\n",
      "state: [-0.00452996 -0.00947078], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1924/2000, Reward: -24.460116055058283, done: True\n",
      "state: [-5.46389336e-03 -8.07236699e-05], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1925/2000, Reward: -19.32786894356277, done: True\n",
      "state: [ 0.0013034 -0.0070466], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1926/2000, Reward: -18.74206424835108, done: True\n",
      "state: [ 0.00164223 -0.00532583], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1927/2000, Reward: -23.776455691874656, done: True\n",
      "state: [ 0.00064193 -0.00887185], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1928/2000, Reward: -20.21739116503584, done: True\n",
      "state: [-0.0027381 -0.0092594], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1929/2000, Reward: -20.522023600775217, done: True\n",
      "state: [ 0.00435089 -0.00953246], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1930/2000, Reward: -17.577971406340687, done: True\n",
      "state: [-0.00552765 -0.00956164], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1931/2000, Reward: -18.618142419094035, done: True\n",
      "state: [ 0.00115953 -0.00720215], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1932/2000, Reward: -24.182539018105746, done: True\n",
      "state: [-0.0061709  -0.00951992], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1933/2000, Reward: -21.004804218493458, done: True\n",
      "state: [-0.00240393 -0.00907879], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1934/2000, Reward: -16.41973433744192, done: True\n",
      "state: [-0.00429301 -0.00938936], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1935/2000, Reward: -19.395992763169602, done: True\n",
      "state: [-0.00292688 -0.00943436], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1936/2000, Reward: -21.302821574414953, done: True\n",
      "state: [ 0.00595355 -0.00754836], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1937/2000, Reward: -20.981529393371463, done: True\n",
      "state: [-0.00554491 -0.00944297], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1938/2000, Reward: -22.227782918770288, done: True\n",
      "state: [-0.00582338 -0.00955689], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1939/2000, Reward: -25.56841842242819, done: True\n",
      "state: [-0.00369366 -0.00947325], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1940/2000, Reward: -19.084460625734064, done: True\n",
      "state: [-0.00067933 -0.00886714], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1941/2000, Reward: -21.812366008081984, done: True\n",
      "state: [-0.00374186 -0.00927019], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1942/2000, Reward: -24.65635026561697, done: True\n",
      "state: [ 0.00777367 -0.00735933], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1943/2000, Reward: -21.09609497036369, done: True\n",
      "state: [ 0.0024463  -0.00728567], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1944/2000, Reward: -22.585445667081956, done: True\n",
      "state: [-0.00313876 -0.00912182], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1945/2000, Reward: -17.45478483286457, done: True\n",
      "state: [ 0.00235426 -0.00652211], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1946/2000, Reward: -17.442486466910236, done: True\n",
      "state: [ 0.00322235 -0.00962488], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1947/2000, Reward: -17.986443530889378, done: True\n",
      "state: [ 0.00758619 -0.00471328], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1948/2000, Reward: -17.770760260982122, done: True\n",
      "state: [ 0.00074209 -0.00885895], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1949/2000, Reward: -16.99652770220746, done: True\n",
      "state: [ 0.00135119 -0.00469931], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1950/2000, Reward: -20.61267343839528, done: True\n",
      "state: [ 0.00117371 -0.0083494 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1951/2000, Reward: -19.90753811328526, done: True\n",
      "state: [-0.00292032 -0.00942227], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1952/2000, Reward: -18.886793112180083, done: True\n",
      "state: [ 0.0023152  -0.00872919], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1953/2000, Reward: -17.30735244123373, done: True\n",
      "state: [ 0.00162997 -0.0063649 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1954/2000, Reward: -19.268702737121547, done: True\n",
      "state: [ 0.00116435 -0.00535434], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1955/2000, Reward: -22.958407984543673, done: True\n",
      "state: [ 0.0057377  -0.00943658], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1956/2000, Reward: -19.99781003705216, done: True\n",
      "state: [ 0.00280532 -0.00888383], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1957/2000, Reward: -21.63332307230287, done: True\n",
      "state: [ 0.00822069 -0.0080862 ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1958/2000, Reward: -20.40248072306721, done: True\n",
      "state: [ 0.00860246 -0.00375021], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1959/2000, Reward: -20.65964542818977, done: True\n",
      "state: [ 0.00753863 -0.00078542], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1960/2000, Reward: -20.61316406900104, done: True\n",
      "state: [ 0.00113295 -0.00658503], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1961/2000, Reward: -22.701665633482286, done: True\n",
      "state: [-0.00220072 -0.00902956], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1962/2000, Reward: -22.167910120908797, done: True\n",
      "state: [-0.00112427 -0.00932097], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1963/2000, Reward: -17.74279794450291, done: True\n",
      "state: [ 0.00281087 -0.00937139], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1964/2000, Reward: -17.52511884774399, done: True\n",
      "state: [ 0.00250433 -0.00914912], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1965/2000, Reward: -20.192075393328597, done: True\n",
      "state: [ 0.00130187 -0.0070607 ], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1966/2000, Reward: -19.43760382007783, done: True\n",
      "state: [ 0.0005656  -0.00895746], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1967/2000, Reward: -27.797496234057665, done: True\n",
      "state: [ 0.00104467 -0.00955566], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1968/2000, Reward: -21.3238287805005, done: True\n",
      "state: [-0.00510066 -0.00963597], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1969/2000, Reward: -20.88430147730126, done: True\n",
      "state: [ 0.00931355 -0.00905297], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1970/2000, Reward: -21.431272838712445, done: True\n",
      "state: [ 0.00853006 -0.00504096], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1971/2000, Reward: -19.666748508041266, done: True\n",
      "state: [-0.00761542 -0.00920413], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1972/2000, Reward: -23.76394221589835, done: True\n",
      "state: [ 0.00117673 -0.00262434], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1973/2000, Reward: -16.778974271608877, done: True\n",
      "state: [-0.00304608 -0.00920196], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1974/2000, Reward: -16.66231803466828, done: True\n",
      "state: [-0.00049251 -0.00902641], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1975/2000, Reward: -20.591079307259154, done: True\n",
      "state: [ 0.001125  -0.0013289], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1976/2000, Reward: -18.391986348450477, done: True\n",
      "state: [0.00684395 0.00485141], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1977/2000, Reward: -19.03133625110094, done: True\n",
      "state: [ 0.00438335 -0.00588053], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1978/2000, Reward: -18.0880697756399, done: True\n",
      "state: [-0.00315312 -0.00941449], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1979/2000, Reward: -15.760257234808734, done: True\n",
      "state: [ 0.00506844 -0.00867806], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1980/2000, Reward: -17.14034926217776, done: True\n",
      "state: [ 0.00123429 -0.00861374], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1981/2000, Reward: -19.869550056261176, done: True\n",
      "state: [ 0.00409792 -0.00788806], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1982/2000, Reward: -17.362544391603866, done: True\n",
      "state: [-0.00297478 -0.00940518], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1983/2000, Reward: -21.66801821948892, done: True\n",
      "state: [-0.00452634 -0.00929824], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1984/2000, Reward: -18.20546036932107, done: True\n",
      "state: [-0.00335387 -0.00941337], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1985/2000, Reward: -18.210778773093455, done: True\n",
      "state: [-0.00234715 -0.00904366], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1986/2000, Reward: -22.851447036908045, done: True\n",
      "state: [0.00885165 0.00073362], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1987/2000, Reward: -20.168724521170315, done: True\n",
      "state: [ 0.00125867 -0.00901079], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1988/2000, Reward: -20.02615343324931, done: True\n",
      "state: [-0.00391234 -0.00951763], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1989/2000, Reward: -17.238763313145338, done: True\n",
      "state: [ 0.00135769 -0.00351043], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 1990/2000, Reward: -14.807471900146933, done: True\n",
      "state: [ 0.00635905 -0.00913524], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1991/2000, Reward: -17.20380124234102, done: True\n",
      "state: [ 0.00270823 -0.00440565], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1992/2000, Reward: -19.763157649737927, done: True\n",
      "state: [0.00864333 0.00932241], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1993/2000, Reward: -21.58878503064665, done: True\n",
      "state: [0.00354569 0.004944  ], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1994/2000, Reward: -17.400236471617234, done: True\n",
      "state: [0.00770517 0.00558031], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1995/2000, Reward: -17.18460958423581, done: True\n",
      "state: [ 0.00997055 -0.00960664], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1996/2000, Reward: -31.234536791022986, done: True\n",
      "state: [0.00190806 0.00936891], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1997/2000, Reward: -20.39597839620409, done: True\n",
      "state: [0.0095589  0.00592117], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1998/2000, Reward: -17.30766583445549, done: True\n",
      "state: [0.0082901  0.00342887], action: [0.33333333333333326, 0.005566666666666668]\n",
      "Episode: 1999/2000, Reward: -21.398070088437688, done: True\n",
      "state: [0.00123445 0.00629745], action: [-0.33333333333333337, 0.0167]\n",
      "Episode: 2000/2000, Reward: -25.913644718273844, done: True\n",
      "state: [0.00117654 0.00999807], action: [-0.33333333333333337, 0.0167]\n"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "num_episodes = 2000\n",
    "steps = 0\n",
    "epsilon = 1.0\n",
    "memory = ReplayBuffer(memory_size)\n",
    "\n",
    "for e in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    step = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = get_action(state, epsilon)\n",
    "        u = [XX[action], YY[action]]\n",
    "        next_state, reward, done = env.step(u)\n",
    "        total_reward += reward\n",
    "\n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        train_model()\n",
    "\n",
    "        steps += 1\n",
    "        step += 1\n",
    "        if steps % update_target_network_steps == 0:\n",
    "            target_q_network.load_state_dict(q_network.state_dict())\n",
    "        if step == 500 or done:\n",
    "            break\n",
    "\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    print(f\"Episode: {e+1}/{num_episodes}, Reward: {total_reward}, done: {done}\")\n",
    "    print(f\"state: {state}, action: {u}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9b11c-32a2-478b-bdf8-fa370480ff6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
